Index: include/llvm/ADT/ilist_node.h
===================================================================
--- include/llvm/ADT/ilist_node.h	(revision 277823)
+++ include/llvm/ADT/ilist_node.h	(working copy)
@@ -70,7 +70,7 @@
     const NodeTy *Prev = this->getPrev();
 
     // Check for sentinel.
-    if (!Prev->getNext())
+    if (!Prev || !Prev->getNext())
       return nullptr;
 
     return Prev;
@@ -81,7 +81,7 @@
     NodeTy *Next = getNext();
 
     // Check for sentinel.
-    if (!Next->getNext())
+    if (!Next || !Next->getNext())
       return nullptr;
 
     return Next;
Index: include/llvm/Analysis/LiveValues.h
===================================================================
--- include/llvm/Analysis/LiveValues.h	(nonexistent)
+++ include/llvm/Analysis/LiveValues.h	(working copy)
@@ -0,0 +1,209 @@
+/*
+ * Calculate live-value sets for functions.
+ *
+ * Liveness-analysis is based on the non-iterative dataflow algorithm for
+ * reducible graphs by Brandner et. al in:
+ *
+ * "Computing Liveness Sets for SSA-Form Programs"
+ * URL: https://hal.inria.fr/inria-00558509v1/document
+ * Accessed: 5/19/2016
+ *
+ * Author: Rob Lyerly <rlyerly@vt.edu>
+ * Date: 5/19/2016
+ */
+
+#ifndef _LIVE_VALUES_H
+#define _LIVE_VALUES_H
+
+#include <map>
+#include <set>
+#include <list>
+#include "llvm/Pass.h"
+#include "llvm/Analysis/LoopNestingTree.h"
+#include "llvm/IR/Function.h"
+#include "llvm/Support/raw_ostream.h"
+
+namespace llvm {
+
+class LiveValues : public FunctionPass
+{
+public:
+  typedef std::pair<const BasicBlock *, const BasicBlock *> Edge;
+
+  static char ID;
+
+  /**
+   * Default constructor.
+   */
+  LiveValues(void);
+
+  /**
+   * Default destructor.
+   */
+  ~LiveValues(void) {}
+
+  /**
+   * Return whether or not a given type should be included in the analysis.
+   * @return true if the type is included in liveness sets, false otherwise
+   */
+  bool includeAsm(void) const { return inlineasm; }
+  bool includeBitcasts(void) const { return bitcasts; }
+  bool includeComparisons(void) const { return comparisons; }
+  bool includeConstants(void) const { return constants; }
+  bool includeMetadata(void) const { return metadata; }
+
+  /**
+   * Set whether or not to include the specified type in the analysis (all
+   * are set to false by default by the constructor).
+   * @param include true if it should be included, false otherwise
+   */
+  void includeAsm(bool include) { inlineasm = include; }
+  void includeBitcasts(bool include) { bitcasts = include; }
+  void includeComparisons(bool include) { comparisons = include; }
+  void includeConstants(bool include) { constants = include; }
+  void includeMetadata(bool include) { metadata = include; }
+
+  /**
+   * Register which analysis passes we need.
+   * @param AU an analysis usage object
+   */
+  virtual void getAnalysisUsage(AnalysisUsage &AU) const;
+
+  /**
+   * Calculate liveness sets for a function.
+   * @param F a function for which to calculate live values.
+   * @return false, always
+   */
+  virtual bool runOnFunction(Function &F);
+
+  /**
+   * Get the human-readable name of the pass.
+   * @return the pass name
+   */
+  virtual const char *getPassName() const { return "Live value analysis"; }
+
+  /**
+   * Print a human-readable version of the analysis.
+   * @param O an output stream
+   * @param F the function for which to print analysis
+   */
+  virtual void print(raw_ostream &O, const Function *F) const;
+
+  /**
+   * Return the live-in set for a basic block.
+   * @param BB a basic block
+   * @return a set of live-in values for the basic block; this set must be
+   *         freed by the user.
+   */
+  std::set<const Value *> *getLiveIn(const BasicBlock *BB) const;
+
+  /**
+   * Return the live-out set for a basic block.
+   * @param BB a basic block
+   * @return a set of live-out values for the basic block; this set must be
+   *         freed by the user.
+   */
+  std::set<const Value *> *getLiveOut(const BasicBlock *BB) const;
+
+  /**
+   * Get the live values across a given instruction, i.e., values live right
+   * after the invocation of the instruction (excluding the value defined by
+   * the instruction itself).
+   * @param inst an instruction
+   * @return the set of values live directly before the instruction; this set
+   *         must be freed by the user.
+   */
+  std::set<const Value *> *
+  getLiveValues(const Instruction *inst) const;
+
+private:
+  /* Should values of each type be included? */
+  bool inlineasm;
+  bool bitcasts;
+  bool comparisons;
+  bool constants;
+  bool metadata;
+
+  /* A loop nesting forest composed of 0 or more loop nesting trees. */
+  typedef std::list<LoopNestingTree> LoopNestingForest;
+
+  /* Maps live values to a basic block. */
+  typedef std::map<const BasicBlock *, std::set<const Value *> > LiveVals;
+  typedef std::pair<const BasicBlock *, std::set<const Value *> > LiveValsPair;
+
+  /* Store analysis for all functions. */
+  std::map<const Function *, LiveVals> FuncBBLiveIn;
+  std::map<const Function *, LiveVals> FuncBBLiveOut;
+
+  /**
+   * Return whether or not a value is a variable that should be tracked.
+   * @param val a value
+   * @return true if the value is a variable to be tracked, false otherwise
+   */
+  bool includeVal(const Value *val) const;
+
+  /**
+   * Insert the values used in phi-nodes at the beginning of basic block S (as
+   * values live from B) into the set uses.
+   * @param B a basic block which passes live values into phi-nodes in S
+   * @param S a basic block, successor to B
+   * @param uses set in which to add values used in phi-nodes in B
+   * @return the number of values added to the set
+   */
+  unsigned phiUses(const BasicBlock *B,
+                   const BasicBlock *S,
+                   std::set<const Value *> &uses);
+
+  /**
+   * Insert the values defined by the phi-nodes at the beginning of basic block
+   * B into the set defs.
+   * @param B a basic block
+   * @param defs set in which to add values defined by phi-nodes in B
+   * @return the number of values added to the set
+   */
+  unsigned phiDefs(const BasicBlock *B,
+                   std::set<const Value *> &defs);
+
+  /**
+   * Do a post-order traversal of the control flow graph to calculate partial
+   * liveness sets.
+   * @param F a function for which to calculate per-basic block partial
+   *          liveness sets
+   * @param liveIn per-basic block live-in values
+   * @param liveOut per-basic block live-out values
+   */
+  void dagDFS(Function &F, LiveVals &liveIn, LiveVals &liveOut);
+
+  /**
+   * Construct the loop-nesting forest for a function.
+   * @param F a function for which to calculate the loop-nesting forest.
+   * @param LNF a loop nesting forest to populate with loop nesting trees.
+   */
+  void constructLoopNestingForest(Function &F, LoopNestingForest &LNF);
+
+  /**
+   * Propagate live values throughout the loop-nesting tree.
+   * @param loopNest a loop-nesting tree
+   * @param liveIn per-basic block live-in values
+   * @param liveOut per-basic block live-out values
+   */
+  void propagateValues(const LoopNestingTree &loopNest,
+                       LiveVals &liveIn,
+                       LiveVals &liveOut);
+
+  /**
+   * Propagate live values within loops for all loop-nesting trees in the
+   * function's loop-nesting forest.
+   * @param LNF a loop nesting forest
+   * @param liveIn per-basic block live-in values
+   * @param liveOut per-basic block live-out values
+   */
+  void loopTreeDFS(LoopNestingForest &LNF,
+                   LiveVals &liveIn,
+                   LiveVals &liveOut);
+};
+
+} /* llvm namespace */
+
+#endif /* _LIVE_VALUES_H */
+
Index: include/llvm/Analysis/LoopNestingTree.h
===================================================================
--- include/llvm/Analysis/LoopNestingTree.h	(nonexistent)
+++ include/llvm/Analysis/LoopNestingTree.h	(working copy)
@@ -0,0 +1,191 @@
+/*
+ * Loop-nesting tree for a loop.  The root of a loop-nesting tree is the loop
+ * header of the outermost loop.  The children of any given node (including the
+ * root) are the basic blocks contained within the loop and the loop headers of
+ * nested loops.
+ *
+ * Note: we assume that the control-flow graphs are reducible
+ *
+ * Author: Rob Lyerly <rlyerly@vt.edu>
+ * Date: 5/23/2016
+ */
+
+#ifndef _LOOP_NESTING_TREE_H
+#define _LOOP_NESTING_TREE_H
+
+#include <list>
+#include <vector>
+#include <queue>
+#include "llvm/IR/BasicBlock.h"
+#include "llvm/Analysis/LoopInfo.h"
+#include "llvm/Support/raw_ostream.h"
+
+class LoopNestingTree {
+private:
+  /*
+   * Tree node object.
+   */
+  class Node {
+  public:
+    /**
+     * Construct a node for a basic block.
+     * @param _bb a basic block
+     * @param _parent the parent of this node, i.e. the loop header of the
+     *                containing loop
+     * @param _isLoopHeader is the basic block a loop header?
+     */
+    Node(const llvm::BasicBlock *_bb, const Node *_parent, bool _isLoopHeader)
+      : bb(_bb), parent(_parent), isLoopHeader(_isLoopHeader) {}
+
+    /**
+     * Add a child to the node.
+     * @param child a child to add to the node
+     */
+    void addChild(Node *child) { children.push_back(child); }
+
+    const llvm::BasicBlock *bb; /* Basic block encapsulated by the node. */
+    const Node *parent; /* Parent node, i.e. header of containing loop. */
+    std::list<Node *> children; /* Regular child nodes in the tree. */
+    bool isLoopHeader; /* Is the basic block a loop header? */
+  };
+
+  unsigned _size; /* Number of nodes (i.e., basic blocks) in the tree. */
+  unsigned _depth; /* Number of nested loops in the tree. */
+  Node *_root; /* Root of the tree, i.e. loop header of outermost loop. */
+
+  /**
+   * Print a node & its children.  Recurses into nested loops.
+   * @param O an output stream on which to print the tree
+   * @param node a node to print
+   * @param depth the current depth
+   */
+  void print(llvm::raw_ostream &O, Node *node, unsigned depth) const;
+
+  /**
+   * Delete the node's children & the node itself.  Recurses into nested loops.
+   * @param node the node being deleted
+   */
+  void deleteRecursive(Node *node);
+
+public:
+  /**
+   * Construct a loop-nesting tree from a strongly-connected component of the
+   * control-flow graph.
+   * @param SCC a strongly-connected component of the control-flow graph
+   * @param LI analysis from the loop info pass
+   */
+  LoopNestingTree(const std::vector<llvm::BasicBlock *> &SCC,
+                  const llvm::LoopInfo &LI);
+
+  /**
+   * Destroy a loop-nesting tree.
+   */
+  ~LoopNestingTree() { deleteRecursive(this->_root); }
+
+  /**
+   * Return the size of the loop-nesting tree, that is the number of nodes in
+   * the loop (and all nested loops).
+   * @return the number of nodes in the tree
+   */
+  unsigned size() const { return this->_size; }
+
+  /**
+   * Return the depth of the loop-nesting tree, that is the number of nested
+   * loops.  A value of one indicates that there are no nested loops.
+   * @return the number of nested loops in the tree
+   */
+  unsigned depth() const { return this->_depth; }
+
+  /**
+   * Print the tree.
+   * @param O the output stream on which to print the tree
+   */
+  void print(llvm::raw_ostream &O) const { print(O, this->_root, 0); }
+
+  /*
+   * Loop-node iterator object.  Delivers loop nodes in breadth-first order.
+   */
+  class loop_iterator {
+  public:
+    typedef loop_iterator self_type;
+    typedef const llvm::BasicBlock *value_type;
+    typedef value_type& reference;
+    typedef value_type* pointer;
+    typedef std::forward_iterator_tag iterator_category;
+
+    self_type operator++(void);
+    self_type operator++(int junk);
+    reference operator*(void) { return cur->bb; }
+    pointer operator->(void) { return &cur->bb; }
+    bool operator==(const self_type& rhs) { return cur == rhs.cur; }
+    bool operator!=(const self_type& rhs) { return cur != rhs.cur; }
+
+    friend class LoopNestingTree;
+    friend class child_iterator;
+  private:
+    Node *cur;
+    std::queue<Node *> remaining;
+
+    loop_iterator(Node *start) : cur(start) { addLoopHeaders(); }
+    void addLoopHeaders(void);
+  };
+
+  /*
+   * Child iterator object.  Traverses children of tree nodes.
+   */
+  class child_iterator {
+  public:
+    typedef child_iterator self_type;
+    typedef const llvm::BasicBlock *value_type;
+    typedef value_type& reference;
+    typedef value_type* pointer;
+    typedef std::forward_iterator_tag iterator_category;
+    enum location { BEGIN, END };
+
+    self_type operator++(void)
+      { self_type me = *this; it.operator++(); return me; }
+    self_type operator++(int junk) { it.operator++(junk); return *this; }
+    reference operator*(void) { return (*it)->bb; }
+    pointer operator->(void) { return &(*it)->bb; }
+    bool operator==(const self_type& rhs) { return it == rhs.it; }
+    bool operator!=(const self_type& rhs) { return it != rhs.it; }
+
+    friend class LoopNestingTree;
+  private:
+    std::list<Node *>::const_iterator it;
+
+    child_iterator(loop_iterator &parent, enum location loc);
+  };
+
+  /**
+   * Return an iterator for traversing all loop nodes (i.e., loop header basic
+   * blocks) in the tree.  Delivers nodes in a breadth-first ordering.
+   * @return an iterator to traverse the loop nodes in the tree
+   */
+  loop_iterator loop_begin() const { loop_iterator it(_root); return it; };
+
+  /**
+   * Return an iterator marking the end of the loop nodes in the tree.
+   * @return an iterator marking the end of the traversal
+   */
+  loop_iterator loop_end() const { loop_iterator it(nullptr); return it; };
+
+  /**
+   * Return an iterator for traversing the children of a loop node.
+   * @param an iterator associated with a loop node
+   * @return an iterator to traverse the children of a loop node
+   */
+  child_iterator children_begin(loop_iterator &parent) const
+    { child_iterator it(parent, child_iterator::BEGIN); return it; }
+
+  /**
+   * Return an iterator marking the end of the children of a loop node.
+   * @param an iterator associated with a loop node
+   * @return an iterator marking the end of the traversal
+   */
+  child_iterator children_end(loop_iterator &parent) const
+    { child_iterator it(parent, child_iterator::END); return it; }
+};
+
+#endif /* _LOOP_NESTING_TREE_H */
+
Index: include/llvm/Analysis/Passes.h
===================================================================
--- include/llvm/Analysis/Passes.h	(revision 277823)
+++ include/llvm/Analysis/Passes.h	(working copy)
@@ -173,6 +173,13 @@
   //
   FunctionPass *createMemDerefPrinter();
 
+  //===--------------------------------------------------------------------===//
+  //
+  // createLiveValuesPass - This pass calculates live-value sets for basic
+  // blocks in a function.
+  //
+  FunctionPass *createLiveValuesPass();
+
 }
 
 #endif
Index: include/llvm/CodeGen/AsmPrinter.h
===================================================================
--- include/llvm/CodeGen/AsmPrinter.h	(revision 277823)
+++ include/llvm/CodeGen/AsmPrinter.h	(working copy)
@@ -199,9 +199,10 @@
 
   /// Emit the specified function out to the OutStreamer.
   bool runOnMachineFunction(MachineFunction &MF) override {
+    bool modified = TagCallSites(MF);
     SetupMachineFunction(MF);
     EmitFunctionBody();
-    return false;
+    return modified;
   }
 
   //===------------------------------------------------------------------===//
@@ -329,6 +330,10 @@
   /// instructions in verbose mode.
   virtual void emitImplicitDef(const MachineInstr *MI) const;
 
+  /// Offset to adjust values returned by getObjectOffset to be an offset from
+  /// the function's frame base pointer
+  virtual unsigned getFBPOffset(void) { return 16; }
+
   //===------------------------------------------------------------------===//
   // Symbol Lowering Routines.
   //===------------------------------------------------------------------===//
@@ -393,6 +398,14 @@
     EmitLabelPlusOffset(Label, 0, Size, IsSectionRelative);
   }
 
+  /// Find the stackmap intrinsic associated with a function call
+  MachineInstr *FindStackMap(MachineBasicBlock &MBB,
+                             MachineInstr *MI) const;
+
+  /// Move stackmap intrinsics directly after calls to correctly capture
+  /// return addresses
+  bool TagCallSites(MachineFunction &MF);
+
   //===------------------------------------------------------------------===//
   // Dwarf Emission Helper Routines
   //===------------------------------------------------------------------===//
Index: include/llvm/CodeGen/MachineFunction.h
===================================================================
--- include/llvm/CodeGen/MachineFunction.h	(revision 277823)
+++ include/llvm/CodeGen/MachineFunction.h	(working copy)
@@ -20,6 +20,8 @@
 
 #include "llvm/ADT/ilist.h"
 #include "llvm/CodeGen/MachineBasicBlock.h"
+#include "llvm/CodeGen/StackTransformTypes.h"
+#include "llvm/IR/Instructions.h"
 #include "llvm/IR/DebugLoc.h"
 #include "llvm/IR/Metadata.h"
 #include "llvm/Support/Allocator.h"
@@ -145,6 +147,12 @@
   /// True if the function includes any inline assembly.
   bool HasInlineAsm;
 
+  /// Duplicate live value locations for stackmap operands
+  InstToOperands SMDuplicateLocs;
+
+  /// Architecture-specific live value locations for each stackmap
+  InstToArchLiveValues SMArchSpecificLocs;
+
   MachineFunction(const MachineFunction &) = delete;
   void operator=(const MachineFunction&) = delete;
 public:
@@ -457,6 +465,9 @@
     return Mask;
   }
 
+  /// Is a register caller-saved?
+  bool isCallerSaved(unsigned Reg) const;
+
   /// allocateMemRefsArray - Allocate an array to hold MachineMemOperand
   /// pointers.  This array is owned by the MachineFunction.
   MachineInstr::mmo_iterator allocateMemRefsArray(unsigned long Num);
@@ -488,6 +499,39 @@
   /// getPICBaseSymbol - Return a function-local symbol to represent the PIC
   /// base.
   MCSymbol *getPICBaseSymbol() const;
+
+  //===--------------------------------------------------------------------===//
+  // Architecture-specific stack transformation metadata
+  //
+
+  /// Add an IR/architecture-specific location mapping for a stackmap operand
+  void addSMOpLocation(const CallInst *SM, const Value *Val,
+                       const MachineLiveLoc &MLL);
+  void addSMOpLocation(const CallInst *SM, unsigned Op,
+                       const MachineLiveLoc &MLL);
+
+  /// Add an architecture-specific live value & location for a stackmap
+  void addSMArchSpecificLocation(const CallInst *SM,
+                                 const MachineLiveLoc &MLL,
+                                 const MachineLiveVal &MC);
+
+  /// Update stack slot references to new indexes after stack slot coloring
+  void updateSMStackSlotRefs(SmallDenseMap<int, int, 16> &Changes);
+
+  /// Are there any architecture-specific locations for operand Val in stackmap
+  /// SM?
+  bool hasSMOpLocations(const CallInst *SM, const Value *Val) const;
+
+  /// Are there any architecture-specific locations for stackmap SM?
+  bool hasSMArchSpecificLocations(const CallInst *SM) const;
+
+  /// Return the architecture-specific locations for a stackmap operand.
+  const MachineLiveLocs &getSMOpLocations(const CallInst *SM,
+                                          const Value *Val) const;
+
+  /// Return the architecture-specific locations for a stackmap that are not
+  /// associated with any operand.
+  const ArchLiveValues &getSMArchSpecificLocations(const CallInst *SM) const;
 };
 
 //===--------------------------------------------------------------------===//
Index: include/llvm/CodeGen/Passes.h
===================================================================
--- include/llvm/CodeGen/Passes.h	(revision 277823)
+++ include/llvm/CodeGen/Passes.h	(working copy)
@@ -142,6 +142,15 @@
 
   CodeGenOpt::Level getOptLevel() const { return TM->getOptLevel(); }
 
+  CodeGenOpt::Level getArchIROptLevel() const
+  { return TM->getArchIROptLevel(); }
+
+  bool emitStackTransformMetadata() const
+  { return TM->emitStackTransformMetadata(); }
+
+  bool emitLibcTransformMetadata() const
+  { return TM->emitLibcTransformMetadata(); }
+
   /// Set the StartAfter, StartBefore and StopAfter passes to allow running only
   /// a portion of the normal code-gen pass sequence.
   ///
@@ -448,6 +457,10 @@
   // instruction and update the MachineFunctionInfo with that information.
   extern char &ShrinkWrapID;
 
+  /// Stack transformation metadata pass.  Gather additional stack
+  /// transformation metadata from machine functions.
+  extern char &StackTransformMetadataID;
+
   /// VirtRegRewriter pass. Rewrite virtual registers to physical registers as
   /// assigned in VirtRegMap.
   extern char &VirtRegRewriterID;
Index: include/llvm/CodeGen/StackMaps.h
===================================================================
--- include/llvm/CodeGen/StackMaps.h	(revision 277823)
+++ include/llvm/CodeGen/StackMaps.h	(working copy)
@@ -13,6 +13,8 @@
 #include "llvm/ADT/MapVector.h"
 #include "llvm/ADT/SmallVector.h"
 #include "llvm/CodeGen/MachineInstr.h"
+#include "llvm/CodeGen/StackTransformTypes.h"
+#include "llvm/IR/Instructions.h"
 #include "llvm/Support/Debug.h"
 #include <map>
 #include <vector>
@@ -22,6 +24,7 @@
 class AsmPrinter;
 class MCExpr;
 class MCStreamer;
+class UnwindInfo;
 
 /// \brief MI-level patchpoint operands.
 ///
@@ -142,9 +145,16 @@
     unsigned Size;
     unsigned Reg;
     int64_t Offset;
-    Location() : Type(Unprocessed), Size(0), Reg(0), Offset(0) {}
-    Location(LocationType Type, unsigned Size, unsigned Reg, int64_t Offset)
-        : Type(Type), Size(Size), Reg(Reg), Offset(Offset) {}
+    bool Ptr;
+    bool Alloca;
+    bool Duplicate;
+    unsigned AllocaSize;
+    Location() : Type(Unprocessed), Size(0), Reg(0), Offset(0),
+                 Ptr(false), Alloca(false), Duplicate(false), AllocaSize(0) {}
+    Location(LocationType Type, unsigned Size, unsigned Reg, int64_t Offset,
+             bool Ptr, bool Alloca, bool Duplicate, unsigned AllocaSize)
+        : Type(Type), Size(Size), Reg(Reg), Offset(Offset), Ptr(Ptr),
+          Alloca(Alloca), Duplicate(Duplicate), AllocaSize(AllocaSize) {}
   };
 
   struct LiveOutReg {
@@ -158,6 +168,18 @@
         : Reg(Reg), DwarfRegNum(DwarfRegNum), Size(Size) {}
   };
 
+  struct Operation {
+    MachineGeneratedVal::ValueGenInst::InstType InstType;
+    Location::LocationType OperandType;
+    unsigned Size;
+    unsigned DwarfReg;
+    int64_t Constant;
+    bool isSymbol;
+    const MCSymbol *Symbol;
+
+    Operation() : Size(0), DwarfReg(0), Constant(0), isSymbol(false) {}
+  };
+
   // OpTypes are used to encode information about the following logical
   // operand (which may consist of several MachineOperands) for the
   // OpParser.
@@ -185,7 +207,7 @@
   /// If there is any stack map data, create a stack map section and serialize
   /// the map info into it. This clears the stack map data structures
   /// afterwards.
-  void serializeToStackMapSection();
+  void serializeToStackMapSection(const UnwindInfo *UI = nullptr);
 
 private:
   static const char *WSMP;
@@ -193,17 +215,23 @@
   typedef SmallVector<LiveOutReg, 8> LiveOutVec;
   typedef MapVector<uint64_t, uint64_t> ConstantPool;
   typedef MapVector<const MCSymbol *, uint64_t> FnStackSizeMap;
+  typedef std::pair<Location, Operation> ArchValue;
+  typedef SmallVector<ArchValue, 8> ArchValues;
 
   struct CallsiteInfo {
+    const MCSymbol *Func;
     const MCExpr *CSOffsetExpr;
     uint64_t ID;
     LocationVec Locations;
     LiveOutVec LiveOuts;
-    CallsiteInfo() : CSOffsetExpr(nullptr), ID(0) {}
-    CallsiteInfo(const MCExpr *CSOffsetExpr, uint64_t ID,
-                 LocationVec &&Locations, LiveOutVec &&LiveOuts)
-        : CSOffsetExpr(CSOffsetExpr), ID(ID), Locations(std::move(Locations)),
-          LiveOuts(std::move(LiveOuts)) {}
+    ArchValues Vals;
+    CallsiteInfo() : Func(nullptr), CSOffsetExpr(nullptr), ID(0) {}
+    CallsiteInfo(const MCSymbol *Func, const MCExpr *CSOffsetExpr,
+                 uint64_t ID, LocationVec &&Locations,
+                 LiveOutVec &&LiveOuts, ArchValues &&Vals)
+        : Func(Func), CSOffsetExpr(CSOffsetExpr), ID(ID),
+          Locations(std::move(Locations)), LiveOuts(std::move(LiveOuts)),
+          Vals(std::move(Vals)) {}
   };
 
   typedef std::vector<CallsiteInfo> CallsiteInfoList;
@@ -213,10 +241,22 @@
   ConstantPool ConstPool;
   FnStackSizeMap FnStackSize;
 
+  /// Get stackmap information for register location
+  void getRegLocation(unsigned Phys, unsigned &Dwarf, unsigned &Offset) const;
+
+  /// Get pointer typing information for stackmap operand
+  void getPointerInfo(const Value *Op, const DataLayout &DL, bool &isPtr,
+                      bool &isAlloca, unsigned &AllocaSize) const;
+
+  /// Add duplicate target-specific locations for a stackmap operand
+  void addDuplicateLocs(const CallInst *StackMap, const Value *Oper,
+                        LocationVec &Locs, unsigned Size, bool Ptr,
+                        bool Alloca, unsigned AllocaSize) const;
+
   MachineInstr::const_mop_iterator
   parseOperand(MachineInstr::const_mop_iterator MOI,
                MachineInstr::const_mop_iterator MOE, LocationVec &Locs,
-               LiveOutVec &LiveOuts) const;
+               LiveOutVec &LiveOuts, User::const_op_iterator &Op) const;
 
   /// \brief Create a live-out register record for the given register @p Reg.
   LiveOutReg createLiveOutReg(unsigned Reg,
@@ -226,6 +266,15 @@
   /// registers that need to be recorded in the stackmap.
   LiveOutVec parseRegisterLiveOutMask(const uint32_t *Mask) const;
 
+  /// Convert a list of instructions used to generate an architecture-specific
+  /// live value into multiple individual records.
+  void genArchValsFromInsts(ArchValues &AV,
+                            Location &Loc,
+                            const MachineLiveVal &MLV);
+
+  /// Add architecture-specific locations for the stackmap.
+  void addArchLiveVals(const CallInst *SM, ArchValues &AV);
+
   /// This should be called by the MC lowering code _immediately_ before
   /// lowering the MI to an MCInst. It records where the operands for the
   /// instruction are stored, and outputs a label to record the offset of
@@ -240,7 +289,7 @@
   void emitStackmapHeader(MCStreamer &OS);
 
   /// \brief Emit the function frame record for each function.
-  void emitFunctionFrameRecords(MCStreamer &OS);
+  void emitFunctionFrameRecords(MCStreamer &OS, const UnwindInfo *UI);
 
   /// \brief Emit the constant pool.
   void emitConstantPoolEntries(MCStreamer &OS);
Index: include/llvm/CodeGen/StackTransformTypes.def
===================================================================
--- include/llvm/CodeGen/StackTransformTypes.def	(nonexistent)
+++ include/llvm/CodeGen/StackTransformTypes.def	(working copy)
@@ -0,0 +1,38 @@
+//===-- llvm/Target/StackTransformTypes.def - Generator Opcodes -*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// Macros which define the set of available instructions for the ISA-agnostic
+// value generator.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_CODEGEN_STACKTRANSFORMTYPES_DEF
+#define LLVM_CODEGEN_STACKTRANSFORMTYPES_DEF
+
+// TODO generate using TableGen rather than X macros
+
+// Each instruction is defined as a mnemonic and a boolean defining if it's a
+// pseudo-instruction (which must be converted to normal instructions after
+// register & stack slot rewriting).
+#define VALUE_GEN_INST \
+  X(Set, false) /* Set the generated value to another value */ \
+  X(Add, false) /* Add a value to the generated value */ \
+  X(Subtract, false) /* Subtract a value from the generated value */ \
+  X(Multiply, false) /* Multiply the generated value by another value */ \
+  X(Divide, false) /* Divide the generated value by another value */ \
+  X(LeftShift, false) /* Left-shift the generated value */ \
+  X(RightShiftLog, false) /* Right-shift (logical) the generated value */ \
+  X(RightShiftArith, false) /* Right-shift (arithmetic) the generated value */ \
+  X(Mask, false) /* Apply bit mask */ \
+  X(Load, false) /* Load value from memory */ \
+  X(StackSlot, true) /* Generate stack slot reference */ \
+  X(ConstantPool, true) /* Generate a constant pool entry reference */
+
+#endif
+
Index: include/llvm/CodeGen/StackTransformTypes.h
===================================================================
--- include/llvm/CodeGen/StackTransformTypes.h	(nonexistent)
+++ include/llvm/CodeGen/StackTransformTypes.h	(working copy)
@@ -0,0 +1,464 @@
+//===------- StackTransformTypes.h - Stack Transform Types ------*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_CODEGEN_STACKTRANFORMTYPES_H
+#define LLVM_CODEGEN_STACKTRANFORMTYPES_H
+
+#include <cstdint>
+#include <map>
+#include <memory>
+#include <string>
+#include "llvm/CodeGen/MachineInstr.h"
+#include "llvm/CodeGen/StackTransformTypes.def"
+
+namespace llvm {
+
+//===----------------------------------------------------------------------===//
+// Machine-specific live values
+//
+
+/// MachineLiveVal - A machine-specific live value
+class MachineLiveVal {
+public:
+  /// Constructors & destructors.  Note: create child class objects rather than
+  /// objects of this class.
+  MachineLiveVal() = delete;
+  virtual ~MachineLiveVal() {}
+  virtual MachineLiveVal *copy() const = 0;
+  virtual bool operator==(const MachineLiveVal &RHS) const = 0;
+
+  /// Possible value types
+  enum Type { None, Reference, Immediate, Generated };
+
+  /// Determine the value's type
+  enum Type getType() const { return Type; }
+  bool isValid() const { return Type == None; }
+  bool isReference() const { return Type == Reference; }
+  bool isImm() const { return Type == Immediate; }
+  bool isGenerated() const { return Type == Generated; }
+
+  /// Generate a human-readable string describing the value
+  virtual std::string toString() const {
+    switch(Type) {
+    case None: return "none";
+    case Reference: return "symbol reference";
+    case Immediate: return "immediate";
+    case Generated: return "generated value";
+    default: return "unknown";
+    }
+  }
+
+  /// Getters/setters for fields
+  const MachineInstr *getDefiningInst() const { return DefMI; }
+  void setDefiningInst(const MachineInstr *DefMI) { this->DefMI = DefMI; }
+
+protected:
+  const enum Type Type;
+  const MachineInstr *DefMI;
+
+  MachineLiveVal(enum Type Type = None, const MachineInstr *DefMI = nullptr)
+    : Type(Type), DefMI(DefMI) {}
+  MachineLiveVal(const MachineLiveVal &C) : Type(C.Type), DefMI(C.DefMI) {}
+};
+
+/// MachineReference - a reference to a symbol
+class MachineReference : public MachineLiveVal {
+public:
+  MachineReference(const std::string &Symbol, const MachineInstr *DefMI)
+    : MachineLiveVal(Reference, DefMI), Symbol(Symbol) {}
+  MachineReference(const MachineReference &C)
+    : MachineLiveVal(C), Symbol(C.Symbol) {}
+
+  virtual MachineLiveVal *copy() const
+  { return new MachineReference(*this); }
+
+  virtual bool operator==(const MachineLiveVal &RHS) const {
+    if(RHS.isReference()) {
+      const MachineReference &MR = (const MachineReference &)RHS;
+      if(MR.Symbol == Symbol) return true;
+    }
+    return false;
+  }
+
+  const std::string &getSymbol() const { return Symbol; }
+  void setSymbol(const std::string &Symbol) { this->Symbol = Symbol; }
+
+  virtual std::string toString() const {
+    std::string Str = MachineLiveVal::toString() + " '" + Symbol + "'";
+    return Str;
+  }
+
+private:
+  // Note: MCSymbols may not exist yet, so instead store symbol name and look
+  // up MCSymbol to generate label at metadata emission time
+  std::string Symbol;
+};
+
+/// MachineImmediate - an immediate value
+class MachineImmediate : public MachineLiveVal {
+public:
+  MachineImmediate(unsigned int Size, uint64_t Value,
+                   const MachineInstr *DefMI)
+    : MachineLiveVal(Immediate, DefMI), Size(Size), Value(Value) {}
+  MachineImmediate(const MachineImmediate &C)
+    : MachineLiveVal(C), Size(C.Size), Value(C.Value) {}
+
+  virtual MachineLiveVal *copy() const
+  { return new MachineImmediate(*this); }
+
+  virtual bool operator==(const MachineLiveVal &RHS) const {
+    if(RHS.isImm()) {
+      const MachineImmediate &MI = (const MachineImmediate &)RHS;
+      if(MI.Size == Size && MI.Value == Value) return true;
+    }
+    return false;
+  }
+
+  virtual std::string toString() const {
+    std::string Str = MachineLiveVal::toString() +
+                      ", value: " + std::to_string(Value);
+    return Str;
+  }
+
+  unsigned getSize() const { return Size; }
+  uint64_t getValue() const { return Value; }
+  void setSize(unsigned Size) { this->Size = Size; }
+  void setValue(uint64_t Value) { this->Value = Value; }
+
+private:
+  unsigned Size; // in bytes
+  uint64_t Value;
+};
+
+#define INV_INST_TYPE "Invalid instruction type"
+
+/// MachineGeneratedVal - a value generated through a set of small operations
+class MachineGeneratedVal : public MachineLiveVal {
+public:
+  class ValueGenInst {
+  public:
+    // Instruction mnemonics or types
+    enum InstType {
+      #define X(type, pseudo) type,
+      VALUE_GEN_INST
+      #undef X
+    };
+
+    // Human-readable instruction names
+    static const char *InstTypeStr[];
+
+    // Is the instruction a pseudo-instruction?  Access using InstType values.
+    static const bool PseudoInst[];
+
+    // Operand types
+    enum OpType { Register, Immediate, None };
+
+    virtual ~ValueGenInst() {}
+    virtual OpType opType() const = 0;
+    virtual InstType type() const = 0;
+    virtual std::string str() const = 0;
+    virtual bool operator==(const ValueGenInst &RHS) const = 0;
+  };
+
+  // Wrap raw pointers to ValueGenInst in smart pointers.  Use shared_ptr so we
+  // can use copy constructors for containers of these instructions.
+  typedef std::shared_ptr<ValueGenInst> ValueGenInstPtr;
+
+  // Base class for register operand instructions
+  class RegInstructionBase : public ValueGenInst {
+  public:
+    // The register used in the instruction
+    // Note: will be converted to DWARF during metadata emission
+    unsigned Reg;
+    int Offset;
+
+    RegInstructionBase(unsigned Reg, int Offset) : Reg(Reg), Offset(Offset) {}
+    virtual OpType opType() const { return Register; }
+    unsigned getReg() const { return Reg; }
+    int getOffset() const { return Offset; }
+    void setReg(unsigned Reg) { this->Reg = Reg; }
+    void setOffset(int Offset) { this->Offset = Offset; }
+  };
+
+  // Register-based instructions
+  template<ValueGenInst::InstType Type>
+  class RegInstruction : public RegInstructionBase {
+    static_assert(Type == Set || Type == Add || Type == Subtract ||
+                  Type == Multiply || Type == Divide || Type == Load,
+                  INV_INST_TYPE " for register instruction");
+  public:
+    RegInstruction(unsigned Reg, int Off) : RegInstructionBase(Reg, Off) {}
+    virtual InstType type() const { return Type; }
+    virtual std::string str() const {
+      std::string buf = std::string(InstTypeStr[Type]) + " register " +
+                        std::to_string(Reg);
+      if(Offset) buf += " offset " + std::to_string(Offset);
+      return buf;
+    }
+
+    virtual bool operator==(const ValueGenInst &RHS) const {
+      if(RHS.type() == Type && RHS.opType() == Register) {
+        const RegInstruction<Type> &RI = (const RegInstruction<Type> &)RHS;
+        if(RI.Reg == Reg) return true;
+      }
+      return false;
+    }
+  };
+
+  // Base class for immediate operand instructions
+  class ImmInstructionBase : public ValueGenInst {
+  public:
+    // The immediate value used in the instruction & its size
+    unsigned Size; // in bytes
+    int64_t Imm;
+
+    ImmInstructionBase(unsigned Size, int64_t Imm) : Size(Size), Imm(Imm) {}
+    virtual OpType opType() const { return Immediate; }
+    unsigned getImmSize() const { return Size; }
+    int64_t getImm() const { return Imm; }
+    void setImm(unsigned Size, int64_t Imm)
+    { this->Size = Size; this->Imm = Imm; }
+  };
+
+  // Immediate-based instructions
+  template<ValueGenInst::InstType Type>
+  class ImmInstruction : public ImmInstructionBase {
+    static_assert(Type != StackSlot,
+                  INV_INST_TYPE " for immediate instruction");
+  public:
+    ImmInstruction(unsigned Size, int64_t Imm)
+      : ImmInstructionBase(Size, Imm) {}
+    virtual InstType type() const { return Type; }
+    virtual std::string str() const {
+      std::string buf = std::string(InstTypeStr[Type]) + " immediate " +
+                        std::to_string(Imm);
+      return buf;
+    }
+
+    virtual bool operator==(const ValueGenInst &RHS) const {
+      if(RHS.type() == Type && RHS.opType() == Immediate) {
+        const ImmInstruction<Type> &II = (const ImmInstruction<Type> &)RHS;
+        if(II.Imm == Imm && II.Size == Size) return true;
+      }
+      return false;
+    }
+  };
+
+  // Base class for pseudo instructions
+  class PseudoInstructionBase : public ValueGenInst {
+  public:
+    // Whatever data is needed and the operation to be implemented after
+    // rewriting the pseudo-instruction
+    uint64_t Data;
+    InstType GenType;
+
+    PseudoInstructionBase(uint64_t Data, InstType GenType)
+      : Data(Data), GenType(GenType) {}
+    virtual OpType opType() const { return None; }
+    uint64_t getData() const { return Data; }
+    InstType getGenType() const { return GenType; }
+    void setData(uint64_t Data) { this->Data = Data; }
+    void setGenType(InstType GenType) { this->GenType = GenType; }
+  };
+
+  // Pseudo-instructions which must be converted to normal instructions later
+  template<ValueGenInst::InstType Type>
+  class PseudoInstruction : public PseudoInstructionBase {
+    static_assert(Type == StackSlot || Type == ConstantPool,
+                  INV_INST_TYPE " for pseudo-instruction");
+  public:
+    PseudoInstruction(uint64_t Data, InstType GenType)
+      : PseudoInstructionBase(Data, GenType) {}
+    virtual InstType type() const { return Type; }
+    virtual std::string str() const {
+      std::string buf = std::string(InstTypeStr[Type]) + " (" +
+                        std::to_string(Data) + ")";
+      return buf;
+    }
+
+    virtual bool operator==(const ValueGenInst &RHS) const {
+      if(RHS.type() == Type) {
+        const PseudoInstruction<Type> &PI =
+          (const PseudoInstruction<Type> &)RHS;
+        if(PI.Data == Data) return true;
+      }
+      return false;
+    }
+  };
+
+  // A list of instructions used to generate a value
+  typedef std::vector<ValueGenInstPtr> ValueGenInstList;
+
+  MachineGeneratedVal(const ValueGenInstList &VG, const MachineInstr *DefMI)
+    : MachineLiveVal(Generated, DefMI), VG(VG) {}
+
+  virtual MachineLiveVal *copy() const
+  { return new MachineGeneratedVal(*this); }
+
+  virtual bool operator==(const MachineLiveVal &RHS) const {
+    if(!RHS.isGenerated()) return false;
+    const MachineGeneratedVal &MGV = (const MachineGeneratedVal &)RHS;
+
+    if(VG.size() != MGV.VG.size()) return false;
+    for(size_t i = 0, num = VG.size(); i < num; i++)
+      if(VG[i] != MGV.VG[i]) return false;
+    return true;
+  }
+
+  ValueGenInstList &getInstructions() { return VG; }
+  const ValueGenInstList &getInstructions() const { return VG; }
+
+  virtual std::string toString() const {
+    std::string buf = MachineLiveVal::toString() + ", " +
+                      std::to_string(VG.size()) + " instruction(s)";
+    return buf;
+  }
+
+private:
+  ValueGenInstList VG;
+};
+
+#undef INV_INST_TYPE
+
+//===----------------------------------------------------------------------===//
+// Machine-specific locations
+//
+
+/// MachineLiveLoc - an architecture-specific location for a live value
+class MachineLiveLoc {
+public:
+  /// Constructors & destructors.  Note: create child class objects rather than
+  /// objects of this class.
+  MachineLiveLoc() = delete;
+  virtual ~MachineLiveLoc() {}
+  virtual MachineLiveLoc *copy() const = 0;
+  virtual bool operator==(const MachineLiveLoc &R) const = 0;
+
+  /// Possible types of live value's storage location
+  enum Type { None, Register, StackSlot };
+
+  /// Determine the live value location type
+  bool isValid() const { return Type == None; }
+  bool isReg() const { return Type == Register; }
+  bool isStackSlot() const { return Type == StackSlot; }
+
+  virtual std::string toString() const {
+    switch(Type) {
+    case None: return "none";
+    case Register: return "register";
+    case StackSlot: return "stack slot";
+    default: return "unknown";
+    }
+  }
+
+protected:
+  /// Types & attributes
+  enum Type Type;
+
+  MachineLiveLoc(enum Type Type = None) : Type(Type){}
+  MachineLiveLoc(const MachineLiveLoc &M) : Type(M.Type) {}
+};
+
+/// MachineLiveReg - a live value stored in a register.  Stores the register
+/// number as an architecture-specific physical register.
+class MachineLiveReg : public MachineLiveLoc {
+public:
+  MachineLiveReg(unsigned Reg = UINT32_MAX)
+    : MachineLiveLoc(MachineLiveLoc::Register), Reg(Reg) {}
+  MachineLiveReg(const MachineLiveReg &M) : MachineLiveLoc(M), Reg(M.Reg) {}
+
+  virtual MachineLiveLoc *copy() const
+  { return new MachineLiveReg(*this); }
+
+  virtual bool operator==(const MachineLiveLoc &R) const {
+    if(R.isReg()) {
+      const MachineLiveReg &RLV = (const MachineLiveReg &)R;
+      if(Reg == RLV.Reg) return true;
+    }
+    return false;
+  }
+
+  unsigned getReg() const { return Reg; }
+  void setReg(unsigned Reg) { this->Reg = Reg; }
+
+  virtual std::string toString() const {
+    return MachineLiveLoc::toString() + " " + std::to_string(Reg);
+  };
+
+private:
+  unsigned Reg;
+};
+
+/// MachineLiveStackSlot - a live value stored in a stack slot
+class MachineLiveStackSlot : public MachineLiveLoc {
+public:
+  MachineLiveStackSlot(int StackSlot = INT32_MIN)
+    : MachineLiveLoc(MachineLiveLoc::StackSlot), StackSlot(StackSlot) {}
+  MachineLiveStackSlot(const MachineLiveStackSlot &M)
+    : MachineLiveLoc(M), StackSlot(M.StackSlot) {}
+
+  virtual MachineLiveLoc *copy() const
+  { return new MachineLiveStackSlot(*this); }
+
+  virtual bool operator==(const MachineLiveLoc &R) const {
+    if(R.isStackSlot()) {
+      const MachineLiveStackSlot &SLV = (const MachineLiveStackSlot &)R;
+      if(StackSlot == SLV.StackSlot) return true;
+    }
+    return false;
+  }
+
+  unsigned getStackSlot() const { return StackSlot; }
+  void setStackSlot(int StackSlot) { this->StackSlot = StackSlot; }
+
+  virtual std::string toString() const {
+    return MachineLiveLoc::toString() + " " + std::to_string(StackSlot);
+  };
+
+private:
+  int StackSlot;
+};
+
+/// Useful typedefs for data structures needed to store additional stack
+/// transformation metadata not captured in the stackmap instructions.
+
+// Tidy up objects defined above into smart pointers
+typedef std::unique_ptr<MachineLiveVal> MachineLiveValPtr;
+typedef std::unique_ptr<MachineLiveLoc> MachineLiveLocPtr;
+
+// A wrapper & vector of architecture-specific live value locations
+// Note: we could use a set instead (because we want unique live values), but
+// because we're using MachineLiveLoc pointers the set would only uniquify
+// based on the pointer, not the pointed-to value.
+typedef SmallVector<MachineLiveLocPtr, 4> MachineLiveLocs;
+
+// Map IR value to a list of architecture-specific live value locations.
+// Usually used to store duplicate locations for an IR value.
+typedef std::map<const Value *, MachineLiveLocs> IRToMachineLocs;
+typedef std::pair<const Value *, MachineLiveLocs> IRMachineLocPair;
+
+// Map an IR instruction to the metadata about its IR operands (and their
+// associated architecture-specific live values locations).
+typedef std::map<const Instruction *, IRToMachineLocs> InstToOperands;
+typedef std::pair<const Instruction *, IRToMachineLocs> InstOperandPair;
+
+// Architecture-specific live values are more complicated because we have to
+// store the live value in addition to the location.  A pair and vector for
+// encapsulating instances of architecture-specific live values.
+typedef std::pair<MachineLiveLocPtr, MachineLiveValPtr> ArchLiveValue;
+typedef SmallVector<ArchLiveValue, 8> ArchLiveValues;
+
+// Map an IR instruction to architecture-specific live values
+typedef std::map<const Instruction *, ArchLiveValues> InstToArchLiveValues;
+typedef std::pair<const Instruction *, ArchLiveValues> InstArchLiveValuePair;
+
+}
+
+#endif
+
Index: include/llvm/CodeGen/UnwindInfo.h
===================================================================
--- include/llvm/CodeGen/UnwindInfo.h	(nonexistent)
+++ include/llvm/CodeGen/UnwindInfo.h	(working copy)
@@ -0,0 +1,112 @@
+//===----------------- UnwindInfo.h - UnwindInfo ---------------*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// Generate unwinding information for stack transformation runtime.  Note that
+// this is implemented assuming the function uses a frame base pointer (FBP).
+// This requirement is guaranteed to be satisfied if the function has a
+// stackmap, which are the only functions for which we want to generate
+// unwinding information.
+//
+//===---------------------------------------------------------------------===//
+
+#ifndef LLVM_CODEGEN_UNWINDINFO_H
+#define LLVM_CODEGEN_UNWINDINFO_H
+
+#include "llvm/CodeGen/AsmPrinter.h"
+#include "llvm/CodeGen/MachineFrameInfo.h"
+#include "llvm/CodeGen/MachineFunction.h"
+#include "llvm/MC/MCContext.h"
+#include "llvm/MC/MCStreamer.h"
+#include "llvm/Support/Debug.h"
+#include <map>
+
+namespace llvm {
+
+class UnwindInfo {
+public:
+  /// Per-function unwinding metadata classes & typedefs
+  class FuncUnwindInfo {
+  public:
+    uint32_t SecOffset; // Offset into unwinding record section
+    uint32_t NumUnwindRecord; // Number of unwinding records
+
+    FuncUnwindInfo() : SecOffset(UINT32_MAX), NumUnwindRecord(0) {}
+    FuncUnwindInfo(uint32_t SecOffset, uint32_t NumUnwindRecord)
+      : SecOffset(SecOffset), NumUnwindRecord(NumUnwindRecord) {}
+  };
+
+  typedef std::pair<const MCSymbol *, FuncUnwindInfo> FuncUnwindPair;
+  typedef std::map<const MCSymbol *, FuncUnwindInfo> FuncUnwindMap;
+
+  /// Unwinding record classes & typedefs
+  class RegOffset {
+  public:
+    uint32_t DwarfReg;
+    int32_t Offset;
+
+    RegOffset() : DwarfReg(0), Offset(0) {}
+    RegOffset(uint32_t DwarfReg, int32_t Offset) :
+      DwarfReg(DwarfReg), Offset(Offset) {}
+  };
+
+  typedef SmallVector<RegOffset, 32> CalleeSavedRegisters;
+  typedef std::pair<const MCSymbol *, CalleeSavedRegisters> FuncCalleePair;
+  typedef std::map<const MCSymbol *, CalleeSavedRegisters> FuncCalleeMap;
+
+  /// \brief Constructors
+  UnwindInfo() = delete;
+  UnwindInfo(AsmPrinter &AP)
+    : AP(AP), OutContext(AP.OutStreamer->getContext()), Emitted(false) {};
+
+  /// \bried Clear all saved unwinding information
+  void reset() {
+    Emitted = false;
+    FuncCalleeSaved.clear();
+    FuncUnwindMetadata.clear();
+  }
+
+  /// \brief Store unwinding information for a function
+  void recordUnwindInfo(const MachineFunction &MF);
+
+  /// \brief Add a register restore offset for a function.  MachineReg will get
+  /// converted to a DWARF register internally.
+  void addRegisterUnwindInfo(const MachineFunction &MF,
+                             uint32_t MachineReg,
+                             int32_t Offset);
+
+  /// Create an unwinding information section and serialize the map info into
+  /// it.
+  ///
+  /// Note: unlike StackMaps::serializeToStackMapSection, this function *does
+  /// not* clear out the data structures.  This is so that the stack map
+  /// machinery can access per-function unwinding information.
+  void serializeToUnwindInfoSection();
+
+  /// Get unwinding section metadata for a function
+  const FuncUnwindInfo &getUnwindInfo(const MCSymbol *Func) const;
+
+private:
+  AsmPrinter &AP;
+  MCContext &OutContext;
+  FuncCalleeMap FuncCalleeSaved;
+  FuncUnwindMap FuncUnwindMetadata;
+  bool Emitted;
+
+  /// \brief Emit the unwind info for each function.
+  void emitUnwindInfo(MCStreamer &OS);
+
+  /// \brief Emit the address range info for each function.
+  void emitAddrRangeInfo(MCStreamer &OS);
+
+  void print(raw_ostream &OS);
+  void debug() { print(dbgs()); }
+};
+}
+
+#endif
Index: include/llvm/InitializePasses.h
===================================================================
--- include/llvm/InitializePasses.h	(revision 277823)
+++ include/llvm/InitializePasses.h	(working copy)
@@ -146,6 +146,7 @@
 void initializeInductiveRangeCheckEliminationPass(PassRegistry&);
 void initializeIndVarSimplifyPass(PassRegistry&);
 void initializeInlineCostAnalysisPass(PassRegistry&);
+void initializeInsertStackMapsPass(PassRegistry&);
 void initializeInstructionCombiningPassPass(PassRegistry&);
 void initializeInstCountPass(PassRegistry&);
 void initializeInstNamerPass(PassRegistry&);
@@ -153,6 +154,7 @@
 void initializeIntervalPartitionPass(PassRegistry&);
 void initializeJumpThreadingPass(PassRegistry&);
 void initializeLCSSAPass(PassRegistry&);
+void initializeLibcStackMapsPass(PassRegistry&);
 void initializeLICMPass(PassRegistry&);
 void initializeLazyValueInfoPass(PassRegistry&);
 void initializeLibCallAliasAnalysisPass(PassRegistry&);
@@ -162,6 +164,7 @@
 void initializeLiveRegMatrixPass(PassRegistry&);
 void initializeLiveStacksPass(PassRegistry&);
 void initializeLiveVariablesPass(PassRegistry&);
+void initializeLiveValuesPass(PassRegistry&);
 void initializeLoaderPassPass(PassRegistry&);
 void initializeLocalStackSlotPassPass(PassRegistry&);
 void initializeLoopDeletionPass(PassRegistry&);
@@ -208,6 +211,7 @@
 void initializeMetaRenamerPass(PassRegistry&);
 void initializeMergeFunctionsPass(PassRegistry&);
 void initializeModuleDebugInfoPrinterPass(PassRegistry&);
+void initializeNameStringLiteralsPass(PassRegistry&);
 void initializeNaryReassociatePass(PassRegistry&);
 void initializeNoAAPass(PassRegistry&);
 void initializeObjCARCAliasAnalysisPass(PassRegistry&);
@@ -252,7 +256,8 @@
 void initializeScalarEvolutionPass(PassRegistry&);
 void initializeShrinkWrapPass(PassRegistry &);
 void initializeSimpleInlinerPass(PassRegistry&);
-void initializeShadowStackGCLoweringPass(PassRegistry&);  
+void initializeShadowStackGCLoweringPass(PassRegistry&);
+void initializeStaticVarSectionsPass(PassRegistry&);
 void initializeRegisterCoalescerPass(PassRegistry&);
 void initializeSingleLoopExtractorPass(PassRegistry&);
 void initializeSinkingPass(PassRegistry&);
@@ -263,6 +268,7 @@
 void initializeStackProtectorPass(PassRegistry&);
 void initializeStackColoringPass(PassRegistry&);
 void initializeStackSlotColoringPass(PassRegistry&);
+void initializeStackTransformMetadataPass(PassRegistry&);
 void initializeStraightLineStrengthReducePass(PassRegistry &);
 void initializeStripDeadDebugInfoPass(PassRegistry&);
 void initializeStripDeadPrototypesPassPass(PassRegistry&);
Index: include/llvm/LinkAllPasses.h
===================================================================
--- include/llvm/LinkAllPasses.h	(revision 277823)
+++ include/llvm/LinkAllPasses.h	(working copy)
@@ -33,6 +33,7 @@
 #include "llvm/Transforms/Instrumentation.h"
 #include "llvm/Transforms/ObjCARC.h"
 #include "llvm/Transforms/Scalar.h"
+#include "llvm/Transforms/Utils.h"
 #include "llvm/Transforms/Utils/SymbolRewriter.h"
 #include "llvm/Transforms/Utils/UnifyFunctionExitNodes.h"
 #include "llvm/Transforms/Vectorize.h"
@@ -92,11 +93,14 @@
       (void) llvm::createIPSCCPPass();
       (void) llvm::createInductiveRangeCheckEliminationPass();
       (void) llvm::createIndVarSimplifyPass();
+      (void) llvm::createInsertStackMapsPass();
       (void) llvm::createInstructionCombiningPass();
       (void) llvm::createInternalizePass();
       (void) llvm::createLCSSAPass();
+      (void) llvm::createLibcStackMapsPass();
       (void) llvm::createLICMPass();
       (void) llvm::createLazyValueInfoPass();
+      (void) llvm::createLiveValuesPass();
       (void) llvm::createLoopExtractorPass();
       (void) llvm::createLoopInterchangePass();
       (void) llvm::createLoopSimplifyPass();
@@ -110,6 +114,7 @@
       (void) llvm::createLowerInvokePass();
       (void) llvm::createLowerSwitchPass();
       (void) llvm::createNaryReassociatePass();
+      (void) llvm::createNameStringLiteralsPass();
       (void) llvm::createNoAAPass();
       (void) llvm::createObjCARCAliasAnalysisPass();
       (void) llvm::createObjCARCAPElimPass();
@@ -134,6 +139,7 @@
       (void) llvm::createSafeStackPass();
       (void) llvm::createScalarReplAggregatesPass();
       (void) llvm::createSingleLoopExtractorPass();
+      (void) llvm::createStaticVarSectionsPass();
       (void) llvm::createStripSymbolsPass();
       (void) llvm::createStripNonDebugSymbolsPass();
       (void) llvm::createStripDeadDebugInfoPass();
Index: include/llvm/MC/MCCodeGenInfo.h
===================================================================
--- include/llvm/MC/MCCodeGenInfo.h	(revision 277823)
+++ include/llvm/MC/MCCodeGenInfo.h	(working copy)
@@ -32,6 +32,19 @@
   ///
   CodeGenOpt::Level OptLevel;
 
+  /// ArchIROptLevel - Optimization level (architecture-specific IR
+  /// optimizations only).
+  ///
+  CodeGenOpt::Level ArchIROptLevel;
+
+  /// EmitStackTransformMetadata - Flag for emitting stack transformation
+  /// metadata
+  bool EmitStackTransformMetadata;
+
+  /// EmitLibcTransformMetadata - Flag for emitting transformation metadata
+  /// for libc thread start routines
+  bool EmitLibcTransformMetadata;
+
 public:
   void initMCCodeGenInfo(Reloc::Model RM = Reloc::Default,
                          CodeModel::Model CM = CodeModel::Default,
@@ -43,8 +56,23 @@
 
   CodeGenOpt::Level getOptLevel() const { return OptLevel; }
 
+  CodeGenOpt::Level getArchIROptLevel() const { return ArchIROptLevel; }
+
+  bool emitStackTransformMetadata() const
+  { return EmitStackTransformMetadata; }
+
+  bool emitLibcTransformMetadata() const { return EmitLibcTransformMetadata; }
+
   // Allow overriding OptLevel on a per-function basis.
   void setOptLevel(CodeGenOpt::Level Level) { OptLevel = Level; }
+
+  void setArchIROptLevel(CodeGenOpt::Level Level) { ArchIROptLevel = Level; }
+
+  void setEmitStackTransformMetadata(bool Emit)
+  { EmitStackTransformMetadata = Emit; }
+
+  void setEmitLibcTransformMetadata(bool Emit)
+  { EmitLibcTransformMetadata = Emit; }
 };
 } // namespace llvm
 
Index: include/llvm/MC/MCObjectFileInfo.h
===================================================================
--- include/llvm/MC/MCObjectFileInfo.h	(revision 277823)
+++ include/llvm/MC/MCObjectFileInfo.h	(working copy)
@@ -135,6 +135,10 @@
   /// Null if this target doesn't support a BSS section. ELF and MachO only.
   MCSection *TLSBSSSection; // Defaults to ".tbss".
 
+  /// Unwinding address ranges & register location sections.
+  MCSection *UnwindAddrRangeSection;
+  MCSection *UnwindInfoSection;
+
   /// StackMap section.
   MCSection *StackMapSection;
 
@@ -267,6 +271,8 @@
   const MCSection *getTLSDataSection() const { return TLSDataSection; }
   MCSection *getTLSBSSSection() const { return TLSBSSSection; }
 
+  MCSection *getUnwindInfoSection() const { return UnwindInfoSection; }
+  MCSection *getUnwindAddrRangeSection() const { return UnwindAddrRangeSection; }
   MCSection *getStackMapSection() const { return StackMapSection; }
   MCSection *getFaultMapSection() const { return FaultMapSection; }
 
Index: include/llvm/Target/TargetMachine.h
===================================================================
--- include/llvm/Target/TargetMachine.h	(revision 277823)
+++ include/llvm/Target/TargetMachine.h	(working copy)
@@ -171,6 +171,26 @@
   /// \brief Overrides the optimization level.
   void setOptLevel(CodeGenOpt::Level Level) const;
 
+  /// Returns the architecture-specific IR optimization level: None, Less,
+  /// Default or Aggressive.
+  CodeGenOpt::Level getArchIROptLevel() const;
+
+  /// \brief Overrides the architecture-specific IR optimization level.
+  void setArchIROptLevel(CodeGenOpt::Level Level) const;
+
+  /// Returns whether or not we should emit stack transformation metadata
+  bool emitStackTransformMetadata() const;
+
+  /// \brief Enable/disable emitting of stack transformation metadata
+  void setEmitStackTransformMetadata(bool Emit);
+
+  /// Returns whether or not we should emit transformation metadata for libc
+  /// thread start functions
+  bool emitLibcTransformMetadata() const;
+
+  /// \brief Enable/disable emitting of libc thread start function metadata
+  void setEmitLibcTransformMetadata(bool Emit);
+
   void setFastISel(bool Enable) { Options.EnableFastISel = Enable; }
 
   bool shouldPrintMachineCode() const { return Options.PrintMachineCode; }
Index: include/llvm/Target/TargetSubtargetInfo.h
===================================================================
--- include/llvm/Target/TargetSubtargetInfo.h	(revision 277823)
+++ include/llvm/Target/TargetSubtargetInfo.h	(working copy)
@@ -32,6 +32,7 @@
 class TargetRegisterInfo;
 class TargetSchedModel;
 class TargetSelectionDAGInfo;
+class TargetValues;
 struct MachineSchedPolicy;
 template <typename T> class SmallVectorImpl;
 
@@ -95,6 +96,13 @@
     return nullptr;
   }
 
+  /// getValues - Returns the value generator object for the target or specific
+  /// subtarget
+  ///
+  virtual const TargetValues *getValues() const {
+    return nullptr;
+  };
+
   /// Resolve a SchedClass at runtime, where SchedClass identifies an
   /// MCSchedClassDesc with the isVariant property. This may return the ID of
   /// another variant SchedClass, but repeated invocation must quickly terminate
Index: include/llvm/Target/TargetValues.h
===================================================================
--- include/llvm/Target/TargetValues.h	(nonexistent)
+++ include/llvm/Target/TargetValues.h	(working copy)
@@ -0,0 +1,44 @@
+//===----- llvm/Target/TargetValues.h - Value Properties ----*- C++ -----*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file provides an API for detecting properties of architecture-specific
+// values & for generating a series of simple metadata instructions for
+// reconstituting a value.  This is used by the stack transformation runtime to
+// set up architecture-specific live values.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_TARGET_TARGETVAL_H
+#define LLVM_TARGET_TARGETVAL_H
+
+#include "llvm/CodeGen/StackTransformTypes.h"
+
+namespace llvm {
+
+//===----------------------------------------------------------------------===//
+// Superclass for ISA-specific values
+//
+
+class TargetValues {
+public:
+  TargetValues(const TargetValues &) = delete;
+  void operator=(const TargetValues &) = delete;
+  virtual ~TargetValues() {};
+
+  /// Return a machine-specific value generated by a machine instruction.
+  virtual MachineLiveValPtr getMachineValue(const MachineInstr *MI) const = 0;
+
+protected:
+  TargetValues() {}
+};
+
+} // End llvm namespace
+
+#endif
+
Index: include/llvm/Transforms/Instrumentation.h
===================================================================
--- include/llvm/Transforms/Instrumentation.h	(revision 277823)
+++ include/llvm/Transforms/Instrumentation.h	(working copy)
@@ -136,6 +136,14 @@
 /// protect against stack-based overflow vulnerabilities.
 FunctionPass *createSafeStackPass();
 
+/// \brief This pass inserts stack map intrinsics at equivalence points in
+/// order to record live value locations
+ModulePass *createInsertStackMapsPass();
+
+/// \brief This pass inserts stack map intrinsics similarly to InsertStackMaps,
+/// but only in thread start functions inside of libc
+ModulePass *createLibcStackMapsPass();
+
 } // End llvm namespace
 
 #endif
Index: include/llvm/Transforms/Utils.h
===================================================================
--- include/llvm/Transforms/Utils.h	(nonexistent)
+++ include/llvm/Transforms/Utils.h	(working copy)
@@ -0,0 +1,16 @@
+namespace llvm {
+
+//===----------------------------------------------------------------------===//
+//
+// NameStringLiterals - Give symbol names to anonymous string literals so they
+// can be aligned at link-time
+//
+ModulePass *createNameStringLiteralsPass();
+
+//===----------------------------------------------------------------------===//
+//
+// StaticVarSections - Put static global variables into their own sections
+//
+ModulePass *createStaticVarSectionsPass();
+
+}
Index: lib/Analysis/Analysis.cpp
===================================================================
--- lib/Analysis/Analysis.cpp	(revision 277823)
+++ lib/Analysis/Analysis.cpp	(working copy)
@@ -53,6 +53,7 @@
   initializeLazyValueInfoPass(Registry);
   initializeLibCallAliasAnalysisPass(Registry);
   initializeLintPass(Registry);
+  initializeLiveValuesPass(Registry);
   initializeLoopInfoWrapperPassPass(Registry);
   initializeMemDepPrinterPass(Registry);
   initializeMemDerefPrinterPass(Registry);
Index: lib/Analysis/CMakeLists.txt
===================================================================
--- lib/Analysis/CMakeLists.txt	(revision 277823)
+++ lib/Analysis/CMakeLists.txt	(working copy)
@@ -34,9 +34,11 @@
   LibCallAliasAnalysis.cpp
   LibCallSemantics.cpp
   Lint.cpp
+  LiveValues.cpp
   Loads.cpp
   LoopAccessAnalysis.cpp
   LoopInfo.cpp
+  LoopNestingTree.cpp
   LoopPass.cpp
   MemDepPrinter.cpp
   MemDerefPrinter.cpp
Index: lib/Analysis/LiveValues.cpp
===================================================================
--- lib/Analysis/LiveValues.cpp	(nonexistent)
+++ lib/Analysis/LiveValues.cpp	(working copy)
@@ -0,0 +1,374 @@
+#include "llvm/Analysis/LiveValues.h"
+#include "llvm/IR/Metadata.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/CFG.h"
+#include "llvm/Analysis/CFG.h"
+#include "llvm/Analysis/LoopInfo.h"
+#include "llvm/ADT/PostOrderIterator.h"
+#include "llvm/ADT/SCCIterator.h"
+#include "llvm/Support/Debug.h"
+
+#define DEBUG_TYPE "live-values"
+
+using namespace llvm;
+
+char LiveValues::ID = 0;
+INITIALIZE_PASS_BEGIN(LiveValues, "live-values", 
+                    "Live-value set calculation", true, true)
+INITIALIZE_PASS_DEPENDENCY(LoopInfoWrapperPass)
+INITIALIZE_PASS_END(LiveValues, "live-values", 
+                    "Live-value set calculation", true, true)
+
+namespace llvm {
+  FunctionPass *createLiveValuesPass() { return new LiveValues(); }
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// Public API
+///////////////////////////////////////////////////////////////////////////////
+
+LiveValues::LiveValues(void)
+  : FunctionPass(ID), inlineasm(false), bitcasts(false), comparisons(true),
+    constants(false), metadata(false) {}
+
+void LiveValues::getAnalysisUsage(AnalysisUsage &AU) const
+{
+  AU.addRequired<LoopInfoWrapperPass>();
+  AU.setPreservesAll();
+}
+
+bool LiveValues::runOnFunction(Function &F)
+{
+  if(FuncBBLiveIn.count(&F))
+  {
+    DEBUG(
+      errs() << "\nFound previous analysis for " << F.getName() << "\n\n";
+      print(errs(), &F);
+    );
+  }
+  else
+  {
+    DEBUG(errs() << "\n********** Beginning LiveValues **********\n"
+                 << "********** Function: " << F.getName() << " **********\n\n"
+                    "LiveValues: performing bottom-up dataflow analysis\n");
+
+    LoopNestingForest LNF;
+    FuncBBLiveIn.emplace(&F, LiveVals());
+    FuncBBLiveOut.emplace(&F, LiveVals());
+
+    /* 1. Compute partial liveness sets using a postorder traversal. */
+    dagDFS(F, FuncBBLiveIn[&F], FuncBBLiveOut[&F]);
+
+    DEBUG(errs() << "LiveValues: constructing loop-nesting forest\n");
+
+    /* 2. Construct loop-nesting forest. */
+    constructLoopNestingForest(F, LNF);
+
+    DEBUG(errs() << "LiveValues: propagating values within loop-nests\n");
+
+    /* 3. Propagate live variables within loop bodies. */
+    loopTreeDFS(LNF, FuncBBLiveIn[&F], FuncBBLiveOut[&F]);
+
+    DEBUG(
+      print(errs(), &F);
+      errs() << "LiveValues: finished analysis\n"
+    );
+  }
+
+  return false;
+}
+
+void
+LiveValues::print(raw_ostream &O, const Function *F) const
+{
+  LiveVals::const_iterator bbIt;
+  std::set<const Value *>::const_iterator valIt;
+  const Module *M = F->getParent();
+
+  O << "LiveValues: results of live-value analysis\n";
+
+  if(!FuncBBLiveIn.count(F) || !FuncBBLiveOut.count(F))
+  {
+    if(F->hasName())
+      O << "No liveness information for function " << F->getName() << "\n";
+    else
+      O << "No liveness information for requested function\n";
+  }
+  else
+  {
+    for(bbIt = FuncBBLiveIn.at(F).cbegin();
+        bbIt != FuncBBLiveIn.at(F).cend();
+        bbIt++)
+    {
+      const BasicBlock *bb = bbIt->first;
+      const std::set<const Value *> &liveInVals = bbIt->second;
+      const std::set<const Value *> &liveOutVals = FuncBBLiveOut.at(F).at(bb);
+
+      bb->printAsOperand(O, false, M);
+      O << "\n  Live-in:\n    ";
+      for(valIt = liveInVals.cbegin(); valIt != liveInVals.cend(); valIt++)
+      {
+        (*valIt)->printAsOperand(O, false, M);
+        O << " ";
+      }
+
+      O << "\n  Live-out:\n    ";
+      for(valIt = liveOutVals.cbegin(); valIt != liveOutVals.cend(); valIt++)
+      {
+        (*valIt)->printAsOperand(O, false, M);
+        O << " ";
+      }
+
+      O << "\n";
+    }
+  }
+}
+
+std::set<const Value *> *LiveValues::getLiveIn(const BasicBlock *BB) const
+{
+  const Function *F = BB->getParent();
+  return new std::set<const Value *>(FuncBBLiveIn.at(F).at(BB));
+}
+
+std::set<const Value *> *LiveValues::getLiveOut(const BasicBlock *BB) const
+{
+  const Function *F = BB->getParent();
+  return new std::set<const Value *>(FuncBBLiveOut.at(F).at(BB));
+}
+
+std::set<const Value *>
+*LiveValues::getLiveValues(const Instruction *inst) const
+{
+  const BasicBlock *BB = inst->getParent();
+  const Function *F = BB->getParent();
+  BasicBlock::const_reverse_iterator ri, rie;
+  std::set<const Value *> *live =
+    new std::set<const Value *>(FuncBBLiveOut.at(F).at(BB));
+
+  for(ri = BB->rbegin(), rie = BB->rend(); ri != rie; ri++)
+  {
+    if(&*ri == inst) break;
+
+    live->erase(&*ri);
+    for(User::const_op_iterator op = ri->op_begin();
+        op != ri->op_end();
+        op++)
+      if(includeVal(*op))
+        live->insert(*op);
+  }
+  live->erase(&*ri);
+
+  return live;
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// Private API
+///////////////////////////////////////////////////////////////////////////////
+
+bool LiveValues::includeVal(const llvm::Value *val) const
+{
+  bool include = true;
+
+  // TODO other values that should be filtered out?
+  if(isa<BasicBlock>(val))
+    include = false;
+  else if(isa<InlineAsm>(val) && !inlineasm)
+    include = false;
+  else if(isa<BitCastInst>(val) && !bitcasts)
+    include = false;
+  else if(isa<CmpInst>(val) && !comparisons)
+    include = false;
+  else if(isa<Constant>(val) && !constants)
+    include = false;
+  else if(isa<MetadataAsValue>(val) && !metadata)
+    include = false;
+
+  return include;
+}
+
+unsigned LiveValues::phiUses(const BasicBlock *B,
+                             const BasicBlock *S,
+                             std::set<const Value *> &uses)
+{
+  const PHINode *phi;
+  unsigned added = 0;
+
+  for(BasicBlock::const_iterator it = S->begin(); it != S->end(); it++)
+  {
+    if((phi = dyn_cast<PHINode>(&*it))) {
+      for(unsigned i = 0; i < phi->getNumIncomingValues(); i++)
+        if(phi->getIncomingBlock(i) == B &&
+           includeVal(phi->getIncomingValue(i)))
+          if(uses.insert(phi->getIncomingValue(i)).second)
+            added++;
+    }
+    else break; // phi-nodes are always at the start of the basic block
+  }
+
+  return added;
+}
+
+unsigned LiveValues::phiDefs(const BasicBlock *B,
+                             std::set<const Value *> &uses)
+{
+  const PHINode *phi;
+  unsigned added = 0;
+
+  for(BasicBlock::const_iterator it = B->begin(); it != B->end(); it++)
+  {
+    if((phi = dyn_cast<PHINode>(&*it))) {
+      if(includeVal(phi))
+        if(uses.insert(&*it).second)
+          added++;
+    }
+    else break; // phi-nodes are always at the start of the basic block
+  }
+
+  return added;
+}
+
+void LiveValues::dagDFS(Function &F, LiveVals &liveIn, LiveVals &liveOut)
+{
+  std::set<const Value *> live, phiDefined;
+  std::set<Edge> loopEdges;
+  SmallVector<Edge, 16> loopEdgeVec;
+
+  /* Find loop edges & convert to set for existence checking. */
+  FindFunctionBackedges(F, loopEdgeVec);
+  for(SmallVectorImpl<Edge>::const_iterator eit = loopEdgeVec.begin();
+      eit != loopEdgeVec.end();
+      eit++)
+    loopEdges.insert(*eit);
+
+  /* Calculate partial liveness sets for CFG nodes. */
+  for(auto B = po_iterator<const BasicBlock *>::begin(&F.getEntryBlock());
+      B != po_iterator<const BasicBlock *>::end(&F.getEntryBlock());
+      B++)
+  {
+    /* Calculate live-out set (lines 4-7 of Algorithm 2). */
+    for(succ_const_iterator S = succ_begin(*B); S != succ_end(*B); S++)
+    {
+      // Note: skip self-loop-edges, as adding values from phi-uses of this
+      // block causes use-def violations, and LLVM will complain.  This
+      // shouldn't matter, as phi-defs will cover this case.
+      if(*S == *B) continue;
+
+      phiUses(*B, *S, live);
+      if(!loopEdges.count(Edge(*B, *S)))
+      {
+        phiDefs(*S, phiDefined);
+        for(std::set<const Value *>::const_iterator vi = liveIn[*S].begin();
+            vi != liveIn[*S].end();
+            vi++)
+          if(!phiDefined.count(*vi) && includeVal(*vi)) live.insert(*vi);
+        phiDefined.clear();
+      }
+    }
+    liveOut.insert(LiveValsPair(*B, std::set<const Value *>(live)));
+
+    /* Calculate live-in set (lines 8-11 of Algorithm 2). */
+    for(BasicBlock::const_reverse_iterator inst = (*B)->rbegin();
+        inst != (*B)->rend();
+        inst++)
+    {
+      if(isa<PHINode>(&*inst)) break;
+
+      live.erase(&*inst);
+      for(User::const_op_iterator op = inst->op_begin();
+          op != inst->op_end();
+          op++)
+        if(includeVal(*op)) live.insert(*op);
+    }
+    phiDefs(*B, live);
+    liveIn.insert(LiveValsPair(*B, std::set<const Value *>(live)));
+
+    live.clear();
+
+    DEBUG(
+      errs() << "  ";
+      (*B)->printAsOperand(errs(), false);
+      errs() << ":\n";
+      errs() << "    Live-in:\n      ";
+      std::set<const Value *>::const_iterator it;
+      for(it = liveIn[*B].begin(); it != liveIn[*B].end(); it++)
+      {
+        (*it)->printAsOperand(errs(), false);
+        errs() << " ";
+      }
+      errs() << "\n    Live-out:\n      ";
+      for(it = liveOut[*B].begin(); it != liveOut[*B].end(); it++)
+      {
+        (*it)->printAsOperand(errs(), false);
+        errs() << " ";
+      }
+      errs() << "\n";
+    );
+  }
+}
+
+void LiveValues::constructLoopNestingForest(Function &F,
+                                            LoopNestingForest &LNF)
+{
+  LoopInfo &LI = getAnalysis<LoopInfoWrapperPass>().getLoopInfo();
+
+  for(scc_iterator<Function *> scc = scc_begin(&F);
+      scc != scc_end(&F);
+      ++scc)
+  {
+    const std::vector<BasicBlock *> &SCC = *scc;
+    LNF.emplace_back(SCC, LI);
+
+    DEBUG(
+      errs() << "Loop nesting tree: "
+             << LNF.back().size() << " node(s), loop-nesting depth: "
+             << LNF.back().depth() << "\n";
+      LNF.back().print(errs());
+      errs() << "\n"
+    );
+  }
+}
+
+void LiveValues::propagateValues(const LoopNestingTree &loopNest,
+                                 LiveVals &liveIn,
+                                 LiveVals &liveOut)
+{
+  std::set<const Value *> liveLoop, phiDefined;
+
+  /* Iterate over all loop nodes. */
+  for(LoopNestingTree::loop_iterator loop = loopNest.loop_begin();
+      loop != loopNest.loop_end();
+      loop++)
+  {
+    /* Calculate LiveLoop (lines 3 & 4 of Algorithm 3). */
+    phiDefs(*loop, phiDefined);
+    for(std::set<const Value *>::const_iterator it = liveIn[*loop].begin();
+        it != liveIn[*loop].end();
+        it++)
+      if(!phiDefined.count(*it) && includeVal(*it))
+        liveLoop.insert(*it);
+
+    /* Propagate values to children (lines 5-8 of Algorithm 3). */
+    for(LoopNestingTree::child_iterator child = loopNest.children_begin(loop);
+        child != loopNest.children_end(loop);
+        child++) {
+      for(std::set<const Value *>::const_iterator it = liveLoop.begin();
+          it != liveLoop.end();
+          it++) {
+        liveIn[*child].insert(*it);
+        liveOut[*child].insert(*it);
+      }
+    }
+
+    liveLoop.clear();
+  }
+}
+
+void LiveValues::loopTreeDFS(LoopNestingForest &LNF,
+                             LiveVals &liveIn,
+                             LiveVals &liveOut)
+{
+  LoopNestingForest::const_iterator it;
+  for(it = LNF.begin(); it != LNF.end(); it++)
+    propagateValues(*it, liveIn, liveOut);
+}
+
Index: lib/Analysis/LoopNestingTree.cpp
===================================================================
--- lib/Analysis/LoopNestingTree.cpp	(nonexistent)
+++ lib/Analysis/LoopNestingTree.cpp	(working copy)
@@ -0,0 +1,148 @@
+#include "llvm/Analysis/LoopNestingTree.h"
+#include "llvm/Support/raw_ostream.h"
+
+using namespace llvm;
+
+///////////////////////////////////////////////////////////////////////////////
+// Public API
+///////////////////////////////////////////////////////////////////////////////
+
+LoopNestingTree::LoopNestingTree(const std::vector<BasicBlock *> &SCC,
+                                 const LoopInfo &LI)
+  : _size(1), _depth(1), _root(nullptr)
+{
+  unsigned depth = 1, nodeDepth;
+  const Loop *loop = nullptr;
+  Node *loopHeader = nullptr, *newHeader = nullptr;
+  std::list<Node *> work;
+
+  /* Bootstrap by grabbing the loop of the first basic block encountered. */
+  loop = LI[SCC.front()];
+  if(!loop) // Is the SCC actually a loop?
+  {
+    _root = new Node(SCC.front(), nullptr, true);
+    return;
+  }
+
+  /* Get header of outermost loop, the tree's root. */
+  while(loop->getLoopDepth() > 1)
+    loop = loop->getParentLoop();
+  _root = new Node(loop->getHeader(), nullptr, true);
+  work.push_back(_root);
+
+  /* Parse the loop-headers of the SCC into the tree. */
+  while(work.size())
+  {
+    loopHeader = work.front();
+    work.pop_front();
+    loop = LI[loopHeader->bb];
+    depth = LI.getLoopDepth(loopHeader->bb);
+    _depth = (depth > _depth ? depth : _depth);
+
+    /* Add children of the loop header. */
+    for(auto bbi = loop->block_begin()++; bbi != loop->block_end(); bbi++)
+    {
+      nodeDepth = LI.getLoopDepth(*bbi);
+      if(nodeDepth == depth) // Regular child node
+      {
+        loopHeader->addChild(new Node(*bbi, loopHeader, false));
+        _size++;
+      }
+      else if(nodeDepth == (depth + 1) && // Header of nested loop
+              LI.isLoopHeader(*bbi))
+      {
+        newHeader = new Node(*bbi, loopHeader, true);
+        loopHeader->addChild(newHeader);
+        work.push_back(newHeader);
+        _size++;
+      }
+    }
+  }
+}
+
+LoopNestingTree::loop_iterator LoopNestingTree::loop_iterator::operator++()
+{
+  loop_iterator me = *this;
+  if(remaining.size())
+  {
+    cur = remaining.front();
+    remaining.pop();
+    addLoopHeaders();
+  }
+  else cur = nullptr;
+  return me;
+}
+
+LoopNestingTree::loop_iterator
+LoopNestingTree::loop_iterator::operator++(int junk)
+{
+  if(remaining.size())
+  {
+    cur = remaining.front();
+    remaining.pop();
+    addLoopHeaders();
+  }
+  else cur = nullptr;
+  return *this;
+}
+
+LoopNestingTree::child_iterator::child_iterator(loop_iterator &parent,
+                                                enum location loc)
+{
+  if(loc == BEGIN) it = parent.cur->children.begin();
+  else it = parent.cur->children.end();
+}
+
+///////////////////////////////////////////////////////////////////////////////
+// Private API
+///////////////////////////////////////////////////////////////////////////////
+
+void LoopNestingTree::print(raw_ostream &O, Node *node, unsigned depth) const
+{
+  for(unsigned i = 0; i < depth; i++) O << " ";
+  node->bb->printAsOperand(O, false);
+  O << "\n";
+  if(node->children.size())
+  {
+    for(unsigned i = 0; i < depth; i++) O << " ";
+    O << "\\\n";
+
+    for(std::list<Node *>::const_iterator it = node->children.begin();
+        it != node->children.end();
+        it++)
+    {
+      if((*it)->isLoopHeader) print(O, (*it), depth + 1);
+      else
+      {
+        for(unsigned i = 0; i < depth + 1; i++) O << " ";
+        (*it)->bb->printAsOperand(O, false);
+        O << "\n";
+      }
+    }
+  }
+}
+
+void LoopNestingTree::deleteRecursive(Node *node)
+{
+  for(std::list<Node *>::iterator it = node->children.begin();
+      it != node->children.end();
+      it++)
+  {
+    if((*it)->isLoopHeader) deleteRecursive(*it);
+    else delete *it;
+  }
+  delete node;
+}
+
+void LoopNestingTree::loop_iterator::addLoopHeaders()
+{
+  if(cur != nullptr)
+  {
+    for(std::list<Node *>::const_iterator it = cur->children.begin();
+        it != cur->children.end();
+        it++)
+      if((*it)->isLoopHeader)
+        remaining.push(*it);
+  }
+}
+
Index: lib/CodeGen/AsmPrinter/AsmPrinter.cpp
===================================================================
--- lib/CodeGen/AsmPrinter/AsmPrinter.cpp	(revision 277823)
+++ lib/CodeGen/AsmPrinter/AsmPrinter.cpp	(working copy)
@@ -1160,6 +1160,41 @@
   return CurExceptionSym;
 }
 
+MachineInstr *AsmPrinter::FindStackMap(MachineBasicBlock &MBB,
+                                       MachineInstr *MI) const {
+  MachineBasicBlock::instr_iterator i, ie;
+  for(i = MI->getNextNode(), ie = MBB.instr_end();
+      i != ie;
+      i = i->getNextNode()) {
+    if(i->getOpcode() == TargetOpcode::STACKMAP)
+      return &*i;
+    else if(i->isCall())
+      break;
+  }
+
+  // Call site without a stackmap implies that either the call was generated by
+  // the backend or the LLVM bitcode was never instrumented by the StackInfo
+  // pass.  This is not necessarily an error!
+  return nullptr;
+}
+
+bool AsmPrinter::TagCallSites(MachineFunction &MF) {
+  bool tagged = false;
+  for(auto MBB = MF.begin(), MBBE = MF.end(); MBB != MBBE; MBB++) {
+    for(auto MI = MBB->instr_begin(), MIE = MBB->instr_end(); MI != MIE; MI++) {
+      if(MI->isCall() && !MI->isPseudo()) {
+        MachineInstr *SMI = FindStackMap(*MBB, &*MI);
+        if(SMI != nullptr) {
+          MBB->remove(SMI);
+          MI = MBB->insert(++MI, SMI);
+          tagged = true;
+        }
+      }
+    }
+  }
+  return tagged;
+}
+
 void AsmPrinter::SetupMachineFunction(MachineFunction &MF) {
   this->MF = &MF;
   // Get the function symbol.
Index: lib/CodeGen/CMakeLists.txt
===================================================================
--- lib/CodeGen/CMakeLists.txt	(revision 277823)
+++ lib/CodeGen/CMakeLists.txt	(working copy)
@@ -111,6 +111,8 @@
   StackSlotColoring.cpp
   StackMapLivenessAnalysis.cpp
   StackMaps.cpp
+  StackTransformMetadata.cpp
+  StackTransformTypes.cpp
   StatepointExampleGC.cpp
   TailDuplication.cpp
   TargetFrameLoweringImpl.cpp
@@ -122,6 +124,7 @@
   TargetSchedule.cpp
   TwoAddressInstructionPass.cpp
   UnreachableBlockElim.cpp
+  UnwindInfo.cpp
   VirtRegMap.cpp
   WinEHPrepare.cpp
 
Index: lib/CodeGen/CodeGen.cpp
===================================================================
--- lib/CodeGen/CodeGen.cpp	(revision 277823)
+++ lib/CodeGen/CodeGen.cpp	(working copy)
@@ -68,6 +68,7 @@
   initializeStackMapLivenessPass(Registry);
   initializeStackProtectorPass(Registry);
   initializeStackSlotColoringPass(Registry);
+  initializeStackTransformMetadataPass(Registry);
   initializeTailDuplicatePassPass(Registry);
   initializeTargetPassConfigPass(Registry);
   initializeTwoAddressInstructionPassPass(Registry);
Index: lib/CodeGen/LLVMTargetMachine.cpp
===================================================================
--- lib/CodeGen/LLVMTargetMachine.cpp	(revision 277823)
+++ lib/CodeGen/LLVMTargetMachine.cpp	(working copy)
@@ -42,6 +42,19 @@
 EnableFastISelOption("fast-isel", cl::Hidden,
   cl::desc("Enable the \"fast\" instruction selector"));
 
+// Enable generation of stack transformation metadata, which also requires
+// disabling late-stage optimizations.
+static cl::opt<bool> EmitStackTransformMetadata("emit-st-metadata",
+  cl::init(false), cl::NotHidden,
+  cl::desc("Enable generation of Popcorn stack transformation metadata"));
+
+// Similar to "-emit-st-metadata", but *only* for specific libc thread start
+// functions
+static cl::opt<bool> EmitLibcTransformMetadata("emit-libc-metadata",
+  cl::init(false), cl::NotHidden,
+  cl::desc("Enable generation of transformation metadata for libc thread "
+           "start functions"));
+
 void LLVMTargetMachine::initAsmInfo() {
   MRI = TheTarget.createMCRegInfo(getTargetTriple().str());
   MII = TheTarget.createMCInstrInfo();
@@ -105,6 +118,19 @@
   // Set PassConfig options provided by TargetMachine.
   PassConfig->setDisableVerify(DisableVerify);
 
+  // Add stack transformation instrumentation passes, remove late-stage IR
+  // optimizations
+  if(EmitStackTransformMetadata) {
+    TM->setArchIROptLevel(CodeGenOpt::None);
+    TM->setEmitStackTransformMetadata(true);
+  }
+
+  // Add libc instrumentation passes, remove late-stage IR optimizations
+  if(EmitLibcTransformMetadata) {
+    TM->setArchIROptLevel(CodeGenOpt::None);
+    TM->setEmitLibcTransformMetadata(true);
+  }
+
   PM.add(PassConfig);
 
   PassConfig->addIRPasses();
Index: lib/CodeGen/MachineFunction.cpp
===================================================================
--- lib/CodeGen/MachineFunction.cpp	(revision 277823)
+++ lib/CodeGen/MachineFunction.cpp	(working copy)
@@ -253,6 +253,15 @@
                                MMO->getBaseAlignment());
 }
 
+/// Is a register caller-saved?
+bool MachineFunction::isCallerSaved(unsigned Reg) const {
+  assert(TargetRegisterInfo::isPhysicalRegister(Reg) && "Invalid register");
+  CallingConv::ID CC = Fn->getCallingConv();
+  const uint32_t *Mask =
+    RegInfo->getTargetRegisterInfo()->getCallPreservedMask(*this, CC);
+  return !((Mask[Reg / 32] >> Reg % 32) & 1);
+}
+
 MachineInstr::mmo_iterator
 MachineFunction::allocateMemRefsArray(unsigned long Num) {
   return Allocator.Allocate<MachineMemOperand *>(Num);
@@ -482,6 +491,166 @@
                                Twine(getFunctionNumber()) + "$pb");
 }
 
+/// Get the value for key K in Map M, or create a new one if it doesn't exist.
+template<typename Key, typename Val, typename Map>
+static Val &getOrCreateMapping(const Key *K, Map &M) {
+  typename Map::iterator It;
+  if((It = M.find(K)) == M.end())
+    It = M.insert(std::pair<const Key *, Val>(K, Val())).first;
+  return It->second;
+}
+
+/// Add an IR/architecture-specific location mapping for a stackmap operand
+void MachineFunction::addSMOpLocation(const CallInst *SM,
+                                      const Value *Val,
+                                      const MachineLiveLoc &MLL) {
+  auto containsLoc = [](const MachineLiveLocs &Vals,
+                        const MachineLiveLoc &Cur) -> bool {
+    for(auto &LV : Vals) if(Cur == *LV) return true;
+    return false;
+  };
+
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid stackmap operand");
+
+  IRToMachineLocs &IRMap =
+    getOrCreateMapping<Instruction,
+                       IRToMachineLocs,
+                       InstToOperands>(SM, SMDuplicateLocs);
+  MachineLiveLocs &Vals =
+    getOrCreateMapping<Value,
+                       MachineLiveLocs,
+                       IRToMachineLocs>(Val, IRMap);
+  if(!containsLoc(Vals, MLL))
+    Vals.push_back(MachineLiveLocPtr(MLL.copy()));
+}
+
+/// Add an IR/architecture-specific location mapping for a stackmap operand
+void MachineFunction::addSMOpLocation(const CallInst *SM,
+                                      unsigned Op,
+                                      const MachineLiveLoc &MLL) {
+  assert(SM && "Invalid stackmap");
+  assert(Op < SM->getNumArgOperands() && "Invalid operand number");
+  addSMOpLocation(SM, SM->getArgOperand(Op), MLL);
+}
+
+
+/// Add an architecture-specific live value & location for a stackmap
+void MachineFunction::addSMArchSpecificLocation(const CallInst *SM,
+                                                const MachineLiveLoc &MLL,
+                                                const MachineLiveVal &MC) {
+  auto containsLoc = [](const ArchLiveValues &Vals,
+                        const MachineLiveLoc &Cur) -> bool {
+    for(auto &LV : Vals) if(Cur == *LV.first) return true;
+    return false;
+  };
+
+  assert(SM && "Invalid stackmap");
+  ArchLiveValues &Vals =
+    getOrCreateMapping<Instruction,
+                       ArchLiveValues,
+                       InstToArchLiveValues>(SM, SMArchSpecificLocs);
+  if(!containsLoc(Vals, MLL))
+    Vals.push_back(ArchLiveValue(MachineLiveLocPtr(MLL.copy()),
+                                 MachineLiveValPtr(MC.copy())));
+}
+
+/// Update stack slot references to new indexes after stack slot coloring
+void
+MachineFunction::updateSMStackSlotRefs(SmallDenseMap<int, int, 16> &Changes) {
+  if(Changes.size()) {
+    DEBUG(dbgs() << "Updating stackmap stack slot references\n";);
+    SmallDenseMap<int, int, 16>::iterator Change;
+
+    // Iterate over all operand duplicate locations
+    for(auto &InstIt : SMDuplicateLocs) {
+      for(auto &IRIt : InstIt.second) {
+        for(auto &MLL : IRIt.second) {
+          if(MLL->isStackSlot()) {
+            MachineLiveStackSlot &LSS = (MachineLiveStackSlot &)*MLL;
+            int SS = LSS.getStackSlot();
+            Change = Changes.find(SS);
+            if(Change != Changes.end())
+              LSS.setStackSlot(Change->second);
+          }
+        }
+      }
+    }
+
+    // Iterate over all architecture-specific locations
+    for(auto &InstIt : SMArchSpecificLocs) {
+      for(auto &MLL : InstIt.second) {
+        if(MLL.first->isStackSlot()) {
+          MachineLiveStackSlot &LSS = (MachineLiveStackSlot &)*MLL.first;
+          int SS = LSS.getStackSlot();
+          Change = Changes.find(SS);
+          if(Change != Changes.end())
+            LSS.setStackSlot(Change->second);
+        }
+
+        if(MLL.second->isGenerated()) {
+          MachineGeneratedVal &MG = (MachineGeneratedVal &)*MLL.second;
+          for(auto &Inst : MG.getInstructions()) {
+            if(Inst->type() == MachineGeneratedVal::ValueGenInst::StackSlot) {
+              MachineGeneratedVal::PseudoInstructionBase &PS =
+                (MachineGeneratedVal::PseudoInstructionBase &)*Inst;
+              int SS = (int)PS.getData();
+              Change = Changes.find(SS);
+              if(Change != Changes.end())
+                PS.setData((uint64_t)Change->second);
+            }
+          }
+        }
+      }
+    }
+  }
+}
+
+/// Are there any architecture-specific locations for operand Val in stackmap
+/// SM?
+bool
+MachineFunction::hasSMOpLocations(const CallInst *SM, const Value *Val) const {
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid stackmap operand");
+  InstToOperands::const_iterator InstIt;
+  if((InstIt = SMDuplicateLocs.find(SM)) != SMDuplicateLocs.end())
+    return InstIt->second.find(Val) != InstIt->second.end();
+  return false;
+}
+
+/// Are there any architecture-specific locations for stackmap SM?
+bool
+MachineFunction::hasSMArchSpecificLocations(const llvm::CallInst *SM) const {
+  assert(SM && "Invalid stackmap");
+  return SMArchSpecificLocs.find(SM) != SMArchSpecificLocs.end();
+}
+
+/// Return the architecture-specific locations for a stackmap operand.
+const MachineLiveLocs &
+MachineFunction::getSMOpLocations(const CallInst *SM,
+                                  const Value *Val ) const {
+  assert(SM && "Invalid stackmap");
+  assert(Val && "Invalid stackmap operand");
+  InstToOperands::const_iterator InstIt = SMDuplicateLocs.find(SM);
+  assert(InstIt != SMDuplicateLocs.end() &&
+         "No duplicate locations for stackmap");
+  IRToMachineLocs::const_iterator IRIt = InstIt->second.find(Val);
+  assert(IRIt != InstIt->second.end() &&
+         "No duplicate locations for stackmap operand");
+  return IRIt->second;
+}
+
+/// Return the architecture-specific locations for a stackmap that are not
+/// associated with any operand.
+const ArchLiveValues &
+MachineFunction::getSMArchSpecificLocations(const CallInst *SM) const {
+  assert(SM && "Invalid stackmap");
+  InstToArchLiveValues::const_iterator InstIt = SMArchSpecificLocs.find(SM);
+  assert(InstIt != SMArchSpecificLocs.end() &&
+         "No architecture-specific locations for stackmap");
+  return InstIt->second;
+}
+
 //===----------------------------------------------------------------------===//
 //  MachineFrameInfo implementation
 //===----------------------------------------------------------------------===//
Index: lib/CodeGen/Passes.cpp
===================================================================
--- lib/CodeGen/Passes.cpp	(revision 277823)
+++ lib/CodeGen/Passes.cpp	(working copy)
@@ -459,6 +459,16 @@
 void TargetPassConfig::addISelPrepare() {
   addPreISel();
 
+  // Add pass to instrument IR with stackmap instructions, which get lowered
+  // to metadata needed for Popcorn's stack transformation
+  if(emitStackTransformMetadata())
+    addPass(createInsertStackMapsPass());
+
+  // Similarly to creatInsertStackMaps pass, but only instruments libc thread
+  // start functions
+  if(emitLibcTransformMetadata())
+    addPass(createLibcStackMapsPass());
+
   // Add both the safe stack and the stack protection passes: each of them will
   // only protect functions that have corresponding attributes.
   addPass(createSafeStackPass());
@@ -754,6 +764,10 @@
   // Allow targets to change the register assignments before rewriting.
   addPreRewrite();
 
+  // Gather additional stack transformation metadata before rewriting virtual
+  // registers
+  addPass(&StackTransformMetadataID);
+
   // Finally rewrite virtual registers.
   addPass(&VirtRegRewriterID);
 
Index: lib/CodeGen/RegAllocFast.cpp
===================================================================
--- lib/CodeGen/RegAllocFast.cpp	(revision 277823)
+++ lib/CodeGen/RegAllocFast.cpp	(working copy)
@@ -1078,6 +1078,13 @@
 /// runOnMachineFunction - Register allocate the whole function
 ///
 bool RAFast::runOnMachineFunction(MachineFunction &Fn) {
+  // TODO the fast register allocator behaves poorly for stackmaps with lots
+  // of operands, and since it doesn't use the VirtRegRewriter pass we can't
+  // capture correct stackmap operand locations
+  if(Fn.getFrameInfo()->hasStackMap())
+    llvm_unreachable("Fast register allocator not supported for stack"
+                     "transformation");
+
   DEBUG(dbgs() << "********** FAST REGISTER ALLOCATION **********\n"
                << "********** Function: " << Fn.getName() << '\n');
   MF = &Fn;
Index: lib/CodeGen/SelectionDAG/LegalizeIntegerTypes.cpp
===================================================================
--- lib/CodeGen/SelectionDAG/LegalizeIntegerTypes.cpp	(revision 277823)
+++ lib/CodeGen/SelectionDAG/LegalizeIntegerTypes.cpp	(working copy)
@@ -886,6 +886,9 @@
   case ISD::SRL:
   case ISD::ROTL:
   case ISD::ROTR: Res = PromoteIntOp_Shift(N); break;
+
+  case (uint16_t)~TargetOpcode::STACKMAP:
+    Res = PromoteIntOp_STACKMAP(N, OpNo); break;
   }
 
   // If the result is null, the sub-method took care of registering results etc.
@@ -1131,6 +1134,23 @@
                                 SExtPromotedInteger(N->getOperand(0))), 0);
 }
 
+SDValue DAGTypeLegalizer::PromoteIntOp_STACKMAP(SDNode *N, unsigned OpNo) {
+  std::vector<SDValue> Ops(N->getNumOperands());
+  SDLoc dl(N);
+
+  for(unsigned i = 0; i < N->getNumOperands(); i++) {
+    if(i == OpNo) {
+      if(N->getOperand(i).getValueType() == MVT::i1 ||
+         N->getOperand(i).getValueType() == MVT::i8 ||
+         N->getOperand(i).getValueType() == MVT::i16)
+        Ops[i] = DAG.getNode(ISD::ZERO_EXTEND, dl, MVT::i32, N->getOperand(i));
+    }
+    else Ops[i] = N->getOperand(i);
+  }
+
+  return SDValue(DAG.UpdateNodeOperands(N, Ops), 0);
+}
+
 SDValue DAGTypeLegalizer::PromoteIntOp_STORE(StoreSDNode *N, unsigned OpNo){
   assert(ISD::isUNINDEXEDStore(N) && "Indexed store during type legalization!");
   SDValue Ch = N->getChain(), Ptr = N->getBasePtr();
Index: lib/CodeGen/SelectionDAG/LegalizeTypes.h
===================================================================
--- lib/CodeGen/SelectionDAG/LegalizeTypes.h	(revision 277823)
+++ lib/CodeGen/SelectionDAG/LegalizeTypes.h	(working copy)
@@ -288,6 +288,7 @@
   SDValue PromoteIntOp_Shift(SDNode *N);
   SDValue PromoteIntOp_SIGN_EXTEND(SDNode *N);
   SDValue PromoteIntOp_SINT_TO_FP(SDNode *N);
+  SDValue PromoteIntOp_STACKMAP(SDNode *N, unsigned OpNo);
   SDValue PromoteIntOp_STORE(StoreSDNode *N, unsigned OpNo);
   SDValue PromoteIntOp_TRUNCATE(SDNode *N);
   SDValue PromoteIntOp_UINT_TO_FP(SDNode *N);
Index: lib/CodeGen/StackColoring.cpp
===================================================================
--- lib/CodeGen/StackColoring.cpp	(revision 277823)
+++ lib/CodeGen/StackColoring.cpp	(working copy)
@@ -713,7 +713,7 @@
 
   // This is a simple greedy algorithm for merging allocas. First, sort the
   // slots, placing the largest slots first. Next, perform an n^2 scan and look
-  // for disjoint slots. When you find disjoint slots, merge the samller one
+  // for disjoint slots. When you find disjoint slots, merge the smaller one
   // into the bigger one and update the live interval. Remove the small alloca
   // and continue.
 
Index: lib/CodeGen/StackMaps.cpp
===================================================================
--- lib/CodeGen/StackMaps.cpp	(revision 277823)
+++ lib/CodeGen/StackMaps.cpp	(working copy)
@@ -12,12 +12,16 @@
 #include "llvm/CodeGen/MachineFrameInfo.h"
 #include "llvm/CodeGen/MachineFunction.h"
 #include "llvm/CodeGen/MachineInstr.h"
+#include "llvm/CodeGen/UnwindInfo.h"
 #include "llvm/IR/DataLayout.h"
+#include "llvm/IR/DiagnosticInfo.h"
+#include "llvm/IR/IntrinsicInst.h"
 #include "llvm/MC/MCContext.h"
 #include "llvm/MC/MCExpr.h"
 #include "llvm/MC/MCObjectFileInfo.h"
 #include "llvm/MC/MCSectionMachO.h"
 #include "llvm/MC/MCStreamer.h"
+#include "llvm/MC/MCSymbol.h"
 #include "llvm/Support/CommandLine.h"
 #include "llvm/Target/TargetMachine.h"
 #include "llvm/Target/TargetOpcodes.h"
@@ -29,6 +33,14 @@
 
 #define DEBUG_TYPE "stackmaps"
 
+#define TYPE_AND_FLAGS(type, ptr, alloca, dup) \
+  ((uint8_t)type) << 4 | ((uint8_t)ptr) << 2 | \
+  ((uint8_t)alloca) << 1 | ((uint8_t)dup)
+
+#define ARCH_TYPE_AND_FLAGS(type, ptr) ((uint8_t)type) << 4 | ((uint8_t)ptr)
+
+#define ARCH_OP_TYPE(inst, op) ((uint8_t)inst << 4) | ((uint8_t)op)
+
 static cl::opt<int> StackMapVersion(
     "stackmap-version", cl::init(1),
     cl::desc("Specify the stackmap encoding version (default = 1)"));
@@ -84,32 +96,110 @@
   return (unsigned)RegNum;
 }
 
+/// Get pointer typing information for a stackmap operand
+void StackMaps::getPointerInfo(const Value *Op, const DataLayout &DL,
+                               bool &isPtr, bool &isAlloca,
+                               unsigned &AllocaSize) const {
+  isPtr = false;
+  isAlloca = false;
+  AllocaSize = 0;
+
+  assert(Op != nullptr && "Invalid stackmap operand");
+  Type *Ty = Op->getType();
+  if(Ty->isPointerTy())
+  {
+    isPtr = true;
+    PointerType *PTy = cast<PointerType>(Ty);
+    if(PTy->getElementType()->isSized() && isa<AllocaInst>(Op)) {
+      isAlloca = true;
+      AllocaSize = DL.getTypeAllocSize(PTy->getElementType());
+    }
+  }
+}
+
+/// Get stackmap information for register location
+void StackMaps::getRegLocation(unsigned Phys,
+                               unsigned &Dwarf,
+                               unsigned &Offset) const {
+  const TargetRegisterInfo *TRI = AP.MF->getSubtarget().getRegisterInfo();
+  assert(!TRI->isVirtualRegister(Phys) &&
+         "Virtual registers should have been rewritten by now");
+  Offset = 0;
+  Dwarf = getDwarfRegNum(Phys, TRI);
+  unsigned LLVMRegNum = TRI->getLLVMRegNum(Dwarf, false);
+  unsigned SubRegIdx = TRI->getSubRegIndex(LLVMRegNum, Phys);
+  if(SubRegIdx)
+    Offset = TRI->getSubRegIdxOffset(SubRegIdx);
+}
+
+/// Add duplicate target-specific locations for a stackmap operand
+void StackMaps::addDuplicateLocs(const CallInst *StackMap, const Value *Oper,
+                                 LocationVec &Locs, unsigned Size, bool Ptr,
+                                 bool Alloca, unsigned AllocaSize) const {
+  if(AP.MF->hasSMOpLocations(StackMap, Oper)) {
+    const TargetRegisterInfo *TRI = AP.MF->getSubtarget().getRegisterInfo();
+    const MachineLiveLocs &Dups = AP.MF->getSMOpLocations(StackMap, Oper);
+    const unsigned FBPOff = AP.getFBPOffset();
+
+    for(const MachineLiveLocPtr &LL : Dups) {
+      if(LL->isReg()) {
+        const MachineLiveReg &MR = (const MachineLiveReg &)*LL;
+        unsigned Offset, DwarfRegNum;
+        getRegLocation(MR.getReg(), DwarfRegNum, Offset);
+
+        Locs.emplace_back(Location::Register, Size, DwarfRegNum, Offset,
+                          Ptr, Alloca, true, AllocaSize);
+      }
+      else if(LL->isStackSlot()) {
+        const MachineLiveStackSlot &MSS = (const MachineLiveStackSlot &)*LL;
+        const MachineFrameInfo *MFI = AP.MF->getFrameInfo();
+        assert(!MFI->isDeadObjectIndex(MSS.getStackSlot()) &&
+               "Attempting to add a dead stack slot");
+        int64_t Offset = MFI->getObjectOffset(MSS.getStackSlot()) + FBPOff;
+
+        Locs.emplace_back(Location::Indirect, Size,
+          getDwarfRegNum(TRI->getFrameRegister(*AP.MF), TRI),
+          Offset, Ptr, Alloca, true, AllocaSize);
+      }
+    }
+  }
+}
+
 MachineInstr::const_mop_iterator
 StackMaps::parseOperand(MachineInstr::const_mop_iterator MOI,
                         MachineInstr::const_mop_iterator MOE, LocationVec &Locs,
-                        LiveOutVec &LiveOuts) const {
+                        LiveOutVec &LiveOuts, User::const_op_iterator &Op) const {
+  bool isPtr, isAlloca;
+  unsigned AllocaSize;
+  auto &DL = AP.MF->getDataLayout();
   const TargetRegisterInfo *TRI = AP.MF->getSubtarget().getRegisterInfo();
+  const CallInst *IRSM = cast<CallInst>(Op->getUser());
+  const Value *IROp = Op->get();
+  getPointerInfo(IROp, DL, isPtr, isAlloca, AllocaSize);
+
   if (MOI->isImm()) {
     switch (MOI->getImm()) {
     default:
       llvm_unreachable("Unrecognized operand type.");
     case StackMaps::DirectMemRefOp: {
-      unsigned Size = AP.TM.getDataLayout()->getPointerSizeInBits();
+      unsigned Size = DL.getPointerSizeInBits();
       assert((Size % 8) == 0 && "Need pointer size in bytes.");
       Size /= 8;
       unsigned Reg = (++MOI)->getReg();
       int64_t Imm = (++MOI)->getImm();
-      Locs.emplace_back(StackMaps::Location::Direct, Size,
-                        getDwarfRegNum(Reg, TRI), Imm);
+      Locs.emplace_back(Location::Direct, Size, getDwarfRegNum(Reg, TRI), Imm,
+                        isPtr, isAlloca, false, AllocaSize);
       break;
     }
     case StackMaps::IndirectMemRefOp: {
       int64_t Size = (++MOI)->getImm();
       assert(Size > 0 && "Need a valid size for indirect memory locations.");
+      Size = DL.getTypeAllocSize(IROp->getType());
       unsigned Reg = (++MOI)->getReg();
       int64_t Imm = (++MOI)->getImm();
-      Locs.emplace_back(StackMaps::Location::Indirect, Size,
-                        getDwarfRegNum(Reg, TRI), Imm);
+      Locs.emplace_back(Location::Indirect, (unsigned)Size,
+                        getDwarfRegNum(Reg, TRI), Imm, isPtr, isAlloca, false,
+                        AllocaSize);
       break;
     }
     case StackMaps::ConstantOp: {
@@ -116,17 +206,24 @@
       ++MOI;
       assert(MOI->isImm() && "Expected constant operand.");
       int64_t Imm = MOI->getImm();
-      Locs.emplace_back(Location::Constant, sizeof(int64_t), 0, Imm);
+      Locs.emplace_back(Location::Constant, sizeof(int64_t), 0, Imm,
+                        isPtr, isAlloca, false, AllocaSize);
       break;
     }
     }
+    // Note: we shouldn't have alternate locations -- constants aren't stored
+    // anywhere, and stack slots should be either allocas (which shouldn't have
+    // alternate locations) or register spill locations (handled below in the
+    // register path)
+    assert(!AP.MF->hasSMOpLocations(IRSM, IROp) &&
+           "Unhandled duplicate locations");
+    ++Op;
     return ++MOI;
   }
 
   // The physical register number will ultimately be encoded as a DWARF regno.
   // The stack map also records the size of a spill slot that can hold the
-  // register content. (The runtime can track the actual size of the data type
-  // if it needs to.)
+  // register content, accurate to the actual size of the data type.
   if (MOI->isReg()) {
     // Skip implicit registers (this includes our scratch registers)
     if (MOI->isImplicit())
@@ -134,17 +231,16 @@
 
     assert(TargetRegisterInfo::isPhysicalRegister(MOI->getReg()) &&
            "Virtreg operands should have been rewritten before now.");
-    const TargetRegisterClass *RC = TRI->getMinimalPhysRegClass(MOI->getReg());
     assert(!MOI->getSubReg() && "Physical subreg still around.");
 
-    unsigned Offset = 0;
-    unsigned DwarfRegNum = getDwarfRegNum(MOI->getReg(), TRI);
-    unsigned LLVMRegNum = TRI->getLLVMRegNum(DwarfRegNum, false);
-    unsigned SubRegIdx = TRI->getSubRegIndex(LLVMRegNum, MOI->getReg());
-    if (SubRegIdx)
-      Offset = TRI->getSubRegIdxOffset(SubRegIdx);
+    size_t ValSize = DL.getTypeAllocSize(IROp->getType());
+    unsigned Offset, DwarfRegNum;
+    getRegLocation(MOI->getReg(), DwarfRegNum, Offset);
 
-    Locs.emplace_back(Location::Register, RC->getSize(), DwarfRegNum, Offset);
+    Locs.emplace_back(Location::Register, ValSize, DwarfRegNum, Offset,
+                      isPtr, isAlloca, false, AllocaSize);
+    addDuplicateLocs(IRSM, IROp, Locs, ValSize, isPtr, isAlloca, AllocaSize);
+    ++Op;
     return ++MOI;
   }
 
@@ -161,6 +257,7 @@
   for (const auto &CSI : CSInfos) {
     const LocationVec &CSLocs = CSI.Locations;
     const LiveOutVec &LiveOuts = CSI.LiveOuts;
+    const ArchValues &Values = CSI.Vals;
 
     OS << WSMP << "callsite " << CSI.ID << "\n";
     OS << WSMP << "  has " << CSLocs.size() << " locations\n";
@@ -194,7 +291,7 @@
           OS << TRI->getName(Loc.Reg);
         else
           OS << Loc.Reg;
-        OS << "+" << Loc.Offset;
+        OS << " + " << Loc.Offset;
         break;
       case Location::Constant:
         OS << "Constant " << Loc.Offset;
@@ -203,8 +300,15 @@
         OS << "Constant Index " << Loc.Offset;
         break;
       }
-      OS << "\t[encoding: .byte " << Loc.Type << ", .byte " << Loc.Size
-         << ", .short " << Loc.Reg << ", .int " << Loc.Offset << "]\n";
+      OS << ", pointer? " << Loc.Ptr << ", alloca? " << Loc.Alloca
+         << ", duplicate? " << Loc.Duplicate;
+
+      unsigned TypeAndFlags =
+        TYPE_AND_FLAGS(Loc.Type, Loc.Ptr, Loc.Alloca, Loc.Duplicate);
+
+      OS << "\t[encoding: .byte " << TypeAndFlags << ", .byte " << Loc.Size
+         << ", .short " << Loc.Reg << ", .int " << Loc.Offset
+         << ", .uint " << Loc.AllocaSize << "]\n";
       Idx++;
     }
 
@@ -221,6 +325,77 @@
          << LO.Size << "]\n";
       Idx++;
     }
+
+    OS << WSMP << "\thas " << Values.size() << " arch-specific live values\n";
+
+    Idx = 0;
+    for (const auto &V : Values) {
+      const Location &Loc = V.first;
+      const Operation &Op = V.second;
+
+      OS << WSMP << "\t\tArch-Val " << Idx << ": ";
+      switch(Loc.Type) {
+      case Location::Register:
+        OS << "Register ";
+        if (TRI)
+          OS << TRI->getName(Loc.Reg);
+        else
+          OS << Loc.Reg;
+        break;
+      case Location::Indirect:
+        OS << "Indirect ";
+        if (TRI)
+          OS << TRI->getName(Loc.Reg);
+        else
+          OS << Loc.Reg;
+        if (Loc.Offset)
+          OS << " + " << Loc.Offset;
+        break;
+      default:
+        OS << "<Unknown live value type>";
+        break;
+      }
+
+      OS << ", " << MachineGeneratedVal::ValueGenInst::InstTypeStr[Op.InstType]
+         << " ";
+      switch(Op.OperandType) {
+      case Location::Register:
+        OS << "register ";
+        if (TRI)
+          OS << TRI->getName(Op.DwarfReg);
+        else
+          OS << Op.DwarfReg;
+        break;
+      case Location::Direct:
+        OS << "register ";
+        if (TRI)
+          OS << TRI->getName(Op.DwarfReg);
+        else
+          OS << Op.DwarfReg;
+        if (Op.Constant)
+          OS << " + " << Op.Constant;
+        break;
+      case Location::Constant:
+        if(Op.isSymbol)
+          OS << "address of " << Op.Symbol->getName();
+        else {
+          OS << "immediate ";
+          OS.write_hex(Op.Constant);
+        }
+        break;
+      default:
+        OS << "<Unknown operand type>";
+        break;
+      }
+
+      unsigned TypeAndFlags = ARCH_TYPE_AND_FLAGS(Loc.Type, Loc.Ptr);
+      unsigned OpType = ARCH_OP_TYPE(Op.InstType, Op.OperandType);
+      OS << "\t[encoding: .byte " << TypeAndFlags << ", .byte " << Loc.Size
+         << ", .short " << Loc.Reg << ", .int " << Loc.Offset
+         << ", .byte " << OpType << ", .byte " << Op.Size << ", .short "
+         << Op.DwarfReg << ", .int64 " << (Op.isSymbol ? 0 : Op.Constant)
+         << "]\n";
+    }
   }
 }
 
@@ -277,6 +452,167 @@
   return LiveOuts;
 }
 
+/// Convert a list of instructions used to generate an architecture-specific
+/// live value into multiple individual records.
+void StackMaps::genArchValsFromInsts(ArchValues &AV,
+                                     Location &Loc,
+                                     const MachineLiveVal &MLV) {
+  assert(MLV.isGenerated() && "Invalid live value type");
+
+  typedef MachineGeneratedVal::ValueGenInst::InstType InstType;
+  typedef MachineGeneratedVal::ValueGenInst::OpType OpType;
+  typedef MachineGeneratedVal::RegInstructionBase RegInstruction;
+  typedef MachineGeneratedVal::ImmInstructionBase ImmInstruction;
+  typedef MachineGeneratedVal::PseudoInstructionBase PseudoInstruction;
+
+  const MachineGeneratedVal &MGV = (const MachineGeneratedVal &)MLV;
+  const MachineGeneratedVal::ValueGenInstList &I = MGV.getInstructions();
+  const TargetRegisterInfo *TRI = AP.MF->getSubtarget().getRegisterInfo();
+  const MachineFrameInfo *MFI = AP.MF->getFrameInfo();
+  const unsigned FBP = getDwarfRegNum(TRI->getFrameRegister(*AP.MF), TRI);
+  const unsigned FBPOff = AP.getFBPOffset();
+  Operation Op;
+
+  for(auto &Inst : I) {
+    const RegInstruction *RI;
+    const ImmInstruction *II;
+    const PseudoInstruction *PI;
+
+    switch(Inst->type()) {
+    case MachineGeneratedVal::ValueGenInst::StackSlot:
+      PI = (const PseudoInstruction *)Inst.get();
+      assert((PI->getGenType() == InstType::Add ||
+              PI->getGenType() == InstType::Set) &&
+             "Invalid frame object reference");
+
+      Loc.Ptr = true; // Enable pointer-to-stack fixups in runtime
+      Op.InstType = PI->getGenType();
+      Op.OperandType = Location::Direct;
+      Op.Size = AP.MF->getDataLayout().getPointerSizeInBits() / 8;
+      Op.DwarfReg = FBP;
+      Op.isSymbol = false;
+      Op.Constant = MFI->getObjectOffset(PI->getData()) + FBPOff;
+      break;
+    case MachineGeneratedVal::ValueGenInst::ConstantPool:
+      PI = (const PseudoInstruction *)Inst.get();
+      assert(PI->getGenType() == InstType::Set &&
+             "Invalid constant pool entry reference");
+
+      Op.InstType = PI->getGenType();
+      Op.OperandType = Location::Constant;
+      Op.Size = AP.MF->getDataLayout().getPointerSizeInBits() / 8;
+      Op.DwarfReg = 0;
+      Op.isSymbol = true;
+      Op.Symbol = AP.GetCPISymbol(PI->getData());
+      break;
+    case MachineGeneratedVal::ValueGenInst::Load:
+      RI = (const RegInstruction *)Inst.get();
+      assert(TRI->isPhysicalRegister(RI->getReg()) &&
+             "Virtual should have been converted to physical register");
+
+      Op.InstType = RI->type();
+      Op.OperandType = Location::Direct;
+      Op.Size = 8;
+      Op.DwarfReg = getDwarfRegNum(RI->getReg(), TRI);
+      Op.isSymbol = false;
+      Op.Constant = RI->getOffset();
+      break;
+    default:
+      Op.InstType = Inst->type();
+      Op.isSymbol = false;
+      switch(Inst->opType()) {
+      case OpType::Register:
+        RI = (const RegInstruction *)Inst.get();
+        assert(TRI->isPhysicalRegister(RI->getReg()) &&
+               "Virtual should have been converted to physical register");
+        Op.OperandType = Location::Register;
+        Op.Size = AP.MF->getDataLayout().getPointerSizeInBits() / 8;
+        Op.DwarfReg = getDwarfRegNum(RI->getReg(), TRI);
+        Op.Constant = 0;
+        break;
+      case OpType::Immediate:
+        II = (const ImmInstruction *)Inst.get();
+        Op.OperandType = Location::Constant;
+        Op.Size = II->getImmSize();
+        Op.DwarfReg = 0;
+        Op.Constant = II->getImm();
+        break;
+      default: llvm_unreachable("Invalid operand type"); break;
+      }
+      break;
+    }
+    AV.emplace_back(ArchValue(Loc, Op));
+  }
+}
+
+/// Add architecture-specific locations for the stackmap
+void StackMaps::addArchLiveVals(const CallInst *SM, ArchValues &AV) {
+  const TargetRegisterInfo *TRI = AP.MF->getSubtarget().getRegisterInfo();
+  const MachineFrameInfo *MFI = AP.MF->getFrameInfo();
+
+  if(AP.MF->hasSMArchSpecificLocations(SM)) {
+    const ArchLiveValues &Vals = AP.MF->getSMArchSpecificLocations(SM);
+    const unsigned FBPOff = AP.getFBPOffset();
+
+    for(auto &Val : Vals) {
+      Location Loc; Loc.Ptr = false;
+      Operation Op;
+
+      // Parse the location
+      if(Val.first->isReg()) {
+        const MachineLiveReg &MR = (const MachineLiveReg &)*Val.first;
+        unsigned Offset, DwarfRegNum;
+        const TargetRegisterClass *RC =
+          TRI->getMinimalPhysRegClass(MR.getReg());
+        getRegLocation(MR.getReg(), DwarfRegNum, Offset);
+
+        Loc.Type = Location::Register;
+        Loc.Size = RC->getSize();
+        Loc.Reg = DwarfRegNum;
+        Loc.Offset = Offset;
+      }
+      else if(Val.first->isStackSlot()) {
+        const MachineLiveStackSlot &MSS =
+          (const MachineLiveStackSlot &)*Val.first;
+        int StackSlot = MSS.getStackSlot();
+
+        Loc.Type = Location::Indirect;
+        Loc.Size = MFI->getObjectSize(StackSlot);
+        Loc.Reg = getDwarfRegNum(TRI->getFrameRegister(*AP.MF), TRI);
+        Loc.Offset = MFI->getObjectOffset(StackSlot) + FBPOff;
+      }
+      else llvm_unreachable("Invalid architecture-specific live value");
+
+      // Parse the operation
+      if(Val.second->isImm()) {
+        const MachineImmediate &MI = (const MachineImmediate &)*Val.second;
+        Op.InstType = MachineGeneratedVal::ValueGenInst::Set;
+        Op.OperandType = Location::Constant;
+        Op.Size = MI.getSize();
+        Op.DwarfReg = 0;
+        Op.Constant = MI.getValue();
+        AV.emplace_back(ArchValue(Loc, Op));
+      }
+      else if(Val.second->isReference()) {
+        const MachineReference &MR = (const MachineReference &)*Val.second;
+        Loc.Ptr = true;
+        Op.InstType = MachineGeneratedVal::ValueGenInst::Set;
+        Op.OperandType = Location::Constant;
+        Op.Size = AP.MF->getDataLayout().getPointerSizeInBits() / 8;
+        Op.DwarfReg = 0;
+        Op.isSymbol = true;
+        Op.Symbol = AP.OutContext.lookupSymbol(MR.getSymbol());
+        AV.emplace_back(ArchValue(Loc, Op));
+      }
+      // TODO generated vals may point to allocas, should we also mark them as
+      // pointers in order to do runtime checking?
+      else if(Val.second->isGenerated())
+        genArchValsFromInsts(AV, Loc, *Val.second);
+      else llvm_unreachable("Invalid architecture-specific live value");
+    }
+  }
+}
+
 void StackMaps::recordStackMapOpers(const MachineInstr &MI, uint64_t ID,
                                     MachineInstr::const_mop_iterator MOI,
                                     MachineInstr::const_mop_iterator MOE,
@@ -285,21 +621,46 @@
   MCContext &OutContext = AP.OutStreamer->getContext();
   MCSymbol *MILabel = OutContext.createTempSymbol();
   AP.OutStreamer->EmitLabel(MILabel);
+  User::const_op_iterator Op = nullptr;
 
   LocationVec Locations;
   LiveOutVec LiveOuts;
+  ArchValues Constants;
 
   if (recordResult) {
     assert(PatchPointOpers(&MI).hasDef() && "Stackmap has no return value.");
     parseOperand(MI.operands_begin(), std::next(MI.operands_begin()), Locations,
-                 LiveOuts);
+                 LiveOuts, Op);
   }
 
+  // Find the IR stackmap instruction which corresponds to MI so we can emit
+  // type information along with the value's location
+  const BasicBlock *BB = MI.getParent()->getBasicBlock();
+  const IntrinsicInst *IRSM = nullptr;
+  const std::string SMName("llvm.experimental.stackmap");
+  for(auto BBI = BB->begin(), BBE = BB->end(); BBI != BBE; BBI++)
+  {
+    const IntrinsicInst *II;
+    if((II = dyn_cast<IntrinsicInst>(&*BBI)) &&
+       II->getCalledFunction()->getName() == SMName &&
+       cast<ConstantInt>(II->getArgOperand(0))->getZExtValue() == ID)
+    {
+      IRSM = cast<IntrinsicInst>(&*BBI);
+      break;
+    }
+  }
+  assert(IRSM && "Could not find associated stackmap instruction");
+
   // Parse operands.
+  Op = std::next(IRSM->op_begin(), 2);
   while (MOI != MOE) {
-    MOI = parseOperand(MOI, MOE, Locations, LiveOuts);
+    MOI = parseOperand(MOI, MOE, Locations, LiveOuts, Op);
   }
+  assert(Op == (IRSM->op_end() - 1) && "did not lower all stackmap operands");
 
+  // Add architecture-specific live values
+  addArchLiveVals(IRSM, Constants);
+
   // Move large constants into the constant pool.
   for (auto &Loc : Locations) {
     // Constants are encoded as sign-extended integers.
@@ -327,8 +688,9 @@
       MCSymbolRefExpr::create(MILabel, OutContext),
       MCSymbolRefExpr::create(AP.CurrentFnSymForSize, OutContext), OutContext);
 
-  CSInfos.emplace_back(CSOffsetExpr, ID, std::move(Locations),
-                       std::move(LiveOuts));
+  CSInfos.emplace_back(AP.CurrentFnSym, CSOffsetExpr, ID,
+                       std::move(Locations), std::move(LiveOuts),
+                       std::move(Constants));
 
   // Record the stack size of the current function.
   const MachineFrameInfo *MFI = AP.MF->getFrameInfo();
@@ -411,8 +773,11 @@
 /// StkSizeRecord[NumFunctions] {
 ///   uint64 : Function Address
 ///   uint64 : Stack Size
+///   uint32 : Number of Unwinding Entries
+///   uint32 : Offset into Unwinding Section
 /// }
-void StackMaps::emitFunctionFrameRecords(MCStreamer &OS) {
+void StackMaps::emitFunctionFrameRecords(MCStreamer &OS,
+                                         const UnwindInfo *UI) {
   // Function Frame records.
   DEBUG(dbgs() << WSMP << "functions:\n");
   for (auto const &FR : FnStackSize) {
@@ -420,6 +785,15 @@
                  << " frame size: " << FR.second);
     OS.EmitSymbolValue(FR.first, 8);
     OS.EmitIntValue(FR.second, 8);
+
+    if(UI) {
+      const UnwindInfo::FuncUnwindInfo &FUI = UI->getUnwindInfo(FR.first);
+      DEBUG(dbgs() << " unwind info start: " << FUI.SecOffset
+                   << " (" << FUI.NumUnwindRecord << " entries)\n");
+      OS.EmitIntValue(FUI.NumUnwindRecord, 4);
+      OS.EmitIntValue(FUI.SecOffset, 4);
+    }
+    else OS.EmitIntValue(0, 8);
   }
 }
 
@@ -439,14 +813,20 @@
 ///
 /// StkMapRecord[NumRecords] {
 ///   uint64 : PatchPoint ID
+///   uint32 : Index of Function Record
 ///   uint32 : Instruction Offset
 ///   uint16 : Reserved (record flags)
 ///   uint16 : NumLocations
 ///   Location[NumLocations] {
-///     uint8  : Register | Direct | Indirect | Constant | ConstantIndex
-///     uint8  : Size in Bytes
-///     uint16 : Dwarf RegNum
-///     int32  : Offset
+///     uint8 (4 bits) : Register | Direct | Indirect | Constant | ConstantIndex
+///     uint8 (1 bit)  : Padding
+///     uint8 (1 bit)  : Is it a pointer?
+///     uint8 (1 bit)  : Is it an alloca?
+///     uint8 (1 bit)  : Is it a duplicate record for the same live value?
+///     uint8          : Size in Bytes
+///     uint16         : Dwarf RegNum
+///     int32          : Offset
+///     uint32         : Size of pointed-to alloca data
 ///   }
 ///   uint16 : Padding
 ///   uint16 : NumLiveOuts
@@ -455,6 +835,25 @@
 ///     uint8  : Reserved
 ///     uint8  : Size in Bytes
 ///   }
+///   uint16 : Padding
+///   uint16 : NumArchValues
+///   ArchValues[NumArchValues] {
+///     Location {
+///       uint8 (4 bits) : Register | Indirect
+///       uint8 (3 bits) : Padding
+///       uint8 (1 bit)  : Is it a pointer?
+///       uint8          : Size in Bytes
+///       uint16         : Dwarf RegNum
+///       int32          : Offset
+///     }
+///     Value {
+///       uint8_t (4 bits) : Instruction
+///       uint8_t (4 bits) : Register | Direct | Constant
+///       uint8_t          : Size
+///       uint16_t         : Dwarf RegNum
+///       int64_t          : Offset or Constant
+///     }
+///   }
 ///   uint32 : Padding (only if required to align to 8 byte)
 /// }
 ///
@@ -470,23 +869,29 @@
   for (const auto &CSI : CSInfos) {
     const LocationVec &CSLocs = CSI.Locations;
     const LiveOutVec &LiveOuts = CSI.LiveOuts;
+    const ArchValues &Values = CSI.Vals;
 
     // Verify stack map entry. It's better to communicate a problem to the
     // runtime than crash in case of in-process compilation. Currently, we do
     // simple overflow checks, but we may eventually communicate other
     // compilation errors this way.
-    if (CSLocs.size() > UINT16_MAX || LiveOuts.size() > UINT16_MAX) {
+    if (CSLocs.size() > UINT16_MAX || LiveOuts.size() > UINT16_MAX ||
+        Values.size() > UINT16_MAX) {
       OS.EmitIntValue(UINT64_MAX, 8); // Invalid ID.
+      OS.EmitIntValue(UINT32_MAX, 4); // Invalid index.
       OS.EmitValue(CSI.CSOffsetExpr, 4);
       OS.EmitIntValue(0, 2); // Reserved.
       OS.EmitIntValue(0, 2); // 0 locations.
       OS.EmitIntValue(0, 2); // padding.
       OS.EmitIntValue(0, 2); // 0 live-out registers.
+      OS.EmitIntValue(0, 2); // padding.
+      OS.EmitIntValue(0, 2); // 0 arch-specific values.
       OS.EmitIntValue(0, 4); // padding.
       continue;
     }
 
     OS.EmitIntValue(CSI.ID, 8);
+    OS.EmitIntValue(FnStackSize.find(CSI.Func) - FnStackSize.begin(), 4);
     OS.EmitValue(CSI.CSOffsetExpr, 4);
 
     // Reserved for flags.
@@ -494,10 +899,13 @@
     OS.EmitIntValue(CSLocs.size(), 2);
 
     for (const auto &Loc : CSLocs) {
-      OS.EmitIntValue(Loc.Type, 1);
+      uint8_t TypeAndFlags =
+        TYPE_AND_FLAGS(Loc.Type, Loc.Ptr, Loc.Alloca, Loc.Duplicate);
+      OS.EmitIntValue(TypeAndFlags, 1);
       OS.EmitIntValue(Loc.Size, 1);
       OS.EmitIntValue(Loc.Reg, 2);
       OS.EmitIntValue(Loc.Offset, 4);
+      OS.EmitIntValue(Loc.AllocaSize, 4);
     }
 
     // Num live-out registers and padding to align to 4 byte.
@@ -509,6 +917,31 @@
       OS.EmitIntValue(0, 1);
       OS.EmitIntValue(LO.Size, 1);
     }
+
+    // Num arch-specific constants and padding to align to 4 bytes.
+    OS.EmitIntValue(0, 2);
+    OS.EmitIntValue(Values.size(), 2);
+
+    for (const auto &C : Values) {
+      const Location &Loc = C.first;
+      const Operation &Op = C.second;
+
+      uint8_t TypeAndFlags = ARCH_TYPE_AND_FLAGS(Loc.Type, Loc.Ptr);
+      OS.EmitIntValue(TypeAndFlags, 1);
+      OS.EmitIntValue(Loc.Size, 1);
+      OS.EmitIntValue(Loc.Reg, 2);
+      OS.EmitIntValue(Loc.Offset, 4);
+
+      assert(!MachineGeneratedVal::ValueGenInst::PseudoInst[Op.InstType] &&
+             "Generated values should be lowered to non-pseudo instructions");
+      uint8_t OpType = ARCH_OP_TYPE(Op.InstType, Op.OperandType);
+      OS.EmitIntValue(OpType, 1);
+      OS.EmitIntValue(Op.Size, 1);
+      OS.EmitIntValue(Op.DwarfReg, 2);
+      if(Op.isSymbol) OS.EmitSymbolValue(Op.Symbol, 8);
+      else OS.EmitIntValue(Op.Constant, 8);
+    }
+
     // Emit alignment to 8 byte.
     OS.EmitValueToAlignment(8);
   }
@@ -515,7 +948,7 @@
 }
 
 /// Serialize the stackmap data.
-void StackMaps::serializeToStackMapSection() {
+void StackMaps::serializeToStackMapSection(const UnwindInfo *UI) {
   (void)WSMP;
   // Bail out if there's no stack map data.
   assert((!CSInfos.empty() || (CSInfos.empty() && ConstPool.empty())) &&
@@ -539,7 +972,7 @@
   // Serialize data.
   DEBUG(dbgs() << "********** Stack Map Output **********\n");
   emitStackmapHeader(OS);
-  emitFunctionFrameRecords(OS);
+  emitFunctionFrameRecords(OS, UI);
   emitConstantPoolEntries(OS);
   emitCallsiteEntries(OS);
   OS.AddBlankLine();
Index: lib/CodeGen/StackSlotColoring.cpp
===================================================================
--- lib/CodeGen/StackSlotColoring.cpp	(revision 277823)
+++ lib/CodeGen/StackSlotColoring.cpp	(working copy)
@@ -278,6 +278,7 @@
   SmallVector<int, 16> SlotMapping(NumObjs, -1);
   SmallVector<float, 16> SlotWeights(NumObjs, 0.0);
   SmallVector<SmallVector<int, 4>, 16> RevMap(NumObjs);
+  SmallDenseMap<int, int, 16> SlotChanges;
   BitVector UsedColors(NumObjs);
 
   DEBUG(dbgs() << "Color spill slot intervals:\n");
@@ -292,7 +293,9 @@
     SlotWeights[NewSS] += li->weight;
     UsedColors.set(NewSS);
     Changed |= (SS != NewSS);
+    if(SS != NewSS) SlotChanges[SS] = NewSS;
   }
+  MF.updateSMStackSlotRefs(SlotChanges);
 
   DEBUG(dbgs() << "\nSpill slots after coloring:\n");
   for (unsigned i = 0, e = SSIntervals.size(); i != e; ++i) {
Index: lib/CodeGen/StackTransformMetadata.cpp
===================================================================
--- lib/CodeGen/StackTransformMetadata.cpp	(nonexistent)
+++ lib/CodeGen/StackTransformMetadata.cpp	(working copy)
@@ -0,0 +1,998 @@
+//=== llvm/CodeGen/StackTransformMetadata.cpp - Stack Transformation Metadata ===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+//
+// This file accumulates additional data from machine functions needed to do
+// correct and complete stack transformation.
+//
+// Note: the dataflow analysis in this implementation assumes the ISA does not
+// allow memory-to-memory copies.
+//
+//===----------------------------------------------------------------------===//
+
+#include <queue>
+#include "llvm/CodeGen/LiveIntervalAnalysis.h"
+#include "llvm/CodeGen/LiveStackAnalysis.h"
+#include "llvm/CodeGen/MachineFrameInfo.h"
+#include "llvm/CodeGen/MachineFunction.h"
+#include "llvm/CodeGen/MachineRegisterInfo.h"
+#include "llvm/CodeGen/Passes.h"
+#include "llvm/CodeGen/StackMaps.h"
+#include "llvm/CodeGen/StackTransformTypes.h"
+#include "llvm/CodeGen/VirtRegMap.h"
+#include "llvm/IR/DiagnosticInfo.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/LLVMContext.h"
+#include "llvm/MC/MCSymbol.h"
+#include "llvm/Target/TargetInstrInfo.h"
+#include "llvm/Target/TargetValues.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "stacktransform"
+
+//===----------------------------------------------------------------------===//
+//                          StackTransformMetadata
+//===----------------------------------------------------------------------===//
+//
+// Run analyses over machine functions (before virtual register rewriting) to
+// glean additional information about live values.  This analysis finds
+// duplicate locations for live values (including backing stack slots and other
+// registers) and architecture-specific live values that must be materialized.
+//
+//===----------------------------------------------------------------------===//
+namespace {
+class StackTransformMetadata : public MachineFunctionPass {
+
+  /* Types */
+
+  /// A bundle tying together a stackmap IR instruction, the generated stackmap
+  /// machine instruction and the call machine instruction that caused the
+  /// stackmap to be emitted in the IR, respectively
+  typedef std::tuple<const CallInst *,
+                     const MachineInstr *,
+                     const MachineInstr *> SMInstBundle;
+
+  /// Getters for individual elements of instruction bundles
+  static inline const
+  CallInst *getIRSM(const SMInstBundle &B) { return std::get<0>(B); }
+  static inline const
+  MachineInstr *getMISM(const SMInstBundle &B) { return std::get<1>(B); }
+  static inline const
+  MachineInstr *getMICall(const SMInstBundle &B) { return std::get<2>(B); }
+
+  /// A vector of IR values.  Used when mapping from registers/stack slots to
+  /// IR values.
+  typedef SmallVector<const Value *, 4> ValueVec;
+  typedef std::shared_ptr<ValueVec> ValueVecPtr;
+
+  /// Mapping between virtual registers and IR operands
+  typedef std::pair<unsigned, ValueVecPtr> RegValsPair;
+  typedef std::map<unsigned, ValueVecPtr> RegValsMap;
+
+  /// Mapping between stackmaps and virtual registers referenced by the stackmap
+  typedef std::pair<const MachineInstr *, RegValsMap> SMVregsPair;
+  typedef std::map<const MachineInstr *, RegValsMap> SMVregsMap;
+
+  /// Mapping between stack slots and IR operands
+  typedef std::pair<int, ValueVecPtr> StackValsPair;
+  typedef std::map<int, ValueVecPtr> StackValsMap;
+
+  /// Mapping between stackmaps and stack slots referenced by the stackmap
+  typedef std::pair<const MachineInstr *, StackValsMap> SMStackSlotPair;
+  typedef std::map<const MachineInstr *, StackValsMap> SMStackSlotMap;
+
+  /// A value's spill location
+  class CopyLoc {
+  public:
+    enum Type { NONE, VREG, STACK_LOAD, STACK_STORE };
+    unsigned Vreg;
+    const MachineInstr *Instr;
+    CopyLoc() : Vreg(VirtRegMap::NO_PHYS_REG), Instr(nullptr) {}
+    CopyLoc(unsigned Vreg, const MachineInstr *Instr) :
+      Vreg(Vreg), Instr(Instr) {}
+    virtual CopyLoc *copy() const = 0;
+    virtual ~CopyLoc() {}
+    virtual Type getType() const = 0;
+  };
+  typedef std::shared_ptr<CopyLoc> CopyLocPtr;
+
+  /// A spill to a stack slot
+  class StackCopyLoc : public CopyLoc {
+  public:
+    int StackSlot;
+    StackCopyLoc() : StackSlot(VirtRegMap::NO_STACK_SLOT) {}
+    StackCopyLoc(unsigned Vreg, int StackSlot, const MachineInstr *Instr) :
+      CopyLoc(Vreg, Instr), StackSlot(StackSlot) {}
+    virtual CopyLoc *copy() const = 0;
+    virtual Type getType() const = 0;
+  };
+
+  /// A load from a stack slot
+  class StackLoadLoc : public StackCopyLoc {
+  public:
+    StackLoadLoc() {}
+    StackLoadLoc(unsigned Vreg, int StackSlot, const MachineInstr *Instr) :
+      StackCopyLoc(Vreg, StackSlot, Instr) {}
+    virtual CopyLoc *copy() const
+    { return new StackLoadLoc(Vreg, StackSlot, Instr); }
+    virtual Type getType() const { return CopyLoc::STACK_LOAD; }
+  };
+
+  /// A store to a stack slot
+  class StackStoreLoc : public StackCopyLoc {
+  public:
+    StackStoreLoc() {}
+    StackStoreLoc(unsigned Vreg, int StackSlot, const MachineInstr *Instr) :
+      StackCopyLoc(Vreg, StackSlot, Instr) {}
+    virtual CopyLoc *copy() const
+    { return new StackStoreLoc(Vreg, StackSlot, Instr); }
+    virtual Type getType() const { return CopyLoc::STACK_STORE; }
+  };
+
+  /// A spill to another register
+  class RegCopyLoc : public CopyLoc {
+  public:
+    unsigned SrcVreg;
+    RegCopyLoc() : SrcVreg(VirtRegMap::NO_PHYS_REG) {}
+    RegCopyLoc(unsigned DefVreg, unsigned SrcVreg, const MachineInstr *Instr) :
+      CopyLoc(DefVreg, Instr), SrcVreg(SrcVreg) {}
+    virtual CopyLoc *copy() const
+    { return new RegCopyLoc(Vreg, SrcVreg, Instr); }
+    virtual Type getType() const { return CopyLoc::VREG; }
+  };
+
+  /// Mapping between stack slots and copy locations (e.g., load from or store
+  /// to the stack slot)
+  typedef SmallVector<CopyLocPtr, 8> CopyLocVec;
+  typedef std::shared_ptr<CopyLocVec> CopyLocVecPtr;
+  typedef std::pair<int, CopyLocVecPtr> StackSlotCopyPair;
+  typedef std::map<int, CopyLocVecPtr> StackSlotCopies;
+
+  /* Data */
+
+  /// LLVM-provided analysis & metadata
+  MachineFunction *MF;
+  const MachineFrameInfo *MFI;
+  const MachineRegisterInfo *MRI;
+  const TargetInstrInfo *TII;
+  const TargetRegisterInfo *TRI;
+  const TargetValues *TVG;
+  const LiveIntervals *LI;
+  const LiveStacks *LS;
+  const SlotIndexes *Indexes;
+  const VirtRegMap *VRM;
+
+  /// Stackmap/call instructions, mapping of virtual registers & stack slots to
+  /// IR values, list of instructions that copy to/from the stack
+  SmallVector<SMInstBundle, 32> SM;
+  SMVregsMap SMVregs;
+  SMStackSlotMap SMStackSlots;
+  StackSlotCopies SSUses;
+
+  /* Functions */
+
+  // Reset the analysis for a new function
+  void reset() {
+    SM.clear();
+    SMVregs.clear();
+    SMStackSlots.clear();
+    SSUses.clear();
+  }
+
+  /// Print information about a virtual register and it's associated IR value
+  void dumpReg(unsigned Reg, const Value *IRVal) const;
+
+  /// Print information about a stack slot and it's associated IR value
+  void dumpStackSlot(int SS, const Value *IRVal) const;
+
+  /// Analyze a machine instruction to see if a value is getting copied from
+  /// another location such as a stack slot or register.
+  CopyLocPtr getCopyLocation(const MachineInstr *MI) const;
+
+  /// Gather stackmap machine instructions, the IR instructions which generated
+  /// the stackmaps, and their associated call machine instructions.  Also,
+  /// find copies to/from stack slots (since there's no other mechanism to
+  /// find/traverse them).
+  void findStackmapsAndStackSlotCopies();
+
+  /// Find all virtual register/stack slot operands in a stackmap and collect
+  /// virtual register/stack slot <-> IR value mappings
+  void mapOpsToIR(const CallInst *IRSM, const MachineInstr *MISM);
+
+  /// Is a virtual register live across the machine instruction?
+  /// Note: returns false if the MI is the last instruction for which the
+  /// virtual register is alive
+  bool isVregLiveAcrossInstr(unsigned Vreg, const MachineInstr *MI) const;
+
+  /// Is a stack slot live across the machine instruction?
+  /// Note: returns false if the MI is the last instruction for which the stack
+  /// slot is alive
+  bool isSSLiveAcrossInstr(int SS, const MachineInstr *MI) const;
+
+  /// Add duplicate location information for a virtual register.  Return true
+  /// if metadata was added, or false if the virtual register is not live
+  /// across the call instruction/stackmap.
+  bool addVregMetadata(unsigned Vreg,
+                       ValueVecPtr IRVals,
+                       const SMInstBundle &SM);
+
+  /// Add duplicate location information for a stack slot.  Return true if
+  /// metadata was added, or false if the stack slot is not live across the
+  /// call instruction/stackmap.
+  bool addSSMetadata(int SS, ValueVecPtr IRVals, const SMInstBundle &SM);
+
+  /// Search stack slot copies for additional virtual registers which are live
+  /// across the stackmap.  Will check to see if the copy instructions have
+  /// already been visited, and if appropriate, will add virtual registers to
+  /// work queue.
+  void inline
+  searchStackSlotCopies(int SS,
+                        ValueVecPtr IRVals,
+                        const SMInstBundle &SM,
+                        SmallPtrSet<const MachineInstr *, 32> &Visited,
+                        std::queue<unsigned> &work);
+
+  /// Find all alternate locations for virtual registers in a stackmap, and add
+  /// them to the metadata to be generated.
+  void findAlternateVregLocs(const SMInstBundle &SM);
+
+  /// Find stackmap operands that have been spilled to alternate locations
+  void findAlternateOpLocs();
+
+  /// Ensure virtual registers used to generate architecture-specific values
+  /// are handled by the stackmap & convert to physical registers
+  void sanitizeVregs(MachineLiveValPtr &LV, const MachineInstr *SM) const;
+
+  /// Analyze a machine instruction to find the value being used.  Needs the
+  /// call instruction to ensure values are generated correctly and are valid.
+  MachineLiveValPtr getTargetValue(const MachineInstr *MI,
+                                   const MachineInstr *Call) const;
+
+  /// Find architecture-specific live values added by the backend
+  void findArchSpecificLiveVals();
+
+  /// Warn about unhandled registers & stack slots
+  void warnUnhandled() const;
+
+public:
+  static char ID;
+  static const std::string SMName;
+
+  StackTransformMetadata() : MachineFunctionPass(ID) {}
+
+  virtual void getAnalysisUsage(AnalysisUsage &AU) const override;
+
+  virtual bool runOnMachineFunction(MachineFunction&) override;
+
+};
+
+} // end anonymous namespace
+
+char &llvm::StackTransformMetadataID = StackTransformMetadata::ID;
+const std::string StackTransformMetadata::SMName("llvm.experimental.stackmap");
+
+INITIALIZE_PASS_BEGIN(StackTransformMetadata, "stacktransformmetadata",
+  "Gather stack transformation metadata", false, true)
+INITIALIZE_PASS_DEPENDENCY(SlotIndexes)
+INITIALIZE_PASS_DEPENDENCY(LiveIntervals)
+INITIALIZE_PASS_DEPENDENCY(LiveStacks)
+INITIALIZE_PASS_DEPENDENCY(VirtRegMap)
+INITIALIZE_PASS_END(StackTransformMetadata, "stacktransformmetadata",
+  "Gather stack transformation metadata", false, true)
+
+char StackTransformMetadata::ID = 0;
+
+void StackTransformMetadata::getAnalysisUsage(AnalysisUsage &AU) const {
+  AU.setPreservesAll();
+  AU.addRequired<LiveIntervals>();
+  AU.addRequired<LiveStacks>();
+  AU.addRequired<SlotIndexes>();
+  AU.addRequired<VirtRegMap>();
+  MachineFunctionPass::getAnalysisUsage(AU);
+}
+
+bool StackTransformMetadata::runOnMachineFunction(MachineFunction &fn) {
+  if(fn.getFrameInfo()->hasStackMap()) {
+    MF = &fn;
+    MFI = MF->getFrameInfo();
+    MRI = &MF->getRegInfo();
+    TII = MF->getSubtarget().getInstrInfo();
+    TRI = MF->getSubtarget().getRegisterInfo();
+    TVG = MF->getSubtarget().getValues();
+    Indexes = &getAnalysis<SlotIndexes>();
+    LI = &getAnalysis<LiveIntervals>();
+    LS = &getAnalysis<LiveStacks>();
+    VRM = &getAnalysis<VirtRegMap>();
+    reset();
+
+    DEBUG(
+      dbgs() << "\n********** STACK TRANSFORMATION METADATA **********\n"
+             << "********** Function: " << MF->getName() << '\n';
+      VRM->dump();
+    );
+
+    findStackmapsAndStackSlotCopies();
+    findAlternateOpLocs();
+    findArchSpecificLiveVals();
+    warnUnhandled();
+  }
+
+  return false;
+}
+
+/// Print information about a virtual register and it's associated IR value
+void StackTransformMetadata::dumpReg(unsigned Reg, const Value *IRVal) const {
+  IRVal->printAsOperand(dbgs());
+  if(TargetRegisterInfo::isPhysicalRegister(Reg))
+    dbgs() << ": in register " << PrintReg(Reg, TRI);
+  else {
+    assert(VRM->hasPhys(Reg) && "Invalid virtual register");
+    unsigned Phys = VRM->getPhys(Reg);
+    dbgs() << ": in register " << PrintReg(Phys, TRI)
+           << " (vreg " << TargetRegisterInfo::virtReg2Index(Reg) << ")";
+  }
+  dbgs() << "\n";
+}
+
+/// Print information about a stack slot and it's associated IR value
+void StackTransformMetadata::dumpStackSlot(int SS, const Value *IRVal) const {
+  assert(!MFI->isDeadObjectIndex(SS) && "Invalid stack slot");
+  IRVal->printAsOperand(dbgs());
+  dbgs() << ": in stack slot " << SS << " (size: " << MFI->getObjectSize(SS)
+         << ")\n";
+}
+
+/// Analyze a machine instruction to see if a value is getting copied from
+/// another location such as a stack slot or register.
+StackTransformMetadata::CopyLocPtr
+StackTransformMetadata::getCopyLocation(const MachineInstr *MI) const {
+  unsigned SrcVreg = 0;
+  unsigned DefVreg = 0;
+  int SS;
+
+  assert(MI && "Invalid machine instruction");
+
+  // Is it a copy from another register?
+  if(MI->isCopyLike()) {
+    for(unsigned i = 0, e = MI->getNumOperands(); i != e; i++) {
+      const MachineOperand &MO = MI->getOperand(i);
+      if(MO.isReg()) {
+        if(MO.isDef()) DefVreg = MO.getReg();
+        else SrcVreg = MO.getReg();
+      }
+    }
+
+    // TODO does it have to be a virtual register or can it be a physical one?
+    // Liveness analysis seems to apply only to virtual registers.
+    if(TargetRegisterInfo::isVirtualRegister(SrcVreg) &&
+       TargetRegisterInfo::isVirtualRegister(DefVreg))
+      return CopyLocPtr(new RegCopyLoc(DefVreg, SrcVreg, MI));
+  }
+
+  // Is it a load from the stack?
+  if((DefVreg = TII->isLoadFromStackSlot(MI, SS)) &&
+     TargetRegisterInfo::isVirtualRegister(DefVreg))
+    return CopyLocPtr(new StackLoadLoc(DefVreg, SS, MI));
+
+  // Is it a store to the stack?
+  if((SrcVreg = TII->isStoreToStackSlot(MI, SS)) &&
+     TargetRegisterInfo::isVirtualRegister(SrcVreg))
+    return CopyLocPtr(new StackStoreLoc(SrcVreg, SS, MI));
+
+  // A non-copylike instruction
+  return CopyLocPtr(nullptr);
+}
+
+/// Gather stackmap machine instructions, the IR instructions which generated
+/// the stackmaps, and their associated call machine instructions.  Also,
+/// find copies to/from stack slots (since there's no other mechanism to
+/// find/traverse them).
+void StackTransformMetadata::findStackmapsAndStackSlotCopies() {
+  for(auto MBB = MF->begin(), MBBE = MF->end(); MBB != MBBE; MBB++) {
+    for(auto MI = MBB->instr_begin(), ME = MBB->instr_end(); MI != ME; MI++) {
+      if(MI->getOpcode() == TargetOpcode::STACKMAP) {
+        // Find the stackmap IR instruction
+        assert(MI->getOperand(0).isImm() && "Invalid stackmap ID");
+        int64_t ID = MI->getOperand(0).getImm();
+        const BasicBlock *BB = MI->getParent()->getBasicBlock();
+        const CallInst *IRSM = nullptr;
+        for(auto I = BB->begin(), IE = BB->end(); I != IE; I++)
+        {
+          const IntrinsicInst *II;
+          if((II = dyn_cast<IntrinsicInst>(&*I)) &&
+             II->getCalledFunction()->getName() == SMName &&
+             cast<ConstantInt>(II->getArgOperand(0))->getSExtValue() == ID) {
+            IRSM = cast<CallInst>(II);
+            break;
+          }
+        }
+        assert(IRSM && "Could not find stackmap IR instruction");
+
+        // Find the call instruction
+        const MachineInstr *MCI = MI->getPrevNode();
+        while(MCI != nullptr) {
+          if(MCI->isCall()) {
+            if(MCI->getOpcode() == TargetOpcode::STACKMAP)
+              MCI = nullptr;
+            break;
+          }
+          MCI = MCI->getPrevNode();
+        }
+
+        if(!MCI) {
+          DEBUG(dbgs() << "NOTE: stackmap " << ID << " ";
+                IRSM->print(dbgs());
+                dbgs() << ": could not find associated call instruction "
+                          "(lowered to a native instruction?)\n");
+          continue;
+        }
+
+        SM.push_back(SMInstBundle(IRSM, &*MI, MCI));
+      }
+      else {
+        // See if instruction copies to/from stack slot
+        StackSlotCopies::iterator it;
+        CopyLocPtr loc;
+
+        if(!(loc = getCopyLocation(&*MI))) continue;
+        enum CopyLoc::Type type = loc->getType();
+        if(type == CopyLoc::STACK_LOAD || type == CopyLoc::STACK_STORE) {
+          StackCopyLoc *SCL = (StackCopyLoc *)loc.get();
+          if((it = SSUses.find(SCL->StackSlot)) == SSUses.end()) {
+            StackSlotCopyPair ins(SCL->StackSlot,
+                                  CopyLocVecPtr(new CopyLocVec));
+            it = SSUses.insert(std::move(ins)).first;
+          }
+          it->second->push_back(loc);
+        }
+      }
+    }
+  }
+}
+
+/// Find all virtual register/stack slot operands in a stackmap and collect
+/// virtual register/stack slot <-> IR value mappings
+void StackTransformMetadata::mapOpsToIR(const CallInst *IRSM,
+                                        const MachineInstr *MISM) {
+  RegValsMap::iterator VregIt;
+  StackValsMap::iterator SSIt;
+  MachineInstr::const_mop_iterator MOit;
+  CallInst::const_op_iterator IRit;
+
+  // Initialize new storage location/IR map objects (i.e., for virtual
+  // registers & stack slots) for the stackmap
+  SMVregs.insert(SMVregsPair(MISM, RegValsMap()));
+  SMStackSlots.insert(SMStackSlotPair(MISM, StackValsMap()));
+
+  // Loop over all operands
+  for(MOit = std::next(MISM->operands_begin(), 2),
+      IRit = std::next(IRSM->op_begin(), 2);
+      MOit != MISM->operands_end() && IRit != (IRSM->op_end() - 1);
+      MOit++, IRit++) {
+    if(MOit->isImm()) { // Map IR values to stack slots
+      int FrameIdx = INT32_MAX;
+      const Value *IRVal = IRit->get();
+
+      switch(MOit->getImm()) {
+      case StackMaps::DirectMemRefOp:
+        MOit++;
+        assert(MOit->isFI() && "Invalid operand type");
+        FrameIdx = MOit->getIndex();
+        MOit++;
+        break;
+      case StackMaps::IndirectMemRefOp:
+        MOit++; MOit++;
+        assert(MOit->isFI() && "Invalid operand type");
+        FrameIdx = MOit->getIndex();
+        MOit++;
+        break;
+      case StackMaps::ConstantOp: MOit++; continue;
+      default: llvm_unreachable("Unrecognized stackmap operand type"); break;
+      }
+
+      assert(IRVal && "Invalid stackmap IR operand");
+      assert(MFI->getObjectIndexBegin() <= FrameIdx &&
+             FrameIdx <= MFI->getObjectIndexEnd() && "Invalid frame index");
+      assert(!MFI->isDeadObjectIndex(FrameIdx) && "Dead frame index");
+      DEBUG(dumpStackSlot(FrameIdx, IRVal););
+
+      // Update the list of IR values mapped to the stack slot (multiple IR
+      // values may be mapped to a single stack slot).
+      SSIt = SMStackSlots[MISM].find(FrameIdx);
+      if(SSIt == SMStackSlots[MISM].end()) {
+        StackValsPair OpMap(FrameIdx, ValueVecPtr(new ValueVec));
+        SSIt = SMStackSlots[MISM].insert(std::move(OpMap)).first;
+      }
+      SSIt->second->push_back(IRVal);
+    }
+    else if(MOit->isReg()) { // Map IR values to virtual registers
+      const Value *IRVal = IRit->get();
+      unsigned Reg = MOit->getReg();
+
+      assert(IRVal && "Invalid stackmap IR operand");
+      assert(TargetRegisterInfo::isVirtualRegister(Reg) &&
+             "Should not have been converted to physical registers yet");
+      DEBUG(dumpReg(Reg, IRVal););
+
+      // Update the list of IR values mapped to the virtual register (multiple
+      // IR values may be mapped to a single virtual register).
+      VregIt = SMVregs[MISM].find(Reg);
+      if(VregIt == SMVregs[MISM].end()) {
+        RegValsPair OpMap(Reg, ValueVecPtr(new ValueVec));
+        VregIt = SMVregs[MISM].insert(std::move(OpMap)).first;
+      }
+      VregIt->second->push_back(IRVal);
+    } else {
+      llvm_unreachable("Unrecognized stackmap operand type.");
+    }
+  }
+  assert(IRit == (IRSM->op_end() - 1) && "Did not search all stackmap operands");
+}
+
+/// Is a virtual register live across the machine instruction?
+/// Note: returns false if the MI is the last instruction for which the virtual
+/// register is alive
+bool
+StackTransformMetadata::isVregLiveAcrossInstr(unsigned Vreg,
+                                              const MachineInstr *MI) const {
+  assert(TRI->isVirtualRegister(Vreg) && "Invalid virtual register");
+
+  if(LI->hasInterval(Vreg)) {
+    const LiveInterval &TheLI = LI->getInterval(Vreg);
+    SlotIndex InstrIdx = Indexes->getInstructionIndex(MI);
+    LiveInterval::const_iterator Seg = TheLI.find(InstrIdx);
+    if(Seg != TheLI.end() && Seg->contains(InstrIdx) &&
+       InstrIdx.getInstrDistance(Seg->end) != 0)
+      return true;
+  }
+  return false;
+}
+
+/// Is a stack slot live across the machine instruction?
+/// Note: returns false if the MI is the last instruction for which the stack
+/// slot is alive
+bool
+StackTransformMetadata::isSSLiveAcrossInstr(int SS,
+                                            const MachineInstr *MI) const {
+  if(LS->hasInterval(SS)) {
+    const LiveInterval &TheLI = LS->getInterval(SS);
+    SlotIndex InstrIdx = Indexes->getInstructionIndex(MI);
+    LiveInterval::const_iterator Seg = TheLI.find(InstrIdx);
+    if(Seg != TheLI.end() && Seg->contains(InstrIdx) &&
+       InstrIdx.getInstrDistance(Seg->end) != 0)
+      return true;
+  }
+  return false;
+}
+
+/// Add duplicate location information for a virtual register.
+bool StackTransformMetadata::addVregMetadata(unsigned Vreg,
+                                             ValueVecPtr IRVals,
+                                             const SMInstBundle &SM) {
+  const CallInst *IRSM = getIRSM(SM);
+  const MachineInstr *MISM = getMISM(SM);
+  const MachineInstr *MICall = getMICall(SM);
+  RegValsMap &Vregs = SMVregs[MISM];
+
+  assert(TargetRegisterInfo::isVirtualRegister(Vreg) && VRM->hasPhys(Vreg) &&
+         "Cannot add virtual register metadata -- invalid virtual register");
+
+  if(Vregs.find(Vreg) == Vregs.end() &&
+     (isVregLiveAcrossInstr(Vreg, MISM) || isVregLiveAcrossInstr(Vreg, MICall)))
+  {
+    unsigned Phys = VRM->getPhys(Vreg);
+    for(size_t sz = 0; sz < IRVals->size(); sz++) {
+      DEBUG(dumpReg(Vreg, (*IRVals)[sz]););
+      MF->addSMOpLocation(IRSM, (*IRVals)[sz], MachineLiveReg(Phys));
+    }
+    Vregs[Vreg] = IRVals;
+    return true;
+  }
+  else return false;
+}
+
+/// Add duplicate location information for a stack slot.
+bool StackTransformMetadata::addSSMetadata(int SS,
+                                           ValueVecPtr IRVals,
+                                           const SMInstBundle &SM) {
+  const CallInst *IRSM = getIRSM(SM);
+  const MachineInstr *MISM = getMISM(SM);
+  const MachineInstr *MICall = getMICall(SM);
+  StackValsMap &SSlots = SMStackSlots[MISM];
+
+  assert(!MFI->isDeadObjectIndex(SS) &&
+         "Cannot add stack slot metadata -- invalid stack slot");
+
+  if(SSlots.find(SS) == SSlots.end() &&
+     (isSSLiveAcrossInstr(SS, MISM) || isSSLiveAcrossInstr(SS, MICall)))
+  {
+    for(size_t sz = 0; sz < IRVals->size(); sz++) {
+      DEBUG(dumpStackSlot(SS, (*IRVals)[sz]););
+      MF->addSMOpLocation(IRSM, (*IRVals)[sz], MachineLiveStackSlot(SS));
+    }
+    SSlots[SS] = IRVals;
+    return true;
+  }
+  else return false;
+}
+
+/// Search stack slot copies for additional virtual registers which are live
+/// across the stackmap.  Will check to see if the copy instructions have
+/// already been visited, and if appropriate, will add virtual registers to
+/// work queue.
+void inline
+StackTransformMetadata::searchStackSlotCopies(int SS,
+                                       ValueVecPtr IRVals,
+                                       const SMInstBundle &SM,
+                                       SmallPtrSet<const MachineInstr *, 32> &Visited,
+                                       std::queue<unsigned> &work) {
+  StackSlotCopies::const_iterator Copies;
+  CopyLocVecPtr CL;
+  CopyLocVec::const_iterator Copy, CE;
+
+  if((Copies = SSUses.find(SS)) != SSUses.end()) {
+    CL = Copies->second;
+    for(Copy = CL->begin(), CE = CL->end(); Copy != CE; Copy++) {
+      unsigned Vreg = (*Copy)->Vreg;
+      const MachineInstr *Instr = (*Copy)->Instr;
+
+      if(!Visited.count(Instr)) {
+        addVregMetadata(Vreg, IRVals, SM);
+        Visited.insert(Instr);
+        work.push(Vreg);
+      }
+    }
+  }
+}
+
+/// Find all alternate locations for virtual registers in a stackmap, and add
+/// them to the metadata to be generated.
+void
+StackTransformMetadata::findAlternateVregLocs(const SMInstBundle &SM) {
+  RegValsMap &Vregs = SMVregs[getMISM(SM)];
+  std::queue<unsigned> work;
+  SmallPtrSet<const MachineInstr *, 32> Visited;
+  StackCopyLoc *SCL;
+  RegCopyLoc *RCL;
+
+  DEBUG(dbgs() << "\nDuplicate operand locations:\n\n";);
+
+  // Iterate over all vregs in the stackmap
+  for(RegValsMap::iterator it = Vregs.begin(), end = Vregs.end();
+      it != end; it++) {
+    unsigned origVreg = it->first;
+    ValueVecPtr IRVals = it->second;
+    Visited.clear();
+
+    // Follow data flow to search for all duplicate locations, including stack
+    // slots and other registers.  It's a duplicate if the following are true:
+    //
+    //   1. It's a copy-like instruction, e.g., a register move or a load
+    //      from/store to stack slot
+    //   2. The alternate location (virtual register/stack slot) is live across
+    //      either the machine call instruction or the stackmap
+    //
+    // Note: we *must* search exhaustively (i.e., across copies from registers
+    // that are *not* live across the call) because the following can happen:
+    //
+    //   STORE vreg0, <fi#0>
+    //   ...
+    //   COPY vreg0, vreg1
+    //   ...
+    //   STACKMAP 0, 0, vreg1
+    //
+    // Here, vreg0 is *not* live across the stackmap, but <fi#0> *is*
+    //
+    work.push(origVreg);
+    while(!work.empty()) {
+      unsigned cur, vreg;
+      int ss;
+
+      // Walk over definitions
+      cur = work.front();
+      work.pop();
+      for(auto instr = MRI->def_instr_begin(cur), ei = MRI->def_instr_end();
+          instr != ei;
+          instr++) {
+        if(Visited.count(&*instr)) continue;
+        CopyLocPtr loc = getCopyLocation(&*instr);
+        if(!loc) continue;
+
+        switch(loc->getType()) {
+        case CopyLoc::VREG:
+          RCL = (RegCopyLoc *)loc.get();
+          vreg = RCL->SrcVreg;
+          addVregMetadata(vreg, IRVals, SM);
+          Visited.insert(&*instr);
+          work.push(vreg);
+          break;
+        case CopyLoc::STACK_LOAD:
+          SCL = (StackCopyLoc *)loc.get();
+          ss = SCL->StackSlot;
+          if(addSSMetadata(ss, IRVals, SM)) {
+            Visited.insert(&*instr);
+            searchStackSlotCopies(ss, IRVals, SM, Visited, work);
+          }
+          break;
+        default: llvm_unreachable("Unknown/invalid location type"); break;
+        }
+      }
+
+      // Walk over uses
+      for(auto instr = MRI->use_instr_begin(cur), ei = MRI->use_instr_end();
+          instr != ei; instr++) {
+        if(Visited.count(&*instr)) continue;
+        CopyLocPtr loc = getCopyLocation(&*instr);
+        if(!loc) continue;
+
+        switch(loc->getType()) {
+        case CopyLoc::VREG:
+          RCL = (RegCopyLoc *)loc.get();
+          vreg = RCL->Vreg;
+          addVregMetadata(vreg, IRVals, SM);
+          Visited.insert(&*instr);
+          work.push(vreg);
+          break;
+        case CopyLoc::STACK_STORE:
+          SCL = (StackCopyLoc *)loc.get();
+          ss = SCL->StackSlot;
+          if(addSSMetadata(ss, IRVals, SM)) {
+            Visited.insert(&*instr);
+            searchStackSlotCopies(ss, IRVals, SM, Visited, work);
+          }
+          break;
+        default: llvm_unreachable("Unknown/invalid location type"); break;
+        }
+      }
+    }
+  }
+}
+
+/// Find alternate storage locations for stackmap operands
+void StackTransformMetadata::findAlternateOpLocs() {
+  RegValsMap::iterator vregIt, vregEnd;
+
+  for(auto S = SM.begin(), SE = SM.end(); S != SE; S++) {
+    const CallInst *IRSM = getIRSM(*S);
+    const MachineInstr *MISM = getMISM(*S);
+
+    DEBUG(
+      dbgs() << "\nStackmap " << MISM->getOperand(0).getImm() << ":\n";
+      MISM->dump();
+      dbgs() << "\n";
+    );
+
+    // Get all virtual register/stack slot operands & their associated IR
+    // values
+    mapOpsToIR(IRSM, MISM);
+
+    // Find alternate locations for vregs in stack map.  Note we don't need to
+    // find alternate stack slot locations, as allocas *should* already be in
+    // the stackmap, so the remaining stack slots are spilled registers (which
+    // are covered here).
+    findAlternateVregLocs(*S);
+  }
+}
+
+/// Ensure virtual registers used to generate architecture-specific values are
+/// handled by the stackmap & convert to physical registers
+void StackTransformMetadata::sanitizeVregs(MachineLiveValPtr &LV,
+                                           const MachineInstr *SM) const {
+  typedef MachineGeneratedVal::ValueGenInst::OpType OpType;
+  typedef MachineGeneratedVal::RegInstructionBase RegInstruction;
+
+  if(!LV) return;
+  if(LV->isGenerated()) {
+    MachineGeneratedVal *MGV = (MachineGeneratedVal *)LV.get();
+    MachineGeneratedVal::ValueGenInstList &Inst = MGV->getInstructions();
+    for(size_t i = 0, num = Inst.size(); i < num; i++) {
+      if(Inst[i]->opType() == OpType::Register) {
+        RegInstruction *RI = (RegInstruction *)Inst[i].get();
+        if(!TRI->isVirtualRegister(RI->getReg())) {
+          if(RI->getReg() == TRI->getFrameRegister(*MF)) continue;
+          // TODO walk through stackmap and see if physical register in
+          // instruction is contained in stackmap
+          LV.reset(nullptr);
+          return;
+        }
+        else if(!SMVregs.at(SM).count(RI->getReg())) {
+          DEBUG(dbgs() << "WARNING: vreg "
+                       << TargetRegisterInfo::virtReg2Index(RI->getReg())
+                       << " used to generate value not handled in stackmap\n");
+          LV.reset(nullptr);
+          return;
+        }
+        else {
+          assert(VRM->hasPhys(RI->getReg()) && "Invalid virtual register");
+          RI->setReg(VRM->getPhys(RI->getReg()));
+        }
+      }
+    }
+  }
+}
+
+/// Analyze a machine instruction to find the value being used.  Needs the call
+/// instruction to ensure values are generated correctly and are valid.
+MachineLiveValPtr
+StackTransformMetadata::getTargetValue(const MachineInstr *MI,
+                                       const MachineInstr *SM) const {
+  if(!MI) return MachineLiveValPtr(nullptr);
+
+  // Immediates can be handled in an architecture-agnostic way
+  if(MI->isMoveImmediate()) {
+    unsigned Size = 8;
+    uint64_t Value = UINT64_MAX;
+    for(unsigned i = 0, e = MI->getNumOperands(); i < e; i++) {
+      const MachineOperand &MO = MI->getOperand(i);
+      if(MO.isImm()) Value = MO.getImm();
+      if(MO.isFPImm()) {
+        // We need to encode the bits exactly as they are to represent the
+        // double, so switch types and read relevant info
+        APInt Bits(MO.getFPImm()->getValueAPF().bitcastToAPInt());
+        Size = Bits.getBitWidth() / 8;
+        Value = Bits.getZExtValue();
+      }
+    }
+    return MachineLiveValPtr(new MachineImmediate(Size, Value, MI));
+  }
+  // Otherwise, drop to architecture-specific value generator
+  else {
+    MachineLiveValPtr MLV = TVG->getMachineValue(MI);
+    sanitizeVregs(MLV, SM);
+    return MLV;
+  }
+}
+
+/// Find architecture-specific live values added by the backend
+void StackTransformMetadata::findArchSpecificLiveVals() {
+  DEBUG(dbgs() << "\n*** Finding architecture-specific live values ***\n\n";);
+
+  for(auto S = SM.begin(), SE = SM.end(); S != SE; S++)
+  {
+    const MachineInstr *MISM = getMISM(*S);
+    const MachineInstr *MICall = getMICall(*S);
+    const CallInst *IRSM = getIRSM(*S);
+    RegValsMap &CurVregs = SMVregs[MISM];
+    StackValsMap &CurSS = SMStackSlots[MISM];
+
+    DEBUG(
+      MISM->dump();
+      dbgs() << "  -> Call instruction SlotIndex ";
+      Indexes->getInstructionIndex(MICall).print(dbgs());
+      dbgs() << ", searching vregs 0 -> " << MRI->getNumVirtRegs()
+             << " and stack slots " << MFI->getObjectIndexBegin() << " -> "
+             << MFI->getObjectIndexEnd() << "\n";
+    );
+
+    // Search for virtual registers not handled by the stackmap.  Registers
+    // spilled to the stack should have been converted to frame index
+    // references by now.
+    for(unsigned i = 0, numVregs = MRI->getNumVirtRegs(); i < numVregs; i++) {
+      unsigned Vreg = TargetRegisterInfo::index2VirtReg(i);
+      MachineLiveValPtr MC;
+      MachineLiveReg MLR(0);
+
+      if(VRM->hasPhys(Vreg) && isVregLiveAcrossInstr(Vreg, MICall) &&
+         CurVregs.find(Vreg) == CurVregs.end()) {
+        DEBUG(dbgs() << "    + vreg" << i
+                     << " is live in register but not in stackmap\n";);
+
+        if(!MRI->hasOneDef(Vreg)) {
+          DEBUG(
+            dbgs() << "WARNING: multiple definitions for virtual "
+                      "register, missed in live-value analysis?\n";
+            for(auto d = MRI->def_instr_begin(Vreg), e = MRI->def_instr_end();
+                d != e; d++)
+              d->dump();
+          );
+          continue;
+        }
+
+        MC = getTargetValue(&*MRI->def_instr_begin(Vreg), MISM);
+        if(MC) {
+          DEBUG(dbgs() << "      Defining instruction: ";
+                MC->getDefiningInst()->print(dbgs());
+                dbgs() << "      Value: " << MC->toString() << "\n");
+
+          MLR.setReg(VRM->getPhys(Vreg));
+          MF->addSMArchSpecificLocation(IRSM, MLR, *MC);
+          CurVregs.insert(RegValsPair(Vreg, ValueVecPtr(nullptr)));
+        }
+        else {
+          DEBUG(dbgs() << "      Unhandled defining instruction: ";
+                MRI->def_instr_begin(Vreg)->print(dbgs());
+                dbgs() << "\n");
+        }
+      }
+    }
+
+    // Search for stack slots not handled by the stackmap
+    // TODO handle function arguments on the stack (negative stack slots)
+    for(int SS = MFI->getObjectIndexBegin(), e = MFI->getObjectIndexEnd();
+        SS < e; SS++) {
+      if(!MFI->isDeadObjectIndex(SS) &&
+         isSSLiveAcrossInstr(SS, MICall) && CurSS.find(SS) == CurSS.end()) {
+        DEBUG(dbgs() << "    + stack slot " << SS
+                     << " is live but not in stackmap\n";);
+        // TODO add arch-specific stack slot information to machine function
+      }
+    }
+
+    DEBUG(dbgs() << "\n";);
+  }
+}
+
+/// Find IR call instruction which generated the stackmap
+static inline const CallInst *findCalledFunc(const llvm::CallInst *IRSM) {
+  const Instruction *Func = IRSM->getPrevNode();
+  while(Func && !isa<CallInst>(Func)) Func = Func->getPrevNode();
+  return dyn_cast<CallInst>(Func);
+}
+
+/// Display a warning about unhandled values
+static inline void displayWarning(std::string &Msg,
+                                  const CallInst *CI,
+                                  const Function *F) {
+  assert(CI && "Invalid arguments");
+
+  // Note: it may be possible for us to not have a called function, for example
+  // if we call a function using a function pointer
+  const Function *CurF = CI->getParent()->getParent();
+  if(F && F->hasName()) {
+    Msg += " across call to ";
+    Msg += F->getName();
+  }
+  DiagnosticInfoOptimizationFailure DI(*CurF, CI->getDebugLoc(), Msg);
+  CurF->getContext().diagnose(DI);
+}
+
+/// Warn about unhandled registers & stack slots
+void StackTransformMetadata::warnUnhandled() const {
+  std::string Msg;
+  const CallInst *IRCall;
+  const Function *CalledFunc;
+
+  for(auto S = SM.begin(), SE = SM.end(); S != SE; S++)
+  {
+    const MachineInstr *MISM = getMISM(*S);
+    const MachineInstr *MICall = getMICall(*S);
+    const RegValsMap &CurVregs = SMVregs.at(MISM);
+    const StackValsMap &CurSS = SMStackSlots.at(MISM);
+    IRCall = findCalledFunc(getIRSM(*S));
+    CalledFunc = IRCall->getCalledFunction();
+    assert(IRCall && "No call instruction for stackmap");
+
+    // Search for virtual registers not handled by the stackmap
+    for(unsigned i = 0; i < MRI->getNumVirtRegs(); i++) {
+      unsigned Vreg = TargetRegisterInfo::index2VirtReg(i);
+
+      // Virtual register allocated to physical register
+      if(VRM->hasPhys(Vreg) && isVregLiveAcrossInstr(Vreg, MICall) &&
+         CurVregs.find(Vreg) == CurVregs.end()) {
+        Msg = "Stack transformation: unhandled register ";
+        Msg += TRI->getName(VRM->getPhys(Vreg));
+        displayWarning(Msg, IRCall, CalledFunc);
+      }
+    }
+
+    // Search for all stack slots not handled by the stackmap
+    for(int SS = MFI->getObjectIndexBegin(), e = MFI->getObjectIndexEnd();
+        SS < e; SS++) {
+      if(!MFI->isDeadObjectIndex(SS) &&
+         isSSLiveAcrossInstr(SS, MICall) && CurSS.find(SS) == CurSS.end()) {
+        Msg = "Stack transformation: unhandled stack slot ";
+        Msg += std::to_string(SS);
+        displayWarning(Msg, IRCall, CalledFunc);
+      }
+    }
+  }
+}
+
Index: lib/CodeGen/StackTransformTypes.cpp
===================================================================
--- lib/CodeGen/StackTransformTypes.cpp	(nonexistent)
+++ lib/CodeGen/StackTransformTypes.cpp	(working copy)
@@ -0,0 +1,24 @@
+//===-- llvm/Target/TargetValueGenerator.cpp - Value Generator --*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/CodeGen/StackTransformTypes.h"
+
+using namespace llvm;
+
+const char *MachineGeneratedVal::ValueGenInst::InstTypeStr[] = {
+  #define X(type, pseudo) #type ,
+  VALUE_GEN_INST
+  #undef X
+};
+
+const bool MachineGeneratedVal::ValueGenInst::PseudoInst[] = {
+  #define X(type, pseudo) pseudo,
+  VALUE_GEN_INST
+  #undef X
+};
Index: lib/CodeGen/UnwindInfo.cpp
===================================================================
--- lib/CodeGen/UnwindInfo.cpp	(nonexistent)
+++ lib/CodeGen/UnwindInfo.cpp	(working copy)
@@ -0,0 +1,171 @@
+//===--------------------------- UnwindInfo.cpp ---------------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/CodeGen/UnwindInfo.h"
+#include "llvm/MC/MCSectionELF.h"
+#include "llvm/MC/MCSymbol.h"
+#include "llvm/MC/MCObjectFileInfo.h"
+#include "llvm/Target/TargetRegisterInfo.h"
+#include "llvm/Target/TargetSubtargetInfo.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "unwindinfo"
+
+static const char *UIDbg = "Unwind Info: ";
+
+void UnwindInfo::recordUnwindInfo(const MachineFunction &MF) {
+  // We *only* need this information for functions which have a stackmap, as
+  // only those function activations can be unwound during stack
+  // transformation.  This may also be a correctness criterion since we record
+  // offsets from the FBP, and not all functions may have one (stackmaps are
+  // implemented using FBPs, and thus prevent the FP-elimination optimization).
+  if(!MF.getFrameInfo()->hasStackMap()) return;
+
+  // Get this function's saved registers & FBP offset
+  const unsigned FBPOff = AP.getFBPOffset();
+  const MachineFrameInfo *MFI = MF.getFrameInfo();
+  const std::vector<CalleeSavedInfo> &CSI = MFI->getCalleeSavedInfo();
+
+  // Get DWARF register number and FBP offset using callee saved information
+  const TargetRegisterInfo *TRI = MF.getSubtarget().getRegisterInfo();
+  CalleeSavedRegisters SavedRegs(CSI.size());
+  for(unsigned i = 0; i < CSI.size(); i++) {
+    SavedRegs[i].DwarfReg = TRI->getDwarfRegNum(CSI[i].getReg(), false);
+    SavedRegs[i].Offset = MFI->getObjectOffset(CSI[i].getFrameIdx()) + FBPOff;
+  }
+
+  // Save the information for when we emit the section
+  const MCSymbol *FuncSym = OutContext.lookupSymbol(MF.getName());
+  assert(FuncSym && "Could not find function symbol");
+  FuncCalleeSaved.insert(FuncCalleePair(FuncSym, std::move(SavedRegs)));
+}
+
+void UnwindInfo::addRegisterUnwindInfo(const MachineFunction &MF,
+                                       uint32_t MachineReg,
+                                       int32_t Offset) {
+  if(!MF.getFrameInfo()->hasStackMap()) return;
+
+  const MCSymbol *FuncSym = OutContext.lookupSymbol(MF.getName());
+  assert(FuncSym && "Could not find function symbol");
+  assert(FuncCalleeSaved.find(FuncSym) != FuncCalleeSaved.end() &&
+         "Cannot add register restore information -- function not found");
+  const TargetRegisterInfo *TRI = MF.getSubtarget().getRegisterInfo();
+  FuncCalleeSaved[FuncSym].push_back(
+    RegOffset(TRI->getDwarfRegNum(MachineReg, false), Offset));
+}
+
+void UnwindInfo::emitUnwindInfo(MCStreamer &OS) {
+  unsigned curIdx = 0;
+  unsigned startIdx;
+  FuncCalleeMap::const_iterator f, e;
+  for(f = FuncCalleeSaved.begin(), e = FuncCalleeSaved.end(); f != e; f++) {
+    const MCSymbol *FuncSym = f->first;
+    const CalleeSavedRegisters &CSR = f->second;
+
+    assert(FuncSym && "Invalid machine function");
+    if(CSR.size() < 2)
+      DEBUG(dbgs() << "WARNING: should have at least 2 registers to restore "
+                               "(return address & saved FBP");
+
+    DEBUG(dbgs() << UIDbg << "Function " << FuncSym->getName()
+                 << " (offset " << curIdx << ", "
+                 << CSR.size() << " entries):\n");
+
+    startIdx = curIdx;
+    CalleeSavedRegisters::const_iterator cs, cse;
+    for(cs = CSR.begin(), cse = CSR.end(); cs != cse; cs++) {
+      assert(cs->DwarfReg < UINT16_MAX &&
+             "Register number too large for resolution");
+      assert(INT16_MIN < cs->Offset && cs->Offset < INT16_MAX &&
+             "Register save offset too large for resolution");
+
+      DEBUG(dbgs() << UIDbg << "  Register " << cs->DwarfReg
+                   << " saved at " << cs->Offset << "\n";);
+
+      OS.EmitIntValue(cs->DwarfReg, 2);
+      OS.EmitIntValue(cs->Offset, 2);
+      curIdx++;
+    }
+    FuncUnwindInfo FUI(startIdx, curIdx - startIdx);
+    FuncUnwindMetadata.insert(FuncUnwindPair(FuncSym, std::move(FUI)));
+  }
+}
+
+void UnwindInfo::emitAddrRangeInfo(MCStreamer &OS) {
+  FuncUnwindMap::const_iterator f, e;
+  for(f = FuncUnwindMetadata.begin(), e = FuncUnwindMetadata.end();
+      f != e;
+      f++) {
+    const MCSymbol *Func = f->first;
+    const FuncUnwindInfo &FUI = f->second;
+    OS.EmitSymbolValue(Func, 8);
+    OS.EmitIntValue(FUI.NumUnwindRecord, 4);
+    OS.EmitIntValue(FUI.SecOffset, 4);
+  }
+}
+
+/// Serialize the unwinding information.
+void UnwindInfo::serializeToUnwindInfoSection() {
+  // Bail out if there's no unwind info.
+  if(FuncCalleeSaved.empty()) return;
+
+  // Emit unwinding record information.
+  // FIXME: we only support ELF object files for now
+
+  // Switch to the unwind info section
+  MCStreamer &OS = *AP.OutStreamer;
+  MCSection *UnwindInfoSection =
+      OutContext.getObjectFileInfo()->getUnwindInfoSection();
+  OS.SwitchSection(UnwindInfoSection);
+
+  // Emit a dummy symbol to force section inclusion.
+  OS.EmitLabel(OutContext.getOrCreateSymbol(Twine("__StackTransform_UnwindInfo")));
+
+  // Serialize data.
+  DEBUG(dbgs() << "********** Unwind Info Output **********\n");
+  emitUnwindInfo(OS);
+  OS.AddBlankLine();
+
+  // Switch to the unwind address range section & emit section
+  MCSection *UnwindAddrRangeSection =
+      OutContext.getObjectFileInfo()->getUnwindAddrRangeSection();
+  OS.SwitchSection(UnwindAddrRangeSection);
+  OS.EmitLabel(OutContext.getOrCreateSymbol(Twine("__StackTransform_UnwindAddrRange")));
+  emitAddrRangeInfo(OS);
+  OS.AddBlankLine();
+
+  Emitted = true;
+}
+
+const UnwindInfo::FuncUnwindInfo &
+UnwindInfo::getUnwindInfo(const MCSymbol *Func) const {
+  assert(Emitted && "Have not yet calculated per-function unwinding metadata");
+
+  FuncUnwindMap::const_iterator it = FuncUnwindMetadata.find(Func);
+  assert(it != FuncUnwindMetadata.end() && "Invalid function");
+  return it->second;
+}
+
+void UnwindInfo::print(raw_ostream &OS) {
+  OS << UIDbg << "Function unwinding information\n";
+  FuncCalleeMap::const_iterator b, e;
+  for(b = FuncCalleeSaved.begin(), e = FuncCalleeSaved.end();
+      b != e;
+      b++) {
+    OS << UIDbg << "Function - " << b->first->getName() << "\n";
+    const CalleeSavedRegisters &CSR = b->second;
+    CalleeSavedRegisters::const_iterator br, be;
+    for(br = CSR.begin(), be = CSR.end(); br != be; br++) {
+      OS << UIDbg << "Register " << br->DwarfReg
+                  << " at offset " << br->Offset << "\n";
+    }
+  }
+}
+
Index: lib/MC/MCCodeGenInfo.cpp
===================================================================
--- lib/MC/MCCodeGenInfo.cpp	(revision 277823)
+++ lib/MC/MCCodeGenInfo.cpp	(working copy)
@@ -20,4 +20,6 @@
   RelocationModel = RM;
   CMModel = CM;
   OptLevel = OL;
+  ArchIROptLevel = OL;
+  EmitStackTransformMetadata = false;
 }
Index: lib/MC/MCObjectFileInfo.cpp
===================================================================
--- lib/MC/MCObjectFileInfo.cpp	(revision 277823)
+++ lib/MC/MCObjectFileInfo.cpp	(working copy)
@@ -519,6 +519,15 @@
   DwarfAddrSection =
       Ctx->getELFSection(".debug_addr", ELF::SHT_PROGBITS, 0, "addr_sec");
 
+  UnwindAddrRangeSection =
+      Ctx->getELFSection(".stack_transform.unwind_arange", ELF::SHT_PROGBITS,
+                         0, sizeof(uint64_t) + sizeof(uint64_t), "");
+  UnwindInfoSection =
+      Ctx->getELFSection(".stack_transform.unwind", ELF::SHT_PROGBITS, 0,
+                         sizeof(uint16_t) + sizeof(int16_t), "");
+  UnwindAddrRangeSection->setAlignment(sizeof(uint64_t));
+  UnwindInfoSection->setAlignment(sizeof(uint16_t) + sizeof(int16_t));
+
   StackMapSection =
       Ctx->getELFSection(".llvm_stackmaps", ELF::SHT_PROGBITS, ELF::SHF_ALLOC);
 
Index: lib/Target/AArch64/AArch64AsmPrinter.cpp
===================================================================
--- lib/Target/AArch64/AArch64AsmPrinter.cpp	(revision 277823)
+++ lib/Target/AArch64/AArch64AsmPrinter.cpp	(working copy)
@@ -28,6 +28,7 @@
 #include "llvm/CodeGen/MachineModuleInfoImpls.h"
 #include "llvm/CodeGen/StackMaps.h"
 #include "llvm/CodeGen/TargetLoweringObjectFileImpl.h"
+#include "llvm/CodeGen/UnwindInfo.h"
 #include "llvm/IR/DataLayout.h"
 #include "llvm/IR/DebugInfo.h"
 #include "llvm/MC/MCAsmInfo.h"
@@ -49,11 +50,12 @@
 class AArch64AsmPrinter : public AsmPrinter {
   AArch64MCInstLower MCInstLowering;
   StackMaps SM;
+  UnwindInfo UI;
 
 public:
   AArch64AsmPrinter(TargetMachine &TM, std::unique_ptr<MCStreamer> Streamer)
       : AsmPrinter(TM, std::move(Streamer)), MCInstLowering(OutContext, *this),
-        SM(*this), AArch64FI(nullptr) {}
+        SM(*this), UI(*this), AArch64FI(nullptr) {}
 
   const char *getPassName() const override {
     return "AArch64 Assembly Printer";
@@ -83,7 +85,9 @@
 
   bool runOnMachineFunction(MachineFunction &F) override {
     AArch64FI = F.getInfo<AArch64FunctionInfo>();
-    return AsmPrinter::runOnMachineFunction(F);
+    bool retval = AsmPrinter::runOnMachineFunction(F);
+    UI.recordUnwindInfo(F);
+    return retval;
   }
 
 private:
@@ -129,8 +133,10 @@
     // linker can safely perform dead code stripping.  Since LLVM never
     // generates code that does this, it is always safe to set.
     OutStreamer->EmitAssemblerFlag(MCAF_SubsectionsViaSymbols);
-    SM.serializeToStackMapSection();
   }
+  UI.serializeToUnwindInfoSection();
+  SM.serializeToStackMapSection(&UI);
+  UI.reset(); // Must reset after SM serialization to clear metadata
 }
 
 MachineLocation
Index: lib/Target/AArch64/AArch64ISelLowering.cpp
===================================================================
--- lib/Target/AArch64/AArch64ISelLowering.cpp	(revision 277823)
+++ lib/Target/AArch64/AArch64ISelLowering.cpp	(working copy)
@@ -2032,6 +2032,8 @@
     return LowerFSINCOS(Op, DAG);
   case ISD::MUL:
     return LowerMUL(Op, DAG);
+  case (uint16_t)~TargetOpcode::STACKMAP:
+    return SDValue(); // Use generic stackmap type legalizer
   }
 }
 
Index: lib/Target/AArch64/AArch64Subtarget.h
===================================================================
--- lib/Target/AArch64/AArch64Subtarget.h	(revision 277823)
+++ lib/Target/AArch64/AArch64Subtarget.h	(working copy)
@@ -19,6 +19,7 @@
 #include "AArch64InstrInfo.h"
 #include "AArch64RegisterInfo.h"
 #include "AArch64SelectionDAGInfo.h"
+#include "AArch64Values.h"
 #include "llvm/IR/DataLayout.h"
 #include "llvm/Target/TargetSubtargetInfo.h"
 #include <string>
@@ -63,6 +64,7 @@
   AArch64InstrInfo InstrInfo;
   AArch64SelectionDAGInfo TSInfo;
   AArch64TargetLowering TLInfo;
+  AArch64Values VGen;
 private:
   /// initializeSubtargetDependencies - Initializes using CPUString and the
   /// passed in feature string so that we can use initializer lists for
@@ -89,6 +91,9 @@
   const AArch64RegisterInfo *getRegisterInfo() const override {
     return &getInstrInfo()->getRegisterInfo();
   }
+  const AArch64Values *getValues() const override {
+    return &VGen;
+  }
   const Triple &getTargetTriple() const { return TargetTriple; }
   bool enableMachineScheduler() const override { return true; }
   bool enablePostRAScheduler() const override {
Index: lib/Target/AArch64/AArch64TargetMachine.cpp
===================================================================
--- lib/Target/AArch64/AArch64TargetMachine.cpp	(revision 277823)
+++ lib/Target/AArch64/AArch64TargetMachine.cpp	(working copy)
@@ -220,16 +220,20 @@
   // Cmpxchg instructions are often used with a subsequent comparison to
   // determine whether it succeeded. We can exploit existing control-flow in
   // ldrex/strex loops to simplify this, but it needs tidying up.
-  if (TM->getOptLevel() != CodeGenOpt::None && EnableAtomicTidy)
+  if (TM->getOptLevel() != CodeGenOpt::None &&
+      TM->getArchIROptLevel() != CodeGenOpt::None &&
+      EnableAtomicTidy)
     addPass(createCFGSimplificationPass());
 
   TargetPassConfig::addIRPasses();
 
   // Match interleaved memory accesses to ldN/stN intrinsics.
-  if (TM->getOptLevel() != CodeGenOpt::None)
+  if (TM->getOptLevel() != CodeGenOpt::None &&
+      TM->getArchIROptLevel() != CodeGenOpt::None)
     addPass(createInterleavedAccessPass(TM));
 
-  if (TM->getOptLevel() == CodeGenOpt::Aggressive && EnableGEPOpt) {
+  if (TM->getOptLevel() == CodeGenOpt::Aggressive &&
+      TM->getArchIROptLevel() != CodeGenOpt::None && EnableGEPOpt) {
     // Call SeparateConstOffsetFromGEP pass to extract constants within indices
     // and lower a GEP with multiple indices to either arithmetic operations or
     // multiple GEPs with single index.
@@ -247,12 +251,14 @@
 bool AArch64PassConfig::addPreISel() {
   // Run promote constant before global merge, so that the promoted constants
   // get a chance to be merged
-  if (TM->getOptLevel() != CodeGenOpt::None && EnablePromoteConstant)
+  if (TM->getOptLevel() != CodeGenOpt::None &&
+      TM->getArchIROptLevel() != CodeGenOpt::None && EnablePromoteConstant)
     addPass(createAArch64PromoteConstantPass());
   // FIXME: On AArch64, this depends on the type.
   // Basically, the addressable offsets are up to 4095 * Ty.getSizeInBytes().
   // and the offset has to be a multiple of the related size in bytes.
   if ((TM->getOptLevel() != CodeGenOpt::None &&
+       TM->getArchIROptLevel() != CodeGenOpt::None &&
        EnableGlobalMerge == cl::BOU_UNSET) ||
       EnableGlobalMerge == cl::BOU_TRUE) {
     bool OnlyOptimizeForSize = (TM->getOptLevel() < CodeGenOpt::Aggressive) &&
@@ -260,7 +266,8 @@
     addPass(createGlobalMergePass(TM, 4095, OnlyOptimizeForSize));
   }
 
-  if (TM->getOptLevel() != CodeGenOpt::None)
+  if (TM->getOptLevel() != CodeGenOpt::None &&
+      TM->getArchIROptLevel() != CodeGenOpt::None)
     addPass(createAArch64AddressTypePromotionPass());
 
   return false;
Index: lib/Target/AArch64/AArch64Values.cpp
===================================================================
--- lib/Target/AArch64/AArch64Values.cpp	(nonexistent)
+++ lib/Target/AArch64/AArch64Values.cpp	(working copy)
@@ -0,0 +1,139 @@
+//===- AArch64TargetValues.cpp - AArch64 specific value generator -===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+
+#include "AArch64Values.h"
+#include "AArch64.h"
+#include "llvm/CodeGen/MachineFunction.h"
+#include "llvm/MC/MCSymbol.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+#include "llvm/Target/TargetInstrInfo.h"
+#include "llvm/Target/TargetSubtargetInfo.h"
+
+#define DEBUG_TYPE "stacktransform"
+
+using namespace llvm;
+
+// Make types in MachineGeneratedVal more accessible
+typedef MachineGeneratedVal::ValueGenInst ValueGenInst;
+typedef MachineGeneratedVal::ValueGenInst::InstType InstType;
+typedef MachineGeneratedVal::ValueGenInstPtr ValueGenInstPtr;
+typedef MachineGeneratedVal::ValueGenInstList ValueGenInstList;
+
+template <InstType T>
+using RegInstruction = MachineGeneratedVal::RegInstruction<T>;
+template <InstType T>
+using ImmInstruction = MachineGeneratedVal::ImmInstruction<T>;
+template <InstType T>
+using PseudoInstruction = MachineGeneratedVal::PseudoInstruction<T>;
+
+void AArch64Values::genADDInstructions(const MachineInstr *MI,
+                                       ValueGenInstList &IL) const {
+  int Index;
+
+  switch(MI->getOpcode()) {
+  case AArch64::ADDXri:
+    if(MI->getOperand(1).isFI()) {
+      Index = MI->getOperand(1).getIndex();
+      IL.push_back(ValueGenInstPtr(
+        new PseudoInstruction<InstType::StackSlot>(Index, InstType::Set)));
+      assert(MI->getOperand(2).isImm() && MI->getOperand(2).getImm() == 0);
+      assert(MI->getOperand(3).isImm() && MI->getOperand(3).getImm() == 0);
+    }
+    break;
+  default:
+    llvm_unreachable("Unhandled ADD machine instruction");
+    break;
+  }
+}
+
+void AArch64Values::genBitfieldInstructions(const MachineInstr *MI,
+                                            ValueGenInstList &IL) const {
+  int64_t R, S;
+  unsigned Size = 8, Bits = 64;
+  const uint64_t Mask = UINT64_MAX;
+
+  switch(MI->getOpcode()) {
+  case AArch64::UBFMXri:
+    // TODO ensure this is correct
+    assert(MI->getOperand(1).isReg() && MI->getOperand(2).isImm() &&
+           MI->getOperand(3).isImm());
+    IL.push_back(ValueGenInstPtr(
+      new RegInstruction<InstType::Set>(MI->getOperand(1).getReg(), 0)));
+    R = MI->getOperand(2).getImm();
+    S = MI->getOperand(3).getImm();
+    if(S >= R) {
+      IL.push_back(ValueGenInstPtr(
+        new ImmInstruction<InstType::RightShiftLog>(Size, R)));
+      IL.push_back(ValueGenInstPtr(
+        new ImmInstruction<InstType::Mask>(Size, ~(Mask << (S - R + 1)))));
+    }
+    else {
+      IL.push_back(ValueGenInstPtr(
+        new ImmInstruction<InstType::Mask>(Size, ~(Mask << (S + 1)))));
+      IL.push_back(ValueGenInstPtr(
+        new ImmInstruction<InstType::LeftShift>(Size, Bits - R)));
+    }
+    break;
+  }
+}
+
+MachineLiveValPtr AArch64Values::getMachineValue(const MachineInstr *MI) const {
+  MachineLiveVal* Val = nullptr;
+  const MachineOperand *MO;
+  const TargetInstrInfo *TII;
+  ValueGenInstList IL;
+
+  switch(MI->getOpcode()) {
+  case AArch64::MOVaddr:
+  case AArch64::ADRP:
+    MO = &MI->getOperand(1);
+    if(MO->isCPI()) {
+      IL.push_back(ValueGenInstPtr(
+        new PseudoInstruction<InstType::ConstantPool>(MO->getIndex(),
+                                                      InstType::Set)));
+      Val = new MachineGeneratedVal(IL, MI);
+    }
+    else {
+      assert((MO->isGlobal() || MO->isSymbol() || MO->isMCSymbol()) &&
+             "Invalid operand for address generation");
+      if(MO->isGlobal())
+        Val = new MachineReference(MO->getGlobal()->getName(), MI);
+      else if(MO->isSymbol())
+        Val = new MachineReference(MO->getSymbolName(), MI);
+      else if(MO->isMCSymbol())
+        Val = new MachineReference(MO->getMCSymbol()->getName(), MI);
+    }
+    break;
+  case AArch64::ADDXri:
+    genADDInstructions(MI, IL);
+    if(IL.size()) Val = new MachineGeneratedVal(IL, MI);
+    break;
+  case AArch64::UBFMXri:
+    genBitfieldInstructions(MI, IL);
+    if(IL.size()) Val = new MachineGeneratedVal(IL, MI);
+    break;
+  case AArch64::COPY:
+    MO = &MI->getOperand(1);
+    if(MO->isReg() && MO->getReg() == AArch64::LR) {
+      IL.push_back(ValueGenInstPtr(
+        new RegInstruction<InstType::Load>(AArch64::FP, 8)));
+      Val = new MachineGeneratedVal(IL, MI);
+    }
+    break;
+  default:
+    TII =  MI->getParent()->getParent()->getSubtarget().getInstrInfo();
+    DEBUG(dbgs() << "Unhandled opcode: "
+                 << TII->getName(MI->getOpcode()) << "\n");
+    break;
+  }
+
+  return MachineLiveValPtr(Val);
+}
+
Index: lib/Target/AArch64/AArch64Values.h
===================================================================
--- lib/Target/AArch64/AArch64Values.h	(nonexistent)
+++ lib/Target/AArch64/AArch64Values.h	(working copy)
@@ -0,0 +1,28 @@
+//===----- AArch64TargetValues.cpp - AArch64 specific value generator -----===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/Target/TargetValues.h"
+
+namespace llvm {
+
+class AArch64Values final : public TargetValues {
+public:
+  AArch64Values() {}
+  virtual MachineLiveValPtr getMachineValue(const MachineInstr *MI) const;
+
+private:
+  void genADDInstructions(const MachineInstr *MI,
+                          MachineGeneratedVal::ValueGenInstList &IL) const;
+  void
+  genBitfieldInstructions(const MachineInstr *MI,
+                          MachineGeneratedVal::ValueGenInstList &IL) const;
+};
+
+}
+
Index: lib/Target/AArch64/CMakeLists.txt
===================================================================
--- lib/Target/AArch64/CMakeLists.txt	(revision 277823)
+++ lib/Target/AArch64/CMakeLists.txt	(working copy)
@@ -43,6 +43,7 @@
   AArch64TargetMachine.cpp
   AArch64TargetObjectFile.cpp
   AArch64TargetTransformInfo.cpp
+  AArch64Values.cpp
 )
 
 add_dependencies(LLVMAArch64CodeGen intrinsics_gen)
Index: lib/Target/PowerPC/PPCAsmPrinter.cpp
===================================================================
--- lib/Target/PowerPC/PPCAsmPrinter.cpp	(revision 277823)
+++ lib/Target/PowerPC/PPCAsmPrinter.cpp	(working copy)
@@ -36,6 +36,7 @@
 #include "llvm/CodeGen/MachineRegisterInfo.h"
 #include "llvm/CodeGen/StackMaps.h"
 #include "llvm/CodeGen/TargetLoweringObjectFileImpl.h"
+#include "llvm/CodeGen/UnwindInfo.h"
 #include "llvm/IR/Constants.h"
 #include "llvm/IR/DebugInfo.h"
 #include "llvm/IR/DerivedTypes.h"
@@ -70,10 +71,11 @@
     MapVector<MCSymbol*, MCSymbol*> TOC;
     const PPCSubtarget *Subtarget;
     StackMaps SM;
+    UnwindInfo UI;
   public:
     explicit PPCAsmPrinter(TargetMachine &TM,
                            std::unique_ptr<MCStreamer> Streamer)
-        : AsmPrinter(TM, std::move(Streamer)), SM(*this) {}
+        : AsmPrinter(TM, std::move(Streamer)), SM(*this), UI(*this) {}
 
     const char *getPassName() const override {
       return "PowerPC Assembly Printer";
@@ -101,7 +103,9 @@
     void EmitTlsCall(const MachineInstr *MI, MCSymbolRefExpr::VariantKind VK);
     bool runOnMachineFunction(MachineFunction &MF) override {
       Subtarget = &MF.getSubtarget<PPCSubtarget>();
-      return AsmPrinter::runOnMachineFunction(MF);
+      bool retval = AsmPrinter::runOnMachineFunction(MF);
+      UI.recordUnwindInfo(MF);
+      return retval;
     }
   };
 
@@ -327,7 +331,9 @@
 }
 
 void PPCAsmPrinter::EmitEndOfAsmFile(Module &M) {
-  SM.serializeToStackMapSection();
+  UI.serializeToUnwindInfoSection();
+  SM.serializeToStackMapSection(&UI);
+  UI.reset(); // Must reset after SM serialization to clear metadata
 }
 
 void PPCAsmPrinter::LowerSTACKMAP(MCStreamer &OutStreamer, StackMaps &SM,
Index: lib/Target/TargetMachine.cpp
===================================================================
--- lib/Target/TargetMachine.cpp	(revision 277823)
+++ lib/Target/TargetMachine.cpp	(working copy)
@@ -149,6 +149,39 @@
     CodeGenInfo->setOptLevel(Level);
 }
 
+CodeGenOpt::Level TargetMachine::getArchIROptLevel() const {
+  if (!CodeGenInfo)
+    return CodeGenOpt::Default;
+  return CodeGenInfo->getArchIROptLevel();
+}
+
+void TargetMachine::setArchIROptLevel(CodeGenOpt::Level Level) const {
+  if (CodeGenInfo)
+    CodeGenInfo->setArchIROptLevel(Level);
+}
+
+bool TargetMachine::emitStackTransformMetadata() const {
+  if (!CodeGenInfo)
+    return false;
+  else return CodeGenInfo->emitStackTransformMetadata();
+}
+
+void TargetMachine::setEmitStackTransformMetadata(bool Emit) {
+  if (CodeGenInfo)
+    CodeGenInfo->setEmitStackTransformMetadata(Emit);
+}
+
+bool TargetMachine::emitLibcTransformMetadata() const {
+  if (!CodeGenInfo)
+    return false;
+  else return CodeGenInfo->emitLibcTransformMetadata();
+}
+
+void TargetMachine::setEmitLibcTransformMetadata(bool Emit) {
+  if (CodeGenInfo)
+    CodeGenInfo->setEmitLibcTransformMetadata(Emit);
+}
+
 TargetIRAnalysis TargetMachine::getTargetIRAnalysis() {
   return TargetIRAnalysis([this](Function &F) {
     return TargetTransformInfo(F.getParent()->getDataLayout());
Index: lib/Target/X86/CMakeLists.txt
===================================================================
--- lib/Target/X86/CMakeLists.txt	(revision 277823)
+++ lib/Target/X86/CMakeLists.txt	(working copy)
@@ -34,6 +34,7 @@
   X86VZeroUpper.cpp
   X86FixupLEAs.cpp
   X86WinEHState.cpp
+  X86Values.cpp
   )
 
 if( CMAKE_CL_64 )
Index: lib/Target/X86/X86AsmPrinter.cpp
===================================================================
--- lib/Target/X86/X86AsmPrinter.cpp	(revision 277823)
+++ lib/Target/X86/X86AsmPrinter.cpp	(working copy)
@@ -24,6 +24,7 @@
 #include "llvm/CodeGen/TargetLoweringObjectFileImpl.h"
 #include "llvm/IR/DebugInfo.h"
 #include "llvm/IR/DerivedTypes.h"
+#include "llvm/IR/DiagnosticInfo.h"
 #include "llvm/IR/Mangler.h"
 #include "llvm/IR/Module.h"
 #include "llvm/IR/Type.h"
@@ -49,6 +50,8 @@
 bool X86AsmPrinter::runOnMachineFunction(MachineFunction &MF) {
   Subtarget = &MF.getSubtarget<X86Subtarget>();
 
+  bool modified = TagCallSites(MF);
+
   SMShadowTracker.startFunction(MF);
 
   SetupMachineFunction(MF);
@@ -66,8 +69,19 @@
   // Emit the rest of the function body.
   EmitFunctionBody();
 
-  // We didn't modify anything.
-  return false;
+  // Add this function's register unwind info.  The x86 backend doesn't
+  // maintain the saved FBP (old RBP) and return address (RIP) as callee-saved
+  // registers, so manually add where they're saved.
+  MachineFrameInfo *MFI = MF.getFrameInfo();
+  if(MFI->hasStackMap()) {
+    const TargetRegisterInfo *TRI = MF.getSubtarget().getRegisterInfo();
+    UI.recordUnwindInfo(MF);
+    UI.addRegisterUnwindInfo(MF, TRI->getFrameRegister(MF), 0);
+    UI.addRegisterUnwindInfo(MF, TRI->getProgramCounter(), 8);
+  }
+
+  // We may have modified where stack map intrinsics are located.
+  return modified;
 }
 
 /// printSymbolOperand - Print a raw symbol reference operand.  This handles
@@ -689,8 +703,10 @@
   }
 
   if (TT.isOSBinFormatELF()) {
-    SM.serializeToStackMapSection();
+    UI.serializeToUnwindInfoSection();
+    SM.serializeToStackMapSection(&UI);
     FM.serializeToFaultMapSection();
+    UI.reset(); // Must reset after SM serialization to clear metadata
   }
 }
 
Index: lib/Target/X86/X86AsmPrinter.h
===================================================================
--- lib/Target/X86/X86AsmPrinter.h	(revision 277823)
+++ lib/Target/X86/X86AsmPrinter.h	(working copy)
@@ -14,6 +14,7 @@
 #include "llvm/CodeGen/AsmPrinter.h"
 #include "llvm/CodeGen/FaultMaps.h"
 #include "llvm/CodeGen/StackMaps.h"
+#include "llvm/CodeGen/UnwindInfo.h"
 #include "llvm/Target/TargetMachine.h"
 
 // Implemented in X86MCInstLower.cpp
@@ -28,6 +29,7 @@
 class LLVM_LIBRARY_VISIBILITY X86AsmPrinter : public AsmPrinter {
   const X86Subtarget *Subtarget;
   StackMaps SM;
+  UnwindInfo UI;
   FaultMaps FM;
 
   // This utility class tracks the length of a stackmap instruction's 'shadow'.
@@ -90,8 +92,8 @@
  public:
    explicit X86AsmPrinter(TargetMachine &TM,
                           std::unique_ptr<MCStreamer> Streamer)
-       : AsmPrinter(TM, std::move(Streamer)), SM(*this), FM(*this),
-         SMShadowTracker(TM) {}
+       : AsmPrinter(TM, std::move(Streamer)), SM(*this), UI(*this),
+         FM(*this), SMShadowTracker(TM) {}
 
   const char *getPassName() const override {
     return "X86 Assembly / Object Emitter";
Index: lib/Target/X86/X86ISelLowering.cpp
===================================================================
--- lib/Target/X86/X86ISelLowering.cpp	(revision 277823)
+++ lib/Target/X86/X86ISelLowering.cpp	(working copy)
@@ -18621,6 +18621,8 @@
   case ISD::GC_TRANSITION_START:
                                 return LowerGC_TRANSITION_START(Op, DAG);
   case ISD::GC_TRANSITION_END:  return LowerGC_TRANSITION_END(Op, DAG);
+  case (uint16_t)~TargetOpcode::STACKMAP:
+    return SDValue(); // Use generic stackmap type legalizer
   }
 }
 
Index: lib/Target/X86/X86Subtarget.h
===================================================================
--- lib/Target/X86/X86Subtarget.h	(revision 277823)
+++ lib/Target/X86/X86Subtarget.h	(working copy)
@@ -18,6 +18,7 @@
 #include "X86ISelLowering.h"
 #include "X86InstrInfo.h"
 #include "X86SelectionDAGInfo.h"
+#include "X86Values.h"
 #include "llvm/ADT/Triple.h"
 #include "llvm/IR/CallingConv.h"
 #include "llvm/Target/TargetSubtargetInfo.h"
@@ -248,7 +249,7 @@
   X86InstrInfo InstrInfo;
   X86TargetLowering TLInfo;
   X86FrameLowering FrameLowering;
-
+  X86Values VGen;
 public:
   /// This constructor initializes the data members to match that
   /// of the specified triple.
@@ -269,6 +270,7 @@
   const X86RegisterInfo *getRegisterInfo() const override {
     return &getInstrInfo()->getRegisterInfo();
   }
+  const X86Values *getValues() const override { return &VGen; }
 
   /// Returns the minimum alignment known to hold of the
   /// stack frame on entry to the function and which must be maintained by every
Index: lib/Target/X86/X86Values.cpp
===================================================================
--- lib/Target/X86/X86Values.cpp	(nonexistent)
+++ lib/Target/X86/X86Values.cpp	(working copy)
@@ -0,0 +1,98 @@
+//===--------- X86TargetValues.cpp - X86 specific value generator ---------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+
+#include "X86Values.h"
+#include "X86InstrInfo.h"
+#include "llvm/CodeGen/MachineFunction.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Target/TargetInstrInfo.h"
+#include "llvm/Target/TargetSubtargetInfo.h"
+
+#define DEBUG_TYPE "stacktransform"
+
+using namespace llvm;
+
+// Make types in MachineGeneratedVal more accessible
+typedef MachineGeneratedVal::ValueGenInst ValueGenInst;
+typedef MachineGeneratedVal::ValueGenInst::InstType InstType;
+typedef MachineGeneratedVal::ValueGenInstPtr ValueGenInstPtr;
+typedef MachineGeneratedVal::ValueGenInstList ValueGenInstList;
+
+template <InstType T>
+using RegInstruction = MachineGeneratedVal::RegInstruction<T>;
+template <InstType T>
+using ImmInstruction = MachineGeneratedVal::ImmInstruction<T>;
+template <InstType T>
+using PseudoInstruction = MachineGeneratedVal::PseudoInstruction<T>;
+
+void X86Values::genLEAInstructions(const MachineInstr *MI,
+                                   ValueGenInstList &IL) const {
+  int Index;
+  unsigned Reg;
+  int64_t Imm;
+  unsigned Size = 8; // in bytes
+
+  // TODO do we need to handle the segment register operand?
+  switch(MI->getOpcode()) {
+  case X86::LEA64r:
+    // Set the index register & scale (if we're doing indexing)
+    Reg = MI->getOperand(1 + X86::AddrIndexReg).getReg();
+    if(Reg) {
+      IL.push_back(ValueGenInstPtr(
+        new RegInstruction<InstType::Set>(Reg, 0)));
+
+      Imm = MI->getOperand(1 + X86::AddrScaleAmt).getImm();
+      IL.push_back(ValueGenInstPtr(
+        new ImmInstruction<InstType::Multiply>(Size, Imm)));
+    }
+
+    if(MI->getOperand(1 + X86::AddrBaseReg).isFI()) {
+      // The frame index becomes the base register + displacement after virtual
+      // register rewriting and stack slot allocation
+      Index = MI->getOperand(1 + X86::AddrBaseReg).getIndex();
+      IL.push_back(ValueGenInstPtr(
+        new PseudoInstruction<InstType::StackSlot>(Index, InstType::Add)));
+    }
+    else {
+      assert(MI->getOperand(1 + X86::AddrBaseReg).isReg());
+      Reg = MI->getOperand(1 + X86::AddrBaseReg).getReg();
+      IL.push_back(ValueGenInstPtr(
+        new RegInstruction<InstType::Add>(Reg, 0)));
+
+      Imm = MI->getOperand(1 + X86::AddrDisp).getImm();
+      IL.push_back(ValueGenInstPtr(
+        new ImmInstruction<InstType::Add>(Size, Imm)));
+    }
+    break;
+  default:
+    llvm_unreachable("Unhandled LEA machine instruction");
+    break;
+  }
+}
+
+MachineLiveValPtr X86Values::getMachineValue(const MachineInstr *MI) const {
+  MachineLiveVal* Val = nullptr;
+  const TargetInstrInfo *TII;
+  ValueGenInstList IL;
+
+  switch(MI->getOpcode()) {
+  case X86::LEA64r:
+    genLEAInstructions(MI, IL);
+    if(IL.size() > 0) Val = new MachineGeneratedVal(IL, MI);
+    break;
+  default:
+    TII =  MI->getParent()->getParent()->getSubtarget().getInstrInfo();
+    DEBUG(dbgs() << "Unhandled opcode: "
+                 << TII->getName(MI->getOpcode()) << "\n");
+    break;
+  }
+
+  return MachineLiveValPtr(Val);
+}
+
Index: lib/Target/X86/X86Values.h
===================================================================
--- lib/Target/X86/X86Values.h	(nonexistent)
+++ lib/Target/X86/X86Values.h	(working copy)
@@ -0,0 +1,25 @@
+//===--------- X86TargetValues.cpp - X86 specific value generator ---------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// This file is distributed under the University of Illinois Open Source
+// License. See LICENSE.TXT for details.
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/Target/TargetValues.h"
+
+namespace llvm {
+
+class X86Values final : public TargetValues {
+public:
+  X86Values() {}
+  virtual MachineLiveValPtr getMachineValue(const MachineInstr *MI) const;
+
+private:
+  void genLEAInstructions(const MachineInstr *LEA,
+                          MachineGeneratedVal::ValueGenInstList &IL) const;
+};
+
+}
+
Index: lib/Transforms/Instrumentation/CMakeLists.txt
===================================================================
--- lib/Transforms/Instrumentation/CMakeLists.txt	(revision 277823)
+++ lib/Transforms/Instrumentation/CMakeLists.txt	(working copy)
@@ -4,8 +4,10 @@
   DataFlowSanitizer.cpp
   GCOVProfiling.cpp
   MemorySanitizer.cpp
+  InsertStackMaps.cpp
   Instrumentation.cpp
   InstrProfiling.cpp
+  LibcStackMaps.cpp
   SafeStack.cpp
   SanitizerCoverage.cpp
   ThreadSanitizer.cpp
Index: lib/Transforms/Instrumentation/InsertStackMaps.cpp
===================================================================
--- lib/Transforms/Instrumentation/InsertStackMaps.cpp	(nonexistent)
+++ lib/Transforms/Instrumentation/InsertStackMaps.cpp	(working copy)
@@ -0,0 +1,337 @@
+#include <map>
+#include <set>
+#include <vector>
+#include "llvm/Pass.h"
+#include "llvm/Analysis/LiveValues.h"
+#include "llvm/IR/Dominators.h"
+#include "llvm/IR/IntrinsicInst.h"
+#include "llvm/IR/InstIterator.h"
+#include "llvm/IR/Instructions.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Type.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+#define DEBUG_TYPE "insert-stackmaps"
+
+using namespace llvm;
+
+namespace {
+
+/**
+ * This class instruments equivalence points in the IR with LLVM's stackmap
+ * intrinsic.  This tells the backend to record the locations of IR values
+ * after register allocation in a separate ELF section.
+ */
+class InsertStackMaps : public ModulePass
+{
+public:
+  static char ID;
+  size_t callSiteID;
+  size_t numInstrumented;
+
+  InsertStackMaps() : ModulePass(ID), callSiteID(0), numInstrumented(0) {
+    initializeInsertStackMapsPass(*PassRegistry::getPassRegistry());
+  }
+  ~InsertStackMaps() {}
+
+  /* ModulePass virtual methods */
+  virtual const char *getPassName() const { return "Insert stackmaps"; }
+
+  virtual void getAnalysisUsage(AnalysisUsage &AU) const
+  {
+    AU.addRequired<LiveValues>();
+    AU.addRequired<DominatorTreeWrapperPass>();
+    AU.setPreservesCFG();
+  }
+
+  /**
+   * Use liveness analysis to insert stackmap intrinsics into the IR to record
+   * live values at equivalence points.
+   *
+   * Note: currently we only insert stackmaps at function call sites.
+   */
+  virtual bool runOnModule(Module &M)
+  {
+    bool modified = false;
+    std::set<const Value *> *live;
+    std::set<const Value *, ValueComp> sortedLive;
+    std::set<const Instruction *> hiddenInst;
+    std::set<const Argument *> hiddenArgs;
+
+    DEBUG(errs() << "\n********** Begin InsertStackMaps **********\n"
+                 << "********** Module: " << M.getName() << " **********\n\n");
+
+    this->createSMType(M);
+    if(this->addSMDeclaration(M)) modified = true;
+
+    modified |= this->removeOldStackmaps(M);
+  
+    /* Iterate over all functions/basic blocks/instructions. */
+    for(Module::iterator f = M.begin(), fe = M.end(); f != fe; f++)
+    {
+      if(f->isDeclaration()) continue;
+
+      DEBUG(errs() << "InsertStackMaps: entering function "
+                   << f->getName() << "\n");
+
+      LiveValues &liveVals = getAnalysis<LiveValues>(*f);
+      DominatorTree &DT = getAnalysis<DominatorTreeWrapperPass>(*f).getDomTree();
+      std::set<const Value *>::const_iterator v, ve;
+      getHiddenVals(*f, hiddenInst, hiddenArgs);
+  
+      /* Find call sites in the function. */
+      for(Function::iterator b = f->begin(), be = f->end(); b != be; b++)
+      {
+        DEBUG(
+          errs() << "InsertStackMaps: entering basic block ";
+          b->printAsOperand(errs(), false);
+          errs() << "\n"
+        );
+  
+        for(BasicBlock::iterator i = b->begin(), ie = b->end(); i != ie; i++)
+        {
+          CallInst *CI;
+          if((CI = dyn_cast<CallInst>(&*i)) &&
+             !CI->isInlineAsm() &&
+             !isa<IntrinsicInst>(CI))
+          {
+            live = liveVals.getLiveValues(&*i);
+            for(const Value *val : *live) sortedLive.insert(val);
+            for(const Instruction *val : hiddenInst) {
+              /*
+               * The two criteria for inclusion of a hidden value are:
+               *   1. The value's definition dominates the call
+               *   2. A use which hides the definition is in the stackmap
+               */
+              if(DT.dominates(val, CI) && hasLiveUser(val, *live))
+                sortedLive.insert(val);
+            }
+            for(const Argument *val : hiddenArgs) {
+              /*
+               * Similar criteria apply as above, except we know arguments
+               * dominate the entire function.
+               */
+              if(hasLiveUser(val, *live))
+                sortedLive.insert(val);
+            }
+            delete live;
+  
+            DEBUG(
+              const Function *calledFunc;
+  
+              errs() << "  ";
+              if(!CI->getType()->isVoidTy()) {
+                CI->printAsOperand(errs(), false);
+                errs() << " ";
+              }
+              else errs() << "(void) ";
+  
+              calledFunc = CI->getCalledFunction();
+              if(calledFunc && calledFunc->hasName())
+              {
+                StringRef name = CI->getCalledFunction()->getName();
+                errs() << name << " ";
+              }
+              errs() << "ID: " << this->callSiteID;
+  
+              errs() << ", " << sortedLive.size() << " live value(s)\n   ";
+              for(const Value *val : sortedLive) {
+                errs() << " ";
+                val->printAsOperand(errs(), false);
+              }
+              errs() << "\n";
+            );
+  
+            IRBuilder<> builder(CI->getNextNode());
+            std::vector<Value *> args(2);
+            args[0] = ConstantInt::getSigned(Type::getInt64Ty(M.getContext()), this->callSiteID++);
+            args[1] = ConstantInt::getSigned(Type::getInt32Ty(M.getContext()), 0);
+            for(v = sortedLive.begin(), ve = sortedLive.end(); v != ve; v++)
+              args.push_back((Value*)*v);
+            builder.CreateCall(this->SMFunc, ArrayRef<Value*>(args));
+            sortedLive.clear();
+            this->numInstrumented++;
+          }
+        }
+      }
+
+      hiddenInst.clear();
+      hiddenArgs.clear();
+      this->callSiteID = 0;
+    }
+  
+    DEBUG(
+      errs() << "InsertStackMaps: finished module " << M.getName() << ", added "
+             << this->numInstrumented << " stackmaps\n\n";
+    );
+  
+    if(numInstrumented > 0) modified = true;
+  
+    return modified;
+  }
+
+private:
+  /* Name of stack map intrinsic */
+  static const StringRef SMName;
+
+  /* Stack map instruction creation */
+  Function *SMFunc;
+  FunctionType *SMTy; // Used for creating function declaration
+
+  /* Sort values based on name */
+  struct ValueComp {
+    bool operator() (const Value *a, const Value *b) const
+    {
+      if(a->hasName() && b->hasName())
+        return a->getName().compare(b->getName()) < 0;
+      else if(a->hasName()) return true;
+      else if(b->hasName()) return false;
+      else return a < b;
+    }
+  };
+
+  /**
+   * Create the function type for the stack map intrinsic.
+   */
+  void createSMType(const Module &M)
+  {
+    std::vector<Type*> params(2);
+    params[0] = Type::getInt64Ty(M.getContext());
+    params[1] = Type::getInt32Ty(M.getContext());
+    this->SMTy = FunctionType::get(Type::getVoidTy(M.getContext()),
+                                                   ArrayRef<Type*>(params),
+                                                   true);
+  }
+
+  /**
+   * Add the stackmap intrinisic's function declaration if not already present.
+   * Return true if the declaration was added, or false if it's already there.
+   */
+  bool addSMDeclaration(Module &M)
+  {
+    if(!(this->SMFunc = M.getFunction(this->SMName)))
+    {
+      DEBUG(errs() << "Adding stackmap function declaration to " << M.getName() << "\n");
+      this->SMFunc = cast<Function>(M.getOrInsertFunction(this->SMName, this->SMTy));
+      this->SMFunc->setCallingConv(CallingConv::C);
+      return true;
+    }
+    else return false;
+  }
+
+  /**
+   * Iterate over all instructions, removing previously found stackmaps.
+   */
+  bool removeOldStackmaps(Module &M)
+  {
+    bool modified = false;
+    CallInst* CI;
+    const Function *F;
+
+    DEBUG(dbgs() << "Searching for/removing old stackmaps\n";);
+
+    for(Module::iterator f = M.begin(), fe = M.end(); f != fe; f++) {
+      for(Function::iterator bb = f->begin(), bbe = f->end(); bb != bbe; bb++) {
+        for(BasicBlock::iterator i = bb->begin(), ie = bb->end(); i != ie; i++) {
+          if((CI = dyn_cast<CallInst>(&*i))) {
+            F = CI->getCalledFunction();
+            if(F && F->hasName() && F->getName() == SMName) {
+              i = i->eraseFromParent()->getPrevNode();
+              modified = true;
+            }
+          }
+        }
+      }
+    }
+
+    DEBUG(if(modified)
+            dbgs() << "WARNING: found previous run of Popcorn passes!\n";);
+
+    return modified;
+  }
+
+  /**
+   * Gather a list of values which may be "hidden" from live value analysis.
+   * This function collects the values used in these instructions, which are
+   * later added to the appropriate stackmaps.
+   *
+   * 1. Instructions which access fields of structs or entries of arrays, like
+   *    getelementptr, can interfere with the live value analysis to hide the
+   *    backing values used in the instruction.  For example, the following IR
+   *    obscures %arr from the live value analysis:
+   *
+   *  %arr = alloca [4 x double], align 8
+   *  %arrayidx = getelementptr inbounds [4 x double], [4 x double]* %arr, i64 0, i64 0
+   *
+   *  -> Access to %arr might only happen through %arrayidx, and %arr may not
+   *     be used any more
+   *
+   * 2. Compare instructions, such as icmp & fcmp, can be lowered to complex &
+   *    architecture-specific  machine code by the backend.  To help capture
+   *    all live values, we capture both the value used in the comparison and
+   *    the resulting condition value.
+   *
+   */
+  void getHiddenVals(Function &F,
+                     std::set<const Instruction *> &inst,
+                     std::set<const Argument *> &args)
+  {
+    /* Does the instruction potentially hide values from liveness analysis? */
+    auto hidesValues = [](const Instruction *I) {
+      if(isa<ExtractElementInst>(I) || isa<InsertElementInst>(I) ||
+         isa<ExtractValueInst>(I) || isa<InsertValueInst>(I) ||
+         isa<GetElementPtrInst>(I) || isa<ICmpInst>(I) || isa<FCmpInst>(I))
+        return true ;
+      else return false;
+    };
+
+    /* Search for instructions that obscure live values & record operands */
+    for(inst_iterator i = inst_begin(F), e = inst_end(F); i != e; ++i) {
+      if(hidesValues(&*i)) {
+        for(unsigned op = 0; op < i->getNumOperands(); op++) {
+          if(isa<Instruction>(i->getOperand(op)))
+            inst.insert(cast<Instruction>(i->getOperand(op)));
+          else if(isa<Argument>(i->getOperand(op)))
+            args.insert(cast<Argument>(i->getOperand(op)));
+        }
+      }
+    }
+  }
+
+  /**
+   * Return whether or not a value's user is in a liveness set.
+   *
+   * @param Val a value whose users are checked against the liveness set
+   * @param Live a set of live values
+   * @return true if a user is in the liveness set, false otherwise
+   */
+  bool hasLiveUser(const Value *Val,
+                   const std::set<const Value *> &Live) const {
+    Value::const_use_iterator use, e;
+    for(use = Val->use_begin(), e = Val->use_end(); use != e; use++)
+      if(Live.count(use->getUser())) return true;
+    return false;
+  }
+};
+
+} /* end anonymous namespace */
+
+
+char InsertStackMaps::ID = 0;
+const StringRef InsertStackMaps::SMName = "llvm.experimental.stackmap";
+
+INITIALIZE_PASS_BEGIN(InsertStackMaps, "insert-stackmaps",
+                      "Instrument equivalence points with stack maps",
+                      false, false)
+INITIALIZE_PASS_DEPENDENCY(LiveValues)
+INITIALIZE_PASS_DEPENDENCY(DominatorTreeWrapperPass)
+INITIALIZE_PASS_END(InsertStackMaps, "insert-stackmaps",
+                    "Instrument equivalence points with stack maps",
+                    false, false)
+
+namespace llvm {
+  ModulePass *createInsertStackMapsPass() { return new InsertStackMaps(); }
+}
+
Index: lib/Transforms/Instrumentation/Instrumentation.cpp
===================================================================
--- lib/Transforms/Instrumentation/Instrumentation.cpp	(revision 277823)
+++ lib/Transforms/Instrumentation/Instrumentation.cpp	(working copy)
@@ -25,7 +25,9 @@
   initializeAddressSanitizerModulePass(Registry);
   initializeBoundsCheckingPass(Registry);
   initializeGCOVProfilerPass(Registry);
+  initializeInsertStackMapsPass(Registry);
   initializeInstrProfilingPass(Registry);
+  initializeLibcStackMapsPass(Registry);
   initializeMemorySanitizerPass(Registry);
   initializeThreadSanitizerPass(Registry);
   initializeSanitizerCoverageModulePass(Registry);
Index: lib/Transforms/Instrumentation/LibcStackMaps.cpp
===================================================================
--- lib/Transforms/Instrumentation/LibcStackMaps.cpp	(nonexistent)
+++ lib/Transforms/Instrumentation/LibcStackMaps.cpp	(working copy)
@@ -0,0 +1,229 @@
+#include <map>
+#include <vector>
+#include "llvm/Pass.h"
+#include "llvm/IR/IRBuilder.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/Type.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/Path.h"
+#include "llvm/Support/raw_ostream.h"
+
+#define DEBUG_TYPE "libc-stackmaps"
+
+using namespace llvm;
+
+namespace {
+
+/**
+ * Instrument thread starting points with stackmaps.  These are the only
+ * functions inside of libc for which we want to generate metadata, since we
+ * disallow migration inside the public libc API.
+ */
+// TODO: only implemented for musl-libc!
+class LibcStackMaps : public ModulePass
+{
+public:
+  static char ID;
+  size_t numInstrumented;
+
+  LibcStackMaps() : ModulePass(ID), numInstrumented(0) {
+    initializeLibcStackMapsPass(*PassRegistry::getPassRegistry());
+  }
+  ~LibcStackMaps() {}
+
+  /* ModulePass virtual methods */
+  virtual const char *getPassName() const
+  { return "Insert stackmaps in libc thread start functions"; }
+
+  virtual void getAnalysisUsage(AnalysisUsage &AU) const
+  { AU.setPreservesCFG(); }
+
+  virtual bool runOnModule(Module &M)
+  {
+    int64_t smid;
+    bool modified = false;
+    Function *F;
+    std::map<std::string, std::vector<std::string> >::const_iterator file;
+
+    /* Is this a module (i.e., source file) we're interested in? */
+    if((file = funcs.find(sys::path::stem(M.getName()))) != funcs.end())
+    {
+      DEBUG(dbgs() << "\n********** Begin LibcStackMaps **********\n"
+                   << "********** Module: " << file->first << " **********\n\n");
+
+      this->createSMType(M);
+      modified |= this->addSMDeclaration(M);
+
+      /* Iterate over thread starting functions in the module */
+      for(size_t f = 0, fe = file->second.size(); f < fe; f++)
+      {
+        DEBUG(dbgs() << "LibcStackMaps: entering thread starting function "
+                     << file->second[f] << "\n");
+
+        F = M.getFunction(file->second[f]);
+        assert(F && !F->isDeclaration() && "No thread function definition");
+        modified |= this->removeOldStackmaps(F);
+        assert(smids.find(file->second[f]) != smids.end() && "No ID for function");
+        smid = smids.find(file->second[f])->second;
+
+        /*
+         * Look for & instrument a generic call instruction followed by a call
+         * to an exit function, e.g.,
+         *
+         *   %call = call i32 %main(...)
+         *   call void @exit(i32 %call)
+         */
+        for(Function::iterator bb = F->begin(), be = F->end(); bb != be; bb++)
+        {
+          bool track = false;
+          for(BasicBlock::reverse_iterator i = bb->rbegin(), ie = bb->rend();
+              i != ie; i++)
+          {
+            if(isExitCall(*i)) track = true;
+            else if(track && isa<CallInst>(*i))
+            {
+              IRBuilder<> builder(i->getNextNode());
+              std::vector<Value *> args(2);
+              args[0] = ConstantInt::getSigned(Type::getInt64Ty(M.getContext()), smid);
+              args[1] = ConstantInt::getSigned(Type::getInt32Ty(M.getContext()), 0);
+              builder.CreateCall(this->SMFunc, ArrayRef<Value*>(args));
+              this->numInstrumented++;
+              break;
+            }
+          }
+        }
+      }
+
+      DEBUG(dbgs() << "LibcStackMaps: finished module " << M.getName()
+                   << ", added " << this->numInstrumented << " stackmaps\n\n";);
+    }
+
+    if(numInstrumented > 0) modified = true;
+    return modified;
+  }
+
+private:
+  /* Name of stack map intrinsic */
+  static const StringRef SMName;
+
+  /* Stack map instruction creation */
+  Function *SMFunc;
+  FunctionType *SMTy; // Used for creating function declaration
+
+  /* Files, functions & IDs */
+  static const std::map<std::string, std::vector<std::string> > funcs;
+  static const std::map<std::string, int64_t> smids;
+  static const std::vector<std::string> exitFuncs;
+
+  /**
+   * Create the function type for the stack map intrinsic.
+   */
+  void createSMType(const Module &M)
+  {
+    std::vector<Type*> params(2);
+    params[0] = Type::getInt64Ty(M.getContext());
+    params[1] = Type::getInt32Ty(M.getContext());
+    this->SMTy = FunctionType::get(Type::getVoidTy(M.getContext()),
+                                                   ArrayRef<Type*>(params),
+                                                   true);
+  }
+
+  /**
+   * Add the stackmap intrinisic's function declaration if not already present.
+   * Return true if the declaration was added, or false if it's already there.
+   */
+  bool addSMDeclaration(Module &M)
+  {
+    if(!(this->SMFunc = M.getFunction(this->SMName)))
+    {
+      DEBUG(dbgs() << "Adding stackmap function declaration to " << M.getName() << "\n");
+      this->SMFunc = cast<Function>(M.getOrInsertFunction(this->SMName, this->SMTy));
+      this->SMFunc->setCallingConv(CallingConv::C);
+      return true;
+    }
+    else return false;
+  }
+
+  /**
+   * Iterate over all instructions, removing previously found stackmaps.
+   */
+  bool removeOldStackmaps(Function *F)
+  {
+    bool modified = false;
+    CallInst* CI;
+    const Function *CurF;
+
+    DEBUG(dbgs() << "Searching for/removing old stackmaps\n";);
+
+    for(Function::iterator bb = F->begin(), bbe = F->end(); bb != bbe; bb++) {
+      for(BasicBlock::iterator i = bb->begin(), ie = bb->end(); i != ie; i++) {
+        if((CI = dyn_cast<CallInst>(&*i))) {
+          CurF = CI->getCalledFunction();
+          if(CurF && CurF->hasName() && CurF->getName() == SMName) {
+            i = i->eraseFromParent()->getPrevNode();
+            modified = true;
+          }
+        }
+      }
+    }
+
+    DEBUG(if(modified) dbgs() << "WARNING: found previous stackmaps!\n";);
+    return modified;
+  }
+
+  /**
+   * Return whether or not the instruction is a call to an exit function.
+   */
+  bool isExitCall(Instruction &I)
+  {
+    CallInst *CI;
+    Function *F;
+
+    if((CI = dyn_cast<CallInst>(&I)))
+    {
+      F = CI->getCalledFunction();
+      if(F && F->hasName())
+        for(size_t i = 0, e = exitFuncs.size(); i < e; i++)
+          if(F->getName() == exitFuncs[i]) return true;
+    }
+
+    return false;
+  }
+};
+
+} /* end anonymous namespace */
+
+char LibcStackMaps::ID = 0;
+const StringRef LibcStackMaps::SMName = "llvm.experimental.stackmap";
+
+/**
+ * Map a source code filename (minus the extension) to the names of functions
+ * inside which are to be instrumented.
+ */
+const std::map<std::string, std::vector<std::string> > LibcStackMaps::funcs = {
+  {"__libc_start_main", {"__libc_start_main"}},
+  {"pthread_create", {"start", "start_c11"}}
+};
+
+/* Map a function name to the stackmap ID representing that function. */
+const std::map<std::string, int64_t> LibcStackMaps::smids = {
+  {"__libc_start_main", UINT64_MAX},
+  {"start", UINT64_MAX - 1},
+  {"start_c11", UINT64_MAX - 2}
+};
+
+/**
+ * Thread exit function names, used to search for starting function call site
+ * to be instrumented with stackmap.
+ */
+const std::vector<std::string> LibcStackMaps::exitFuncs = {
+  "exit", "pthread_exit", "__pthread_exit"
+};
+
+INITIALIZE_PASS(LibcStackMaps, "libc-stackmaps",
+  "Instrument libc thread start functions with stack maps", false, false)
+
+namespace llvm {
+  ModulePass *createLibcStackMapsPass() { return new LibcStackMaps(); }
+}
+
Index: lib/Transforms/Utils/CMakeLists.txt
===================================================================
--- lib/Transforms/Utils/CMakeLists.txt	(revision 277823)
+++ lib/Transforms/Utils/CMakeLists.txt	(working copy)
@@ -28,6 +28,7 @@
   Mem2Reg.cpp
   MetaRenamer.cpp
   ModuleUtils.cpp
+  NameStringLiterals.cpp
   PromoteMemoryToRegister.cpp
   SSAUpdater.cpp
   SimplifyCFG.cpp
@@ -34,6 +35,7 @@
   SimplifyIndVar.cpp
   SimplifyInstructions.cpp
   SimplifyLibCalls.cpp
+  StaticVarSections.cpp
   SymbolRewriter.cpp
   UnifyFunctionExitNodes.cpp
   Utils.cpp
Index: lib/Transforms/Utils/NameStringLiterals.cpp
===================================================================
--- lib/Transforms/Utils/NameStringLiterals.cpp	(nonexistent)
+++ lib/Transforms/Utils/NameStringLiterals.cpp	(working copy)
@@ -0,0 +1,119 @@
+#include <algorithm>
+#include <cctype>
+#include "llvm/Pass.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/GlobalVariable.h"
+#include "llvm/IR/GlobalValue.h"
+#include "llvm/IR/Module.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+#define DEBUG_TYPE "name-string-literals"
+#define CHARS_FOR_NAME 10
+
+using namespace llvm;
+
+namespace
+{
+
+/**
+ * Generate unique name for private anonymous string literals.  Uses the
+ * filename, LLVM's temporary name and (up to) the first 10 characters of the
+ * string.  Converts non-alphanumeric characters to underscores.
+ */
+std::string UniquifySymbol(const Module &M, GlobalVariable &Sym)
+{
+  std::string newName;
+  std::string::size_type loc;
+  auto filter = [](char c){ return !isalnum(c); };
+
+  newName = M.getName();
+  loc = newName.find_last_of('.');
+  newName = newName.substr(0, loc) + "_" + Sym.getName().str() + "_";
+  std::replace_if(newName.begin(), newName.end(), filter, '_');
+
+  // Check if it's a string, and if so use string content to uniquify
+  if(Sym.hasInitializer()) {
+    Constant *Initializer = Sym.getInitializer();
+    if(isa<ConstantDataSequential>(Initializer)) {
+      ConstantDataSequential *CDS = cast<ConstantDataSequential>(Initializer);
+      if(CDS->isString()) {
+        std::string data = CDS->getAsString().substr(0, CHARS_FOR_NAME);
+        std::replace_if(data.begin(), data.end(), filter, '_');
+        newName += data;
+      }
+    }
+  }
+
+  return newName;
+}
+
+/**
+ * This pass searches for anonymous read-only data for which there is no symbol
+ * and generates a symbol for the data.  This is required by the Popcorn
+ * compiler in order to align the data at link-time.
+ */
+class NameStringLiterals : public ModulePass
+{
+public:
+	static char ID;
+
+  NameStringLiterals() : ModulePass(ID) {}
+  ~NameStringLiterals() {}
+
+	/* ModulePass virtual methods */
+  virtual void getAnalysisUsage(AnalysisUsage &AU) const { AU.setPreservesCFG(); }
+	virtual bool runOnModule(Module &M)
+  {
+    bool modified = false;
+    std::string newName;
+    Module::global_iterator gl, gle; // for global variables
+
+    DEBUG(errs() << "\n********** Begin NameStringLiterals **********\n"
+                 << "********** Module: " << M.getName() << " **********\n\n");
+
+    // Iterate over all globals and generate symbol for anonymous string
+    // literals in each module
+    for(gl = M.global_begin(), gle = M.global_end(); gl != gle; gl++) {
+      // DONT NEED TO CHANGE NAME PER-SE just change type
+      // PrivateLinkage does NOT show up in any symbol table in the object file!
+      if(gl->getLinkage() == GlobalValue::PrivateLinkage) {
+        //change Linkage
+        //FROM private unnamed_addr constant [num x i8]
+        //TO global [num x i8]
+        gl->setLinkage(GlobalValue::ExternalLinkage);
+
+        // Make the global's name unique so we don't clash when linking with
+        // other files
+        newName = UniquifySymbol(M, *gl);
+        gl->setName(newName);
+
+        // Also REMOVE unnamed_addr value
+        if(gl->hasUnnamedAddr()) {
+          gl->setUnnamedAddr(false);
+        }
+
+        modified = true;
+
+        DEBUG(errs() << "New anonymous string name: " << newName << "\n";);
+      } else {
+        DEBUG(errs() << "> " <<  *gl << ", linkage: "
+                     << gl->getLinkage() << "\n");
+      }
+    }
+  
+    return modified;
+  }
+  virtual const char *getPassName() const { return "Name string literals"; }
+};
+
+} /* end anonymous namespace */
+
+char NameStringLiterals::ID = 0;
+INITIALIZE_PASS(NameStringLiterals, "name-string-literals",
+  "Generate symbols for anonymous string literals", false, false)
+
+namespace llvm {
+  ModulePass *createNameStringLiteralsPass() { return new NameStringLiterals(); }
+}
+
Index: lib/Transforms/Utils/StaticVarSections.cpp
===================================================================
--- lib/Transforms/Utils/StaticVarSections.cpp	(nonexistent)
+++ lib/Transforms/Utils/StaticVarSections.cpp	(working copy)
@@ -0,0 +1,106 @@
+#include <algorithm>
+#include "llvm/Pass.h"
+#include "llvm/IR/Module.h"
+#include "llvm/IR/GlobalVariable.h"
+#include "llvm/IR/GlobalValue.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+#define DEBUG_TYPE "static-var-sections"
+
+using namespace llvm;
+
+namespace
+{
+
+std::string UniquifySymbol(const Module &M,
+                           std::string &section,
+                           GlobalVariable &Sym)
+{
+  std::string newName;
+  auto filter = [](char c){ return !isalnum(c); };
+
+  newName = M.getName().str() + "_" + Sym.getName().str();
+  std::replace_if(newName.begin(), newName.end(), filter, '_');
+
+  return section + newName;
+}
+
+/**
+ * This pass searches for static, i.e., module-private, global variables and
+ * modifies their linkage to be in their own sections similarly to other
+ * global variables with the -fdata-sections switch.  By default, LLVM doesn't
+ * apply -fdata-sections to static global variables.
+ */
+class StaticVarSections : public ModulePass
+{
+public:
+	static char ID;
+
+	StaticVarSections() : ModulePass(ID) {}
+	~StaticVarSections() {}
+
+	/* ModulePass virtual methods */
+  virtual void getAnalysisUsage(AnalysisUsage &AU) const { AU.setPreservesCFG(); }
+	virtual bool runOnModule(Module &M)
+  {
+    bool modified = false;
+    Module::iterator it, ite;
+    Module::global_iterator gl, gle; // for global variables
+  
+    DEBUG(errs() << "\n********** Beginning StaticVarSections **********\n"
+                 << "********** Module: " << M.getName() << " **********\n\n");
+  
+    // Iterate over all static globals and place them in their own section
+    for(gl = M.global_begin(), gle = M.global_end(); gl != gle; gl++) {
+      std::string secName = ".";
+      if(gl->isThreadLocal()) secName += "t";
+  
+      if(gl->hasCommonLinkage() &&
+         gl->getName().find(".cache.") != std::string::npos) {
+        gl->setLinkage(GlobalValue::InternalLinkage);
+      }
+  
+      // InternalLinkage is specifically for STATIC variables
+      if(gl->hasInternalLinkage()) {
+        if(gl->isConstant()) {
+          //Belongs in RODATA
+          assert(!gl->isThreadLocal() && "TLS data should not be in .rodata");
+          secName += "rodata.";
+        }
+        else if(gl->getInitializer()->isZeroValue()) {
+          //Belongs in BSS
+          secName += "bss.";
+        }
+        else {
+          //Belongs in DATA
+          secName += "data.";
+        }
+
+        secName = UniquifySymbol(M, secName, *gl);
+        gl->setSection(secName);
+        modified = true;
+
+        DEBUG(errs() << *gl << " - new section: " << secName << "\n");
+      } else {
+        DEBUG(errs() << "> " <<  *gl << ", linkage: "
+                     << gl->getLinkage() << "\n");
+        continue;
+      }
+    }
+    
+    return modified;
+  }
+  virtual const char *getPassName() const { return "Static variables in separate sections"; }
+};
+
+} /* end anonymous namespace */
+
+char StaticVarSections::ID = 0;
+INITIALIZE_PASS(StaticVarSections, "static-var-sections",
+  "Put static variables into separate sections", false, false)
+
+namespace llvm {
+  ModulePass *createStaticVarSectionsPass() { return new StaticVarSections(); }
+}
+
Index: lib/Transforms/Utils/Utils.cpp
===================================================================
--- lib/Transforms/Utils/Utils.cpp	(revision 277823)
+++ lib/Transforms/Utils/Utils.cpp	(working copy)
@@ -28,7 +28,9 @@
   initializeLoopSimplifyPass(Registry);
   initializeLowerInvokePass(Registry);
   initializeLowerSwitchPass(Registry);
+  initializeNameStringLiteralsPass(Registry);
   initializePromotePassPass(Registry);
+  initializeStaticVarSectionsPass(Registry);
   initializeUnifyFunctionExitNodesPass(Registry);
   initializeInstSimplifierPass(Registry);
   initializeMetaRenamerPass(Registry);
